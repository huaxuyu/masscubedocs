{"/about/":{"data":{"":"The MassCube project is developed by Dr. Huaxu Yu, a postdoctoral researcher in the Prof. Oliver Fiehn’s lab at the University of California, Davis.","contact#Contact":"Please contact us for any questions or suggestions. We welcome contributions to the documentation, code, and workflows.\nCorresponding author: Oliver Fiehn: ofiehn@ucdavis.edu\nDeveloper and maintainer: Huaxu Yu: hxuyu@ucdavis.edu; yhxchem@outlook.com","teams#Teams":"Our teams are organized as follows:\nCode and software development Documentation and website Researcher team for testing and validation Labs and researchers interested in collaborating with us are welcome to contact us. Now we have the following labs working together:\nFiehn Lab "},"title":"About Us"},"/contribute/":{"data":{"":"We welcome contributions to the code, workflows, and documentation.\nCorresponding author: Oliver Fiehn: ofiehn@ucdavis.edu\nDeveloper and maintainer: Huaxu Yu: hxuyu@ucdavis.edu; yhxchem@outlook.com"},"title":"Contribute"},"/docs/":{"data":{"":"Hello! Welcome to the MassCube documentation!\nDate: 2025-07-24 Version: 1.2.9","features#Features":" Open-source: Free for non-commercial use.\nWorkflows: Run the entire data processing pipeline with a single command.\nAccurate: Efficient large-scale data processing with human-expert level accuracy.\nModules: 16 modules to cover the whole workflow.","getting-started#Getting Started":" Installation Quick Start ","must-reads#Must reads":" Starting from MassCube ver. 1.2.8, only one database is needed for the untargeted metabolomics workflow. Make sure you download the latest version of MS/MS database. ","release-notes-for-v1211#Release Notes for v1.2.11":" Signal centroiding is now much faster (\u003e300× faster). Reduce memory usage in the “untargeted-metabolomics” workflow. ","what-is-masscube#What is MassCube?":"MassCube is a Python computing library for mass spectrometry data processing in metabolomics."},"title":"Documentation"},"/docs/algorithms/":{"data":{"":"We are preparing figures to explain the algorithms used in masscube.\nPlease check our publication for details."},"title":"Algorithms"},"/docs/api/":{"data":{"":"All functions and objects in MassCube are documented in the API reference. Version 1.1 of MassCube includes 16 modules designed to manage a variety of data processing tasks, featuring core objects specifically tailored for MS data, particularly data generated from LC-MS experiments.\nMassCube modules masscube ├───init ├───alignment ├───annotation ├───classifier_builder ├───feature_detection ├───feature_evaluation ├───feature_grouping ├───mzpkl ├───network ├───normalization ├───params ├───raw_data_utils ├───stats ├───utils_functions ├───visualization └───workflows "},"title":"APIs"},"/docs/api/alignment/":{"data":{"":"","classes#Classes":"AlignedFeature A class to model a feature in mass spectrometry data. Generally, a feature is defined as a unique pair of m/z and retention time.\nAttributes:\nfeature_id_arr (np.array): Feature ID from individual files (-1 if not detected or gap filled). mz_arr (np.array): m/z values. rt_arr (np.array): Retention times. scan_idx_arr (np.array): Scan index of the peak apex. peak_height_arr (np.array): Peak height. peak_area_arr (np.array): Peak area. top_average_arr (np.array): Average of the highest three intensities. ms2_seq (list): Representative MS2 spectrum from each file (default: highest total intensity). length_arr (np.array): Length (i.e. non-zero scans in the peak). gaussian_similarity_arr (np.array): Gaussian similarity. noise_score_arr (np.array): Noise score. asymmetry_factor_arr (np.array): Asymmetry factor. sse_arr (np.array): Squared error to the smoothed curve. is_segmented_arr (np.array): Whether the peak is segmented. id (int): Index of the feature. feature_group_id (int): Feature group ID. mz (float): m/z. rt (float): Retention time. reference_file (str): The reference file with the highest peak height. reference_scan_idx (int): The scan index of the peak apex from the reference file. highest_intensity (float): The highest peak height from individual files (which is the reference file). ms2 (str): Representative MS2 spectrum. ms2_reference_file (str): The reference file for the representative MS2 spectrum. gaussian_similarity (float): Gaussian similarity from the reference file. noise_score (float): Noise level from the reference file. asymmetry_factor (float): Asymmetry factor from the reference file. detection_rate (float): Number of detected files / total number of files (blank not included). detection_rate_gap_filled (float): Number of detected files after gap filling / total number of files (blank not included). charge_state (int): Charge state. is_isotope (bool): Whether it is an isotope. isotope_signals (list): Isotope signals [[m/z, intensity], …]. is_in_source_fragment (bool): Whether it is an in-source fragment. adduct_type (str): Adduct type. annotation_algorithm (str): Annotation algorithm. Not used now. search_mode (str): ‘identity search’, ‘fuzzy search’, or ‘mzrt_search’. similarity (float): Similarity score (0-1). annotation (str): Name of annotated compound. formula (str): Molecular formula. matched_peak_number (int): Number of matched peaks. smiles (str): SMILES. inchikey (str): InChIKey. matched_precursor_mz (float): Matched precursor m/z. matched_adduct_type (str): Matched adduct type. matched_ms2 (str): Matched ms2 spectra. ","functions#Functions":"feature_alignment feature_alignment(path: str, params: Params)\nAlign the features from multiple processed single files as .txt format.\nParameters:\npath (str): The path to the feature tables of individual files. params (Params object): The parameters for alignment including sample names and sample groups. Returns:\nfeatures (list of AlignedFeature objects) gap_filling gap_filling(features, params: Params)\nFill the gaps for aligned features.\nParameters:\nfeatures (list of AlignedFeature objects): The aligned features. parameters (Params object): The parameters used for gap filling. Returns:\nfeatures (list of AlignedFeature objects). merge_features merge_features(features: list, params: Params)\nClean features by merging features with almost the same m/z and retention time.\nParameters:\nfeatures (list of AlignedFeature objects): The aligned features. params (Params object): The parameters used for merging features. Returns:\nfeatures (list of AlignedFeature objects).\nconvert_features_to_df convert_features_to_df(features, sample_names, quant_method=\"peak_height\")\nConvert the aligned features to a DataFrame.\nParameters:\nfeatures (list of AlignedFeature objects): The aligned features. sample_names (list): The sample names. quant_method (str): The quantification method, “peak_height”, “peak_area” or “top_average”. Returns:\nfeature_table (pd.DataFrame): The feature DataFrame. output_feature_to_msp output_feature_to_msp(feature_table, output_path)\nOutput MS2 spectra to MSP format.\nParameters:\nfeature_table (pd.DataFrame): The feature table. output_path (str): The path to the output MSP file. output_feature_table output_feature_table(feature_table, output_path)\nOutput the aligned feature table.\nParameters:\nfeature_table (pd.DataFrame): The aligned feature table. output_path (str): The path to save the aligned feature table. retention_time_correction retention_time_correction(mz_ref, rt_ref, mz_arr, rt_arr, mz_tol=0.01, rt_tol=2.0, mode='linear_interpolation', rt_max=None)\nCorrect retention times for feature alignment. There are three steps including (1) finding the selected anchors in the given data, (2) creating a model to correct retention times, and (3) correcting retention times.\nParameters:\nmz_ref (np.array): The m/z values of the selected anchors from another reference file. rt_ref (np.array): The retention times of the selected anchors from another reference file. mz_arr (np.array): Feature m/z values in the current file. rt_arr (np.array): Feature retention times in the current file. mz_tol (float): The m/z tolerance for selecting anchors. rt_tol (float): The retention time tolerance for selecting anchors. mode (str): The mode for retention time correction. Only ’linear_interpolation’ is available now. rt_max (float): End of the retention time range. Returns:\nrt_arr (np.array): The corrected retention times. f (interp1d): The model for retention time correction. rt_anchor_selection rt_anchor_selection(data_path, num=50, noise_score_tol=0.1, mz_tol=0.01)\nSelect retention time anchors from the feature tables. Retention time anchors have unique m/z values and low noise scores. From all candidate features, the top num features with the highest peak heights are selected as anchors.\nParameters:\ndata_path (str): The absolute directory to the feature tables. num (int): The number of anchors to be selected. noise_score_tol (float): The noise level for the anchors. mz_tol (float): The m/z tolerance for selecting anchors. Returns:\nanchors (list): A list of anchors (dict) for retention time correction. ","overview#Overview":"This module provides functionality for aligning metabolic features from different samples in mass spectrometry data.\nFeature alignment: Align features across different samples, considering parameters like m/z tolerance and retention time tolerance. Gap filling: Fill in missing features across aligned samples using various strategies. Merge features: Clean feature table by merging features with almost the same m/z and retention time. Retention time correction: Correct retention times to align features more accurately. Output feature table: Save the aligned features to a file. "},"title":"alignment"},"/docs/api/annotation/":{"data":{"":"","functions#Functions":"load_ms2_db load_ms2_db(path)\nLoad MS2 database in pickle, msp, or json format.\nParameters:\npath (str): The path to the MS2 database. Returns:\nentropy_search (FlashEntropySearch object): The MS2 database. annotate_aligned_features annotate_aligned_features(features, params, num=5)\nAnnotate feature’s MS2 using database.\nParameters:\nfeatures (list): A list of AlignedFeature objects. params (Params object): The parameters for the workflow. num (int): The number of top MS2 spectra to search. Returns:\nfeatures (list): A list of AlignedFeature objects with MS2 annotation. annotate_features Annotate features from a single raw data file using MS2 database.\nannotate_features(d, sim_tol=None, fuzzy_search=True, ms2_library_path=None)\nParameters:\nd (MSData object): MS data file. sim_tol (float): The similarity threshold for MS2 annotation. If not specified, the corresponding parameter from the MS data file will be used. fuzzy_search (bool): Whether to further annotated the unmatched MS2 using fuzzy search. ms2_library_path (str): The absolute path to the MS2 database. If not specified, the corresponding parameter from the MS data file will be used. annotate_ms2 Annotate MS2 spectra using MS2 database.\nannotate_ms2(ms2, ms2_library_path, sim_tol=0.7, fuzzy_search=True)\nParameters:\nms2 (Scan object): MS2 spectrum. ms2_library_path (str): The absolute path to the MS2 database. If not specified, the corresponding parameter from the MS data file will be used. sim_tol (float): The similarity threshold for MS2 annotation. fuzzy_search (bool): Whether to further annotated the unmatched MS2 using fuzzy search. Returns:\nscore (float): The similarity score. matched (dict): The matched MS2 spectrum. matched_peak_num (int): The number of matched peaks. search_mode (str): The search mode, ‘identity_search’ or ‘fuzzy_search’. feature_annotation_mzrt feature_annotation_mzrt(features, path, mz_tol=0.01, rt_tol=0.3)\nAnnotate features based on a mzrt file (only .csv is supported now)\nParameters:\nfeatures (list): A list of features. path (str): The path to the mzrt file in csv format. mz_tol (float): The m/z tolerance for matching. rt_tol (float): The RT tolerance for matching. Returns:\nfeatures (list): A list of features with annotation. feature_to_feature_search feature_to_feature_search(feature_list)\nCalculate the MS2 similarity between features using fuzzy search.\nParameters:\nfeature_list (list): A list of AlignedFeature objects. Returns:\nsimilarity_matrix (pandas.DataFrame): A DataFrame containing the similarity matrix between features. index_feature_list index_feature_list(feature_list)\nA helper function to index a list of features for spectrum entropy search.\nParameters:\nfeature_list (list): A list of AlignedFeature objects. Returns:\nentropy_search (FlashEntropySearch object): The indexed feature list. output_ms2_to_msp output_ms2_to_msp(feature_table, output_path)\nOutput MS2 spectra to MSP format\nParameters:\nfeature_table (pandas.DataFrame): A DataFrame containing the MS2 spectra. output_path (str): The path to the output MSP file. ","overview#Overview":"This module is designed for annotating metabolites based on their m/z, retention time, and MS/MS spectra."},"title":"annotation"},"/docs/api/classifier_builder/":{"data":{"":"","functions#Functions":"feature_selection feature_selection(X, y, k=None)\nParameters:\nX (numpy.ndarray): The feature matrix. y (numpy.ndarray): The target variable. k (int): The number of features to select. By default, it is set to the number of samples divided by 10 (1/10 rule) and rounded up. Returns:\nX_new (numpy.ndarray): The selected features. selected_features (numpy.ndarray): The indices of the selected features. def feature_selection(X, y, k=None): \"\"\" Select features for the classification model.\nParameters ---------- X : two-dimensional numpy array The feature matrix. y : one-dimensional numpy array The target variable. k : int The number of features to select. By default, it is set to the number of samples divided by 10 (1/10 rule) and rounded up. Returns ------- X_new : two-dimensional numpy array The fit-transformed feature matrix. selected_features : one-dimensional numpy array The indices of the selected features. \"\"\" train_rdf_model train_rdf_model(X_train, y_train)\nParameters:\nX_train (numpy.ndarray): The feature matrix for training. y_train (numpy.ndarray): The target variable for training. Returns:\nmodel (RandomForestClassifier): The trained random forest model. cross_validate_model cross_validate_model(X, y, model, k=5, random_state=0)\nParameters:\nX (numpy.ndarray): The feature matrix. y (numpy.ndarray): The target variable. model (RandomForestClassifier): The trained random forest model. k (int): The number of folds for cross-validation. random_state (int): The random state for the shuffle in KFold. Returns:\nscores (list): The accuracy scores for each fold. predict predict(model, X_test)\nParameters:\nmodel (RandomForestClassifier): The trained random forest model. X_test (numpy.ndarray): The feature matrix for testing. Returns:\npredictions (numpy.ndarray): The predicted classes. evaluate_model evaluate_model(predictions, y_test)\nParameters:\npredictions (numpy.ndarray): The predicted classes. y_test (numpy.ndarray): The true classes. Returns:\naccuracy (float): The accuracy of the model. build_classifier build_classifier(path=None, by_group=None, feature_num=None, gaussian_cutoff=0.6, detection_rate_cutoff=0.9, fill_ratio=0.5, cross_validation_k=5)\nParameters:\npath (str): Path to the project file. feature_num (int): The number of features to select for building the model. gaussian_cutoff (float): The Gaussian similarity cutoff. Default is 0.6. fill_ratio (float): The zero values will be replaced by the minimum value in the feature matrix times fill_ratio. Default is 0.5. cross_validation_k (int): The number of folds for cross-validation. Default is 5. predict_samples predict_samples(path, mz_tol=0.01, rt_tol=0.3)\nParameters:\npath (str): Path to the project file. mz_tol (float): The m/z tolerance for matching the features. Default is 0.01. rt_tol (float): The retention time tolerance for matching the features. Default is 0.3. ","overview#Overview":"This module provides a set of tools for building and using a random forest classifier for metabolomics data analysis. It supports feature selection, model training, cross-validation, and prediction on new data."},"title":"classifier_builder"},"/docs/api/feature_detection/":{"data":{"":"","classes#Classes":"Feature A class to store a feature characterized by a unique pair of m/z and retention time.\nAttributes:\nrt_seq (list of float): Retention time sequence.\nsignals (list): Signal sequence organized as [[m/z, intensity], …].\nscan_idx_seq (list of int): Scan index sequence.\nms2_seq (list): MS2 spectra.\ngap_counter (int): Counter for the number of consecutive zeros in the peak tail.\nid (int): Feature ID.\nfeature_group_id (int): Peak group ID.\nmz (float): m/z value.\nrt (float): Retention time.\nscan_idx (int): Scan index of the peak apex.\npeak_height (float): Peak height.\npeak_area (float): Peak area.\ntop_average (float): Average of the highest three intensities.\nms2 (object): Representative MS2 spectrum.\nlength (int): Number of valid scans in the feature.\ngaussian_similarity (float): Gaussian similarity.\nnoise_score (float): Noise score.\nasymmetry_factor (float): Asymmetry factor.\nsse (float): Squared error to the smoothed curve.\nis_segmented (bool): Indicates if the feature is segmented.\nis_isotope (bool): Indicates if the feature is an isotope.\ncharge_state (int): Charge state of the feature.\nisotope_signals (list): Isotope signals [[m/z, intensity], …].\nis_in_source_fragment (bool): Indicates if the feature is an in-source fragment.\nadduct_type (str): Adduct type.\nannotation_algorithm (str): Annotation algorithm.\nsearch_mode (str): Search mode (‘identity search’, ‘fuzzy search’, or ‘mzrt_search’).\nsimilarity (float): Similarity score (0-1).\nannotation (str): Name of annotated compound.\nformula (str): Molecular formula.\nmatched_peak_number (int): Number of matched peaks.\nsmiles (str): SMILES notation.\ninchikey (str): InChIKey notation.\nmatched_precursor_mz (float): Matched precursor m/z.\nmatched_ms2 (object): Matched MS2 spectra.\nmatched_adduct_type (str): Matched adduct type.\nMethods:\nextend(self, rt, signal, scan_idx): Extends the chromatographic peak with new data points. get_mz_error(self): Calculates the 3*sigma error of the feature’s m/z. get_rt_error(self): Calculates the 3*sigma error of the feature’s retention time. summarize(self, ph=True, pa=True, ta=True, g_score=True, n_score=True, a_score=True): Summarizes the feature by calculating summary statistics. subset(self, start, end, summarize=True): Keeps a subset of the feature based on start and end positions. ","functions#Functions":"detect_features detect_features(d)\nDetects features in the MS data.\nParameters:\nd (MSData object): An object that contains the MS data. Returns:\nfinal_features (list of Feature objects): A list of detected features. segment_feature segment_feature(feature, sigma=1.2, prominence_ratio=0.05, distance=10, peak_height_tol=1000, length_tol=5, sse_tol=0.5)\nSegments a feature into multiple features based on edge detection.\nParameters:\nfeature (Feature object): The feature to segment. sigma (float): The sigma value for the Gaussian filter. DFault is 1.2. prominence_ratio (float): The prominence ratio for finding peaks. Default is 0.05. distance (int): The minimum distance between peaks. Default is 10. peak_height_tol (float): The peak height tolerance for segmentation. length_tol (int): The length tolerance for segmentation. Default is 5. sse_tol (float): The squared error tolerance for segmentation. Default is 0.5. Returns:\nsegmented_features (list of Feature objects): A list of segmented features. Please see the source code for more internal functions.","overview#Overview":"Untargeted feature detection."},"title":"feature_detection"},"/docs/api/feature_evaluation/":{"data":{"":"","functions#Functions":"calculate_gaussian_similarity calculate_gaussian_similarity(x, y)\nCalculates the Gaussian similarity of a peak by comparing its shape to a Gaussian distribution (Pearson product-moment correlation coefficients).\nParameters:\nx (numpy array): Retention time values of the peak. y (numpy array): Intensity values of the peak. Returns:\nsimilarity (float): Gaussian similarity score, where higher values indicate better similarity to a Gaussian distribution. calculate_noise_level calculate_noise_level(y, rel_int_tol=0.05)\nCalculates the noise level of a peak by observing the intensity fluctuations in the peak.\nParameters:\ny (numpy array): Intensity values of the peak. rel_int_tol (float): Relative intensity tolerance to the base peak. Returns:\nnoise_level (float): Noise level, reflecting the signal fluctuation. calculate_asymmetry_factor calculate_asymmetry_factor(y)\nCalculates the asymmetry factor of the peak at 10% of the peak height.\nParameters:\ny (numpy array): Intensity values of the peak. Returns:\nasymmetry_factor (float): Asymmetry factor, indicating the peak shape asymmetry. ","overview#Overview":"This module provides tools for evaluating the quality of detected features in untargeted metabolomics data. The quality metrics include Gaussian similarity, noise level, and asymmetry factor, which can help assess the reliability and robustness of detected peaks."},"title":"feature_evaluation"},"/docs/api/feature_grouping/":{"data":{"":"","constants#Constants":"ADDUCT_POS A dictionary of positive adducts with the adduct form as the key and the m/z shift, charge state, and multiplier as the values.\nADDUCT_NEG A dictionary of negative adducts with the adduct form as the key and the m/z shift, charge state, and multiplier as the values.","functions#Functions":"group_features_after_alignment group_features_after_alignment(features, params: Params)\nGroups features after alignment based on the reference file. This function requires reloading the raw data to examine the scan-to-scan correlation between features. The annotated feature groups are stored in the feature_group_id attribute of the AlignedFeature objects.\nParameters:\nfeatures (list): A list of AlignedFeature objects. params (Params object): A Params object that contains the parameters for feature grouping. group_features_single_file group_features_single_file(d)\nGroups features from a single file based on the m/z, retention time, MS2, and scan-to-scan correlation. The annotated feature groups are stored in the feature_group_id attribute of the Feature objects.\nParameters:\nd (MSData object): An MSData object containing the detected ROIs to be grouped. generate_search_dict generate_search_dict(feature, adduct_form, ion_mode)\nGenerates a search dictionary for feature grouping based on the adduct form and ionization mode.\nParameters:\nfeature (Feature object): The feature object to be grouped. adduct_form (str): The adduct form of the feature. ion_mode (str): The ionization mode, either “positive” or “negative”. Returns:\ndict: A dictionary containing the possible adducts and in-source fragments. find_isotope_signals find_isotope_signals(mz, signals, mz_tol=0.015, charge_state=1, num=5)\nFinds isotope patterns from the MS1 signals based on the m/z value and intensity.\nParameters:\nmz (float): The m/z value of the feature. signals (np.array): The MS1 signals as [[m/z, intensity], …]. mz_tol (float): The m/z tolerance to find isotopes (default 0.015 Da). charge_state (int): The charge state of the feature (default 1). num (int): The maximum number of isotopes to be found (default 5). Returns:\nnumpy.array: The m/z and intensity of the isotopes. scan_to_scan_cor_intensity scan_to_scan_cor_intensity(a, b)\nCalculates the scan-to-scan correlation between two features using Pearson correlation based on their intensity profiles.\nParameters:\na (np.array): Intensity array of the first m/z. b (np.array): Intensity array of the second m/z. Returns:\nfloat: The scan-to-scan correlation between the two features. scan_to_scan_correlation scan_to_scan_correlation(feature_a, feature_b)\nCalculates the scan-to-scan correlation between two features using Pearson correlation based on their intensity profiles.\nParameters:\nfeature_a (Feature object): The first feature object. feature_b (Feature object): The second feature object. Returns:\nfloat: The scan-to-scan correlation between the two features. get_charge_state get_charge_state(mz_seq, valid_charge_states=[1,2])\nDetermines the charge state of the isotopes based on the m/z sequence.\nParameters:\nmz_seq (list): A list of m/z values of isotopes. valid_charge_states (list): A list of valid charge states (default [1,2]). Returns:\nint: The charge state of the isotopes. ","overview#Overview":"The feature_grouping module provides functions to group features based on their m/z values, retention times, MS2 data, and scan-to-scan correlation. The module is designed for untargeted metabolomics workflows to group features that may represent the same compound, isotopes, in-source fragments, or adducts. The functions in this module are used to group features based on the reference file or within a single file."},"title":"feature_grouping"},"/docs/api/mzpkl/":{"data":{"":"","functions#Functions":"Convert MS Data object to mzpkl convert_MSData_to_mzpkl(d, output_dir: str = None)\nConverts an MSData object to an mzpkl file.\nParameters:\nd (MSData): The MSData object to be converted. output_dir (str): The directory where the mzpkl file will be saved. Output:\nthe converted mzpkl file will be saved in the specified directory. if the output directory is not specified, the mzpkl file will be returned as a dictionary. Read mzpkl to MS Data object read_mzpkl_to_MSData(d, file_path: str)\nReads an mzpkl file to an MSData object.\nParameters:\nd (MSData): The initiated MSData object without scans data. file_path (str): The path to the mzpkl file. ","overview#Overview":"This module defines the structure of the mzpkl file format, which is a temporary file format used to store the raw MS data for faster reloading. The mzpkl file format is a pickle file that is organized this way:\n{ \"name\": str, # the name of the file \"ion_mode\": str, # the ion mode of the file \"ms1_time_arr\": np.ndarray, # the time array of the MS1 scans \"ms1_idx\": np.ndarray, # the index array of the MS1 scans \"ms2_idx\": np.ndarray, # the index array of the MS2 scans \"scans\": list of 2D np.ndarray # MS1 and MS2 scans in the file. Each scan is a 2D np.ndarray with shape (n, 2), [[m/z, intensity], ...] } "},"title":"mzpkl"},"/docs/api/network/":{"data":{"":"Documentation is under construction. Please check our source code directly for the latest updates."},"title":"network"},"/docs/api/normalization/":{"data":{"":"","functions#Functions":"sample_normalization sample_normalization(feature_table, sample_metadata=None, method='pqn', feature_selection=True)\nNormalizes samples using a feature list, typically excluding blank samples.\nParameters:\nfeature_table (pandas DataFrame): The feature table. sample_metadata (pd.DataFrame): DataFrame containing sample metadata. See params module for details. method (str): The method to find the normalization factors. Options: 'pqn': Probabilistic Quotient Normalization. feature_selection (bool): Whether to select high-quality features for normalization. High-quality features have relative standard deviation (RSD) less than 25% in QC samples and average intensity in QC+biological samples greater than 2 fold of the average intensity in blank samples. Returns:\npandas DataFrame: The normalized feature table. find_normalization_factors find_normalization_factors(array, method='pqn')\nFinds the normalization factors for a data frame.\nParameters:\narray (numpy array): The data to be normalized. method (str): The method to find the normalization factors. Options: 'pqn': Probabilistic Quotient Normalization. Returns:\nnumpy array: The normalization factors. sample_normalization_by_factors sample_normalization_by_factors(array, v)\nNormalizes a data frame by a vector.\nParameters:\narray (numpy array): The data to be normalized. v (numpy array): The normalization factor. Returns:\nnumpy array: The normalized data. find_reference_sample find_reference_sample(array, method='median_intensity')\nFinds the reference sample for normalization.\nParameters:\narray (numpy array): The data to be normalized. method (str): The method to find the reference sample. Options: 'number': The reference sample has the most detected features. 'total_intensity': The reference sample has the highest total intensity. 'median_intensity': The reference sample has the highest median intensity. Returns:\nint: The index of the reference sample. high_quality_feature_selection high_quality_feature_selection(array, is_qc=None, is_blank=None, blank_ratio_tol=0.5, qc_rsd_tol=0.25)\nSelects high-quality features based on provided criteria for normalization.\nParameters:\narray (numpy array): The data to be normalized. Samples are in columns and features are in rows. is_qc (numpy array): Boolean array indicating whether a sample is a quality control sample. is_blank (numpy array): Boolean array indicating whether a sample is a blank sample. blank_ratio_tol (float): The tolerance of the ratio of the average intensity in blank samples to the average intensity in QC and biological samples. qc_rsd_tol (float): The tolerance of the relative standard deviation (RSD) in QC samples. Returns:\nnumpy array: High-quality features. Features are in rows and samples are in columns. numpy array: The index of the selected features. signal_normalization signal_normalization(feature_table, sample_metadata, method='lowess', output_plot_path=None)\nNormalizes MS signal drifts based on analytical order.\nParameters:\nfeature_table (pandas DataFrame): The feature table. sample_metadata (pd.DataFrame): DataFrame containing sample metadata. See params module for details. method (str): The method to find the normalization factors. Options: 'lowess': Locally Weighted Scatterplot Smoothing. output_plot_path (str): The path to save the normalization plot. If none, no visualization will be generated. Returns:\npandas DataFrame: The normalized feature table. lowess_normalization lowess_normalization(array, qc_idx, frac=0.07, it=3)\nNormalizes samples using quality control samples.\nParameters:\narray (numpy array): The data to be normalized. qc_idx (numpy array of bool): Boolean array indicating whether a sample is a quality control sample. It’s length should be the same as the length of array. frac (float): The fraction of the data used when estimating each y-value (used in lowess). it (int): The number of residual-based reweightings to perform (used in lowess). Returns:\n‘dict’: A dictionary containing the lowess model, the fit curve, and the normalized array: {‘model’: model, ‘fit_curve’: y, ’normed_arr’: int_arr_corr} ","overview#Overview":"This module provides functions for normalizing data, particularly in the context of mass spectrometry. There are two types of normalization including\nSample normalization - to normalize samples with different total amounts/concentrations. Signal normalization - to address the signal drifts in the mass spectrometry data. "},"title":"normalization"},"/docs/api/params/":{"data":{"additional-notes--gotchas#Additional Notes \u0026amp; Gotchas":"paramsOverview The params module defines a class Params that stores and manages parameters for mass spectrometry-based untargeted metabolomics data processing. It also exposes a helper function find_ms_info and two dictionaries of parameter ranges and defaults.\nThis documentation is synchronized with the current implementation in params.py and reflects all attributes, methods, behaviors, defaults, and edge cases present in the code.\nClasses Params A configuration container for project-level and file-level processing parameters, including project setup, raw data reading/cleaning, feature detection, grouping, alignment, annotation, normalization, statistics, visualization, and output controls.\nAttributes Project \u0026 Metadata sample_metadata (pandas.DataFrame | None) — sample table held in-memory. project_dir (str | None) — project root directory. sample_dir (str | None) — directory for raw MS data; set during workflow prep. single_file_dir (str | None) — outputs for single-file processing. tmp_file_dir (str | None) — temporary/intermediate files. ms2_matching_dir (str | None) — MS/MS matching outputs. bpc_dir (str | None) — base peak chromatogram outputs. project_file_dir (str | None) — auxiliary project files (sample table with time, etc.). normalization_dir (str | None) — normalization results. statistics_dir (str | None) — statistical analysis results. problematic_files (dict) — problematic files mapping {file_name: error_message}. Raw Data Reading \u0026 Cleaning file_name (str | None) — file name of the raw data. file_path (str | None) — absolute path of the raw data. ion_mode (str) — \"positive\" (default) or \"negative\". ms_type (str | None) — \"orbitrap\", \"qtof\", \"tripletof\", or \"others\". is_centroid (bool) — whether data is centroided (True by default). file_format (str | None) — lower-case type (\"mzml\", \"mzxml\", \"mzjson\", or \"mzjson.gz\"). scan_time_unit (str) — \"minute\" (default) or \"second\". mz_lower_limit (float) — lower m/z bound (default 0.0). mz_upper_limit (float) — upper m/z bound (default 100000.0). rt_lower_limit (float) — lower RT bound in minutes (default 0.0). rt_upper_limit (float) — upper RT bound in minutes (default 10000.0). scan_levels (list[int]) — scan levels to read (default [1, 2]). centroid_mz_tol (float | None) — m/z tolerance for centroiding (0.005 by default; set None to disable centroiding). ms1_abs_int_tol (float) — MS1 absolute intensity threshold (recommend 30000 Orbitrap, 1000 QTOF). ms2_abs_int_tol (float) — MS2 absolute intensity threshold (recommend 10000 Orbitrap, 500 QTOF). ms2_rel_int_tol (float) — MS2 relative intensity to base peak (default 0.01). precursor_mz_offset (float) — m/z offset for defining MS2 range (default 2.0). Feature Detection mz_tol_ms1 (float) — MS1 m/z tolerance (default 0.01). mz_tol_ms2 (float) — MS2 m/z tolerance (default 0.015). feature_gap_tol (int) — tolerance in consecutive scans without signal inside a feature (default 10 in Params; see note below about PARAMETER_DEFAULT). batch_size (int) — parallel processing batch size (default 100). percent_cpu_to_use (float) — fraction of CPU to use (default 0.8). Feature Grouping group_features_single_file (bool) — group features within a single file (default False). scan_scan_cor_tol (float) — scan-to-scan correlation threshold (default 0.7). mz_tol_feature_grouping (float) — m/z tolerance for grouping (default 0.015). rt_tol_feature_grouping (float) — RT tolerance for grouping (default 0.1). valid_charge_states (list[int]) — allowed charge states (default [1]). Feature Alignment mz_tol_alignment (float) — m/z tolerance for alignment (default 0.01). rt_tol_alignment (float) — RT tolerance for alignment (default 0.2). rt_tol_rt_correction (float) — expected max RT shift for RT correction (default 0.5 min). correct_rt (bool) — perform RT correction (default True). scan_number_cutoff (int) — minimum non-zero scans to be aligned (default 5). detection_rate_cutoff (float) — required detection rate across QC+samples (default 0.1). merge_features (bool) — merge near-duplicate features (default True). mz_tol_merge_features (float) — m/z tolerance for merging (default 0.01). rt_tol_merge_features (float) — RT tolerance for merging (default 0.02). group_features_after_alignment (bool) — group after alignment (default True). fill_gaps (bool) — fill gaps in aligned features (default True). gap_filling_method (str) — method used in gap filling (default \"local_maximum\"). gap_filling_rt_window (float) — RT window for finding local maxima (default 0.05 min). isotope_rel_int_limit (float) — isotope intensity upper limit relative to base peak (default 1.5). Feature Annotation ms2_library_path (str | None) — path to MS2 library (.msp or .pickle); set to None if not existing. fuzzy_search (bool) — enable fuzzy search (default False). consider_rt (bool) — consider RT in MS2 matching (default False). rt_tol_annotation (float) — RT tolerance for annotation (default 0.2). ms2_sim_tol (float) — MS2 similarity threshold (default 0.7). spectral_similarity_method (str) — similarity method (default \"unweighted_entropy\"). Normalization sample_normalization (bool) — sample-wise normalization by total amount/concentration (default False). sample_norm_method (str) — method for sample normalization (default \"pqn\"). signal_normalization (bool) — feature-wise drift correction (default False). signal_norm_method (str) — drift correction method (default \"lowess\"). Statistics run_statistics (bool) — run statistical analysis (default False). Visualization plot_bpc (bool) — plot BPC chromatograms (default False). plot_ms2 (bool) — plot MS2 mirror plots (default False). plot_normalization (bool) — plot normalization results (default False). Classifier Building by_group_name (str | None) — group name for classifier training (if used). Output output_single_file (bool) — export processed single-file outputs (default False; set True during workflow prep). output_ms1_scans (bool) — export all MS1 scans to pickle for fast reloading (default False; set True during workflow prep). output_aligned_file (bool) — export aligned features (default False; set True during workflow prep). quant_method (str) — \"peak_height\" (default), \"peak_area\", or \"top_average\". Methods read_parameters_from_csv(path) Reads a CSV of key–value pairs and sets attributes. Values convertible to float are cast; otherwise, \"true\"/\"yes\" → True, \"false\"/\"no\" → False. Calls check_parameters() afterward.\nread_sample_metadata(path) Loads sample metadata from CSV. Lower-cases columns named \"is_qc\" and \"is_blank\"; converts \"yes\"/\"no\" strings to booleans (otherwise defaults both columns to False). Sorts so QC appear first and blanks last; adds VALID and ABSOLUTE_PATH columns; stores in sample_metadata.\n_untargeted_metabolomics_workflow_preparation() Prepares a project for the untargeted metabolomics workflow:\nValidates project_dir; derives standard subdirectories and creates them if missing. Ensures raw data exist in project_dir/data (currently auto-detects only .mzML and .mzXML). If sample_table.csv is missing, disables normalization/statistics and prints notices. If parameters.csv is missing, prints notices, infers (ms_type, ion_mode) from the first sample via find_ms_info, calls set_default, and enables plot_bpc. Loads sample table if present; otherwise builds from discovered file basenames. Validates presence of raw files, computes acquisition time via get_start_time, filters invalid, sorts by time, adds sequential analytical_order, and assigns batch IDs via label_batch_id. Writes project_files/sample_table_with_time.csv. Sets output toggles: output_single_file=True, output_ms1_scans=True, output_aligned_file=True. set_default(ms_type, ion_mode) For \"orbitrap\", sets ms1_abs_int_tol=30000, ms2_abs_int_tol=10000; for others, ms1_abs_int_tol=1000, ms2_abs_int_tol=500. Also sets ion_mode.\ncheck_parameters() Validates all numeric parameters against PARAMETER_RAGES. If a value is out of range, it prints a warning and resets that parameter to the value in PARAMETER_DEFAULT. If ms2_library_path does not exist, sets it to None. Casts batch_size to int.\nNote: The code refers to PARAMETER_RAGES throughout (typo intentional to match the implementation).\noutput_parameters(path, format=\"json\") Exports all parameters (except project_dir) to JSON, including \"MassCube_version\" obtained from importlib.metadata.version(\"masscube\"). Only \"json\" is supported.\n_check_raw_files_in_data_dir() Cross-references basenames from sample_metadata with files in sample_dir (currently only .mzML/.mzXML), sets VALID and populates ABSOLUTE_PATH accordingly.\nFunctions find_ms_info(file_name) Reads up to the first 200 lines of an .mzML or .mzXML file (lower-cased text) to infer:\nms_type: \"orbitrap\" if it contains \"orbitrap\"/\"q exactive\", \"tripletof\" if \"tripletof\", else \"qtof\" if contains \"tof\". ion_mode: \"positive\" or \"negative\" if mentioned. centroid: True if \"centroid spectrum\" or centroided=\"1\" present. Returns (ms_type, ion_mode, centroid).\nConstants PARAMETER_RAGES — Valid Ranges PARAMETER_RAGES = { \"mz_lower_limit\": (0.0, 100000.0), \"mz_upper_limit\": (0.0, 100000.0), \"rt_lower_limit\": (0.0, 10000.0), \"rt_upper_limit\": (0.0, 10000.0), \"centroid_mz_tol\": (0.0, 0.1), \"ms1_abs_int_tol\": (0, 1e10), \"ms2_abs_int_tol\": (0, 1e10), \"ms2_rel_int_tol\": (0.0, 1.0), \"precursor_mz_offset\": (0.0, 100000.0), \"mz_tol_ms1\": (0.0, 0.02), \"mz_tol_ms2\": (0.0, 0.02), \"feature_gap_tol\": (0, 100), \"scan_scan_cor_tol\": (0.0, 1.0), \"mz_tol_alignment\": (0.0, 0.02), \"rt_tol_alignment\": (0.0, 2.0), \"scan_number_cutoff\": (0, 100), \"detection_rate_cutoff\": (0.0, 1.0), \"mz_tol_merge_features\": (0.0, 0.02), \"rt_tol_merge_features\": (0.0, 0.5), \"ms2_sim_tol\": (0.0, 1.0) } PARAMETER_DEFAULT — Defaults Used on Reset PARAMETER_DEFAULT = { \"mz_lower_limit\": 0.0, \"mz_upper_limit\": 100000.0, \"rt_lower_limit\": 0.0, \"rt_upper_limit\": 10000.0, \"centroid_mz_tol\": 0.005, \"ms1_abs_int_tol\": 1000.0, \"ms2_abs_int_tol\": 500, \"ms2_rel_int_tol\": 0.01, \"precursor_mz_offset\": 2.0, \"mz_tol_ms1\": 0.01, \"mz_tol_ms2\": 0.015, \"feature_gap_tol\": 30, \"scan_scan_cor_tol\": 0.7, \"mz_tol_alignment\": 0.01, \"rt_tol_alignment\": 0.2, \"scan_number_cutoff\": 5, \"detection_rate_cutoff\": 0.1, \"mz_tol_merge_features\": 0.01, \"rt_tol_merge_features\": 0.05, \"ms2_sim_tol\": 0.7 } Discrepancy note: In the Params initializer, feature_gap_tol defaults to 10, whereas PARAMETER_DEFAULT[\"feature_gap_tol\"] is 30. If check_parameters() resets values (due to range violations), it will use the 30 from PARAMETER_DEFAULT.\nAdditional Notes \u0026 Gotchas Raw file discovery in workflow prep and path validation currently recognizes only .mzML and .mzXML files, even though file_format supports \"mzjson\"/\"mzjson.gz\" in principle. group_features_after_alignment is True in the initializer (despite an inline comment that mentions False), and gap_filling_method is the string \"local_maximum\". If ms2_library_path points to a non-existent path, it is automatically set to None during parameter checking. Exported JSON via output_parameters() omits project_dir and includes a \"MassCube_version\" field. The code consistently uses the identifier PARAMETER_RAGES (with a G), and method docs reflect that spelling. This documentation mirrors the current params.py implementation.","attributes#Attributes":"","classes#Classes":"","constants#Constants":"","functions#Functions":"","methods#Methods":"","overview#Overview":"","params#\u003ccode\u003eparams\u003c/code\u003e":""},"title":"params"},"/docs/api/raw_data_utils/":{"data":{"":"","classes#Classes":"MSData A class that models a single raw MS data file and processes the raw data.\nAttributes:\nscans (list): A list of Scan objects for mass spectra. ms1_idx (list): Scan indexes of MS1 spectra. ms1_time_arr (list): Time of MS1 scans. ms2_idx (list): Scan indexes of MS2 spectra. params (Params object): A Params object that contains all parameters. base_peak_arr (list): Base peak chromatogram, [[m/z, intensity], ...]. features (list): A list of features. feature_mz_arr (numpy array): m/z of all ROIs. Methods:\nread_raw_data(self, file_name, params=None, scan_levels=[1,2], centroid_mz_tol=0.005, ms1_abs_int_tol=None, ms2_abs_int_tol=None, ms2_rel_int_tol=0.01, precursor_mz_offset=2): Reads raw data from an MS file. extract_scan_mzml(self, scans): Extracts all scans from an mzML file. extract_scan_mzxml(self, scans): Extracts all scans from an mzXML file. drop_ms1_ions_by_intensity(self, int_tol): Drops ions in all MS1 scans by intensity threshold. detect_features(self): Runs feature detection. segment_features(self, iteration=2): Segments features by edge detection. summarize_features(self, cal_g_score=True, cal_a_score=True): Processes features to calculate summary statistics. allocate_ms2_to_features(self, mz_tol=0.015): Allocates MS2 scans to ROIs. drop_features_without_ms2(self): Drops features without MS2 scans. drop_features_by_length(self, length=5): Drops features by length. drop_isotope_features(self): Drops features annotated as isotopes. drop_in_source_fragment_features(self): Discards in-source fragments. plot_bpc(self, time_range=None, label_name=True, output_dir=None): Plots the base peak chromatogram. output_single_file(self, output_path=None): Generates a report for features in csv format. get_eic_data(self, target_mz, target_rt=None, mz_tol=0.005, rt_tol=0.3, rt_range=None): Gets the EIC data of a target m/z. plot_eics(self, target_mz_arr, target_rt=None, mz_tol=0.005, rt_tol=0.3, rt_range=None, output_file_name=None, show_target_rt=True, ylim: list=None, return_eic_data=False): Plots multiple EICs in a single plot. find_ms2_by_mzrt(self, mz_target, rt_target, mz_tol=0.01, rt_tol=0.3, return_best=False): Finds MS2 scan by precursor m/z and retention time. find_feature_by_mzrt(self, mz_target, rt_target=None, mz_tol=0.01, rt_tol=0.3): Finds feature by precursor m/z and retention time. find_ms1_scan_by_rt(self, rt_target): Finds the nearest n MS1 scan by retention time. correct_retention_time(self, f): Corrects retention time. plot_feature(self, feature_idx, mz_tol=0.005, rt_range=[0, np.inf], rt_window=None, output=False): Plots EIC of a ROI. Scan A class that models a single mass spectrum scan.\nAttributes:\nlevel (int): Level of mass spectrum. id (int): Scan ID. scan_time (float): Scan time. signals (numpy array): m/z and intensity signals. precursor_mz (float): Precursor m/z. ","functions#Functions":"clean_signals clean_signals(signals, mz_range=None, intensity_range=None)\nCleans signals by removing ions outside specified m/z and intensity ranges.\nParameters:\nsignals (numpy array): m/z and intensity signals. mz_range (list): m/z range [start, end]. intensity_range (list): Intensity range [min, max]. Returns:\ncleaned_signals (numpy array): Cleaned m/z and intensity signals. centroid_signals centroid_signals(signals, mz_tol)\nCentroids m/z and intensity signals.\nParameters:\nsignals (numpy array): m/z and intensity signals. mz_tol (float): m/z tolerance. Returns:\ncentroided_signals (numpy array): Centroided m/z and intensity signals. segment_feature segment_feature(feature, peak_height_tol, distance)\nSegments a feature by edge detection.\nParameters:\nfeature (Feature object): A feature. peak_height_tol (int): Peak height tolerance. distance (int): Distance. Returns:\nsegmented_features (list): Segmented features. detect_features detect_features(ms_data)\nDetects features in MS data.\nParameters:\nms_data (MSData object): An MSData object. Returns:\nfeatures (list): Detected features. find_best_ms2 find_best_ms2(ms2_seq)\nFinds the best MS2 scan with the highest total intensity.\nParameters:\nms2_seq (list): A list of MS2 scans. Returns:\nbest_ms2 (Scan object): The best MS2 scan. ","overview#Overview":"The raw_data_utils module provides classes and functions for reading and processing raw mass spectrometry (MS) data files. The module supports reading mzML, mzXML, mzjson, and compressed mzjson files. The main class in this module is MSData, which models a single MS file and processes the raw data. The module also includes helper functions for cleaning MS/MS spectra, centroiding m/z and intensity sequences, and extracting EIC data."},"title":"raw_data_utils"},"/docs/api/stats/":{"data":{"":"Documentation is under construction. Please check our source code directly for the latest updates."},"title":"stats"},"/docs/api/utils_functions/":{"data":{"":"","functions#Functions":"generate_sample_table generate_sample_table(path=None, output=True)\nGenerate a sample table from the mzML or mzXML files in the specified path. The stucture of the path should be:\npath ├── data │ ├── sample1.mzml │ ├── sample2.mzml │ └── ... └── ... Parameters:\npath : str Path to the main directory that contains a subdirectory ‘data’ with mzML or mzXML files. output : bool If True, output the sample table to a csv file. Return:\nsample_table : pandas DataFrame A DataFrame with two columns: ‘Sample’ and ‘Groups’. Output:\nsample_table.csv : csv file A csv file with two columns: ‘Sample’ and ‘Groups’ in the specified path. get_timestamps get_timestamps(path=None, output=True)\nGet timestamps for individual files and sort the files by time. The stucture of the path should be:\npath ├── data │ ├── sample1.mzml │ ├── sample2.mzml │ └── ... └── ... Parameters:\npath : str Path to the main directory that contains a subdirectory ‘data’ with mzML or mzXML files. output : bool If True, output the timestamps to a txt file with two columns: ‘file_name’ and ‘aquisition_time’. Return:\nfile_times : list A list of tuples with two elements: ‘file_name’ and ‘aquisition_time’. Output:\ntimestamps.txt : txt file A txt file with two columns: ‘file_name’ and ‘aquisition_time’ in the specified path. formula_to_mz formula_to_mz(formula, adduct, charge)\nCalculate the m/z value of a molecule given its chemical formula, adduct and charge.\nParameters:\nformula : str Chemical formula of the molecule. adduct : str Adduct of the molecule. The first character should be ‘+’ or ‘-’. In particular, for adduct like [M-H-H2O]-, use ‘-H3O’ or ‘-H2OH’. charge : int Charge of the molecule. Positive for cations and negative for anions. Returns:\nmz : float The m/z value of the molecule. Examples:\nformula_to_mz(\"C6H12O6\", \"+H\", 1) # 181.070665 formula_to_mz(\"C9H14N3O8P\", \"-H2OH\", -1) # 304.034010 get_start_time get_start_time(file_name)\nFunction to get the start time of the raw data.\nParameters:\nfile_name : str Absolute path of the raw data. extract_signals_from_string extract_signals_from_string(ms2)\nExtract signals from MS2 spectrum in string format.\nParameters:\nms2 : str MS2 spectrum in string format. Format: “mz1;intensity1|mz2;intensity2|…” Returns:\npeaks : numpy.array Peaks in numpy array format: [[mz1, intensity1], [mz2, intensity2], …] convert_signals_to_string convert_signals_to_string(signals)\nConvert peaks to string format.\nParameters:\nsignals : numpy.array MS2 signals organized as [[mz1, intensity1], [mz2, intensity2], …] Returns:\nstring : str Converted signals in string format. Format: “mz1;intensity1|mz2;intensity2|…” ","overview#Overview":"The utils_functions module contains utility functions that are commonly used in the data processing and analysis of mass spectrometry data. The module includes functions for generating a sample table, getting timestamps for individual files, converting chemical formulas to m/z values, extracting signals from MS2 spectrum in string format, and converting signals to string format."},"title":"utils_functions"},"/docs/api/visualization/":{"data":{"":"This documentation is under construction. Please check our source code directly for the latest updates."},"title":"visualization"},"/docs/api/workflows/":{"data":{"":"","functions#Functions":"process_single_file process_single_file(file_name, params=None, segment_feature=True, group_features=False, evaluate_peak_shape=True, annotate_ms2=False, ms2_library_path=None, output_dir=None)\nPerforms untargeted feature detection for a single file.\nParameters:\nfile_name (str): Path to the raw file. params (Params object, optional): Parameters for feature detection. If None, the default parameters are used based on the type of mass spectrometer. segment_feature (bool, default True): Whether to segment the feature to peaks for distinguishing possible isomers. group_features (bool, default False): Whether to group features by isotopes, adducts, and in-source fragments. evaluate_peak_shape (bool, default True): Whether to evaluate the peak shape by calculating noise score and asymmetry factor. annotate_ms2 (bool, default False): Whether to annotate MS2 spectra. ms2_library_path (str, optional): Path to the MS2 library. output_dir (str, optional): The output directory for the single file. If None, the output is saved to the same directory as the raw file. Returns:\nd (MSData object): An MSData object containing the processed data. Usage:\n# use default parameters for processing a single file result = feature_detection(\"sample.mzML\") untargeted_metabolomics_workflow untargeted_metabolomics_workflow(path=None, return_results=False, only_process_single_files=False, return_params_only=False)\nThe untargeted metabolomics workflow.\nParameters:\npath (str, optional): The working directory. If None, the current working directory is used. return_results (bool, default False): Whether to return the results. only_process_single_files (bool, default False): Whether to only process the single files. return_params_only (bool, default False): Whether to return the parameters only. Returns:\nfeatures (list): A list of features. params (Params object): Parameters for the workflow. Usage:\nuntargeted_metabolomics_workflow(path=\"/path/to/project\") batch_file_processing batch_file_processing(path=None, segment_feature=True, group_features=False, evaluate_peak_shape=True, annotate_ms2=True, ms2_library_path=None, cpu_ratio=0.8, batch_size=100)\nProcess single files using default parameters. This function is useful for batch processing of multiple files. Files from different ion modes are allowed, but parameters cannot be specified for individual files, and default parameters are used.\nParameters:\npath (str, optional): The working directory. If None, the current working directory is used. segment_feature (bool, default True): Whether to segment the feature to peaks for distinguishing possible isomers. group_features (bool, default False): Whether to group features by isotopes, adducts, and in-source fragments. evaluate_peak_shape (bool, default True): Whether to evaluate the peak shape by calculating noise score and asymmetry factor. annotate_ms2 (bool, default True): Whether to annotate MS2 spectra. ms2_library_path (str, optional): The path to the MS2 library. cpu_ratio (float, default 0.8): The percentage of CPU cores to use. batch_size (int, default 100): The number of files to process in each batch. run_evaluation run_evaluation(path=None, zscore_threshold=-2)\nEvaluate the run and report the problematic files. The path to the project directory should be organized as follows:\npath ├── single_files │ ├── sample1.txt │ ├── sample2.txt │ └── ... └── ... where single_files contains the processed files in txt format.\nParameters:\npath (str, optional): Path to the project directory. zscore_threshold (float, default -2): The threshold of z-score for detecting problematic files. ","overview#Overview":"This module provides premade data processing workflows for untargeted metabolomics analysis. The workflows include feature detection, alignment, annotation, normalization, and statistical analysis. The module also includes functions for batch file processing and evaluating the data quality of raw files."},"title":"workflows"},"/docs/installation/":{"data":{"":"","install-_masscube_#Install \u003cem\u003emasscube\u003c/em\u003e":"Install Python Visit the official Python website to download Python. Python 3.11 is recommended.\nDownload Python 3.11.7 Download Python 3.11.7. ❗ Add Python to PATH during installation: check the box ☑️ Add Python 3.X to PATH. Install masscube masscube is a Python package that can be installed using pip. Open terminal and run\npip install masscube To update the package to the latest version, open terminal and run\npip install masscube --upgrade To only install masscube for the current user, add the --user flag. This is to avoid permission issues when installing packages globally (e.g. you are not an administrator).\npip install --user masscube Dependencies will be automatically installed. Consider creating a virtual environment if you’re working with Python on multiple projects.\nDependencies dependencies = [ \"numpy\u003e=1.24\", \"pandas\u003e=2.2.1\", \"pyteomics==4.6.3\", \"scipy\u003e=1.10.1\", \"tqdm\u003e=4.66.1\", \"lxml\u003e=4.9.3\", \"matplotlib\u003e=3.8.2\", \"ms_entropy==1.2.2\", \"scikit-learn\u003e=1.3.2\", \"statsmodels\u003e=0.14.2\", \"umap-learn\u003e=0.5.7\", ] ","install-python#Install Python":""},"title":"Installation"},"/docs/plans/":{"data":{"":"We are working on the following features and improvements and welcome contributions from the community.\nTargeted metabolomics workflows\nMore data normalization algorithms and evaluation metrics\nAlgorithms and workflows for data-independent acquisition (DIA) data.\nTools for LC-MS experimental design and instrumental parameters optimization.\nMS imaging data processing"},"title":"Plans for development"},"/docs/quickstart/":{"data":{"":"Let’s dive into the untargeted metabolomics workflow, designed to simplify and streamline untargeted metabolomics analysis. This powerful workflow delivers comprehensive results with just a single command.\nIf you haven’t installed MassCube yet, be sure to follow the installation guide before proceeding.","the-masscube-untargeted-metabolomics-workflow#The MassCube untargeted metabolomics workflow":"One command to process untargeted metabolomics data (Fig. 1).\nFig. 1. The MassCube untargeted metabolomics workflow Input (4 items) You will need data, sample table, parameters, and MS/MS database to run the workflow.\nIn your project folder (e.g. my_project), you need to prepare the following components:\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... |── sample_table.csv └── parameters.csv data folder: a file folder containing all raw LC-MS data in .mzML or .mzXML format. It’s mandatory. I don’t know how to convert my files.\nsample_table.csv file: a csv file to claim quality control samples, blank samples and biological groups. Use MassCube to generate a sample table and then edit. Set yes in the ‘is_blank’ column for blank samples, and yes in the ‘is_qc’ column for quality control (QC) samples. If not provided, normalization and statistical analysis will not be applied.\nparameters.csv file: Set and download a parameter file. If not provided, the default parameters will be applied, but annotation will not be performed since the file location of the MS/MS database is not provided.\nMS/MS database: Download a MS/MS database for MS/MS spectral annotation. You may also prepare your own MS/MS database.\nUsing MassCube 1.0 or 1.1 For MassCube 1.1 or earlier, please use the old MS/MS databases Extra component for annotation:\nmzrt_list.csv file: a csv file to provide the m/z and retention time for feature annotation. It was designed to annotate features using retention time (e.g. internal standards). A template can be downloaded from here. It’s optional. Data Preparation Demo data Processing In the project folder, open a terminal and run the following command:\nuntargeted-metabolomics How to open a terminal Make sure the terminal directory is set to the project folder. For Windows user and MacOS user Output After the processing, you will find the following files and folders in the project folder:\nproject/ ├── data ├── sample_table.csv ├── parameters.csv ├── mzrt_list.csv (optional) ├── project_files │ ├── data_processing_metadata_[DATE].pkl │ ├── features.msp │ └── ... ├── aligned_feature_table.txt |── normalized_feature_table.txt (if signal normalization applied) ├── single_files │ ├── sample1.txt │ ├── sample2.txt │ └── ... ├── chromatograms │ ├── sample1.png │ ├── sample2.png │ └── ... ├── ms2_matching │ ├── compound1.png │ ├── compound2.png │ └── ... ├── statistical_analysis ├── normalization results | ├──feature_0_normalization.png | ├──feature_1_normalization.png | └── ... ├── ... project_files folder: a folder containing the metadata file for data processing. aligned_feature_table.txt file: feature table after alignment (if applied). single_files folder: a folder containing the feature table for each sample. chromatograms folder: a folder containing the chromatogram for each sample. ms2_matching folder: a folder containing the MS/MS matching for each annotated compound. statistical_analysis folder: a folder containing the statistical analysis results. normalization results folder: a folder containing the normalization results (if applied). "},"title":"Quick start"},"/docs/untargeted_metabolomics/":{"data":{"":"Mass spectrometry data processing is highly application-focused, and MassCube is designed to support this by integrating individual functions and modules into workflows. These pre-defined workflows simplify and accelerate data processing and analysis for specific applications.\nWondering how to contribute to the workflows? Please refer to the contribution guide."},"title":"Untargeted metabolomics"},"/docs/untargeted_metabolomics/convert_ms_data/":{"data":{"":"","#":"Raw mass spectrometry data need to be converted to centroid mzML or mxXML format for MassCube data processing.\nWe recommend to use MSConvert for file conversion.\nVisit the official website to download ProteoWizard and install MSConvert.\nFig. 1. MSConvert GUI Step 1. Set options Check the boxes as shown in Fig. 1.\n⚠️ Do NOT check Use zlib compression. Step 2. Set the peak picking filter Step 3. Add the peak picking filter Step 4. Browse and load files Step 5. Start conversion By default, the converted files will be saved in the same directory as the raw files."},"title":"Convert raw MS data"},"/docs/untargeted_metabolomics/database/":{"data":{"":"","download-a-msms-database#Download a MS/MS database":"You can download a combined public MS/MS databases (including MassBank, GNPS, MS-DIAL and MassBank EU). The database is in .pkl format for faster loading speed in masscube.","introduction#Introduction":"A MS/MS database contains m/z, MS/MS spectrum, retentiont time and other information of known compounds. It will be used for compound annotation. You can either download a MS/MS database or prepare your own database.\nMassCube uses unweighted entropy similarity for spectral matching based on the ms_entropy Python package.","prepare-a-database-for-advanced-users#Prepare a database (for advanced users)":"Three formats are supported for the database: pickle, msp, and json.\n🌐 We highly recommend generating the pickle (.pkl) format MS/MS database. MSP format This is the most commonly used database format. Each block is one compound separated by a blank line.\nℹ️ You must provide the MSP file with the keys examplified below. NAME: L-PHENYLALANINE # name PRECURSORMZ: 166.0860 # precursor m/z PRECURSORTYPE: [M+H]+ # adduct IONMODE: positive # ion mode RETENTIONTIME: 3.31 # retention time in minutes CCS: 136.82 # collision cross section FORMULA: C9H11NO2 # chemical formula SMILES: C1=CC=C(C=C1)C[C@@H](C(=O)O)N # SMILES string INCHIKEY: COLNVLDHVKWLRT-QMMMGPOBSA-N # InChIKey INSTRUMENTTYPE: LC-ESI-QFT # instrument type COLLISIONENERGY: 35.0 eV # collision energy Num Peaks: 7 # number of fragment signals 103.054\t15 # m/z and intensity of fragment signals 107.049\t14 120.081\t1000 121.084\t16 131.049\t41 149.059\t16 166.086\t56 NAME, PRECURSORMZ, PRECURSORTYPE, IONMODE, and fragment signals are mandatory.\nPickle format A .pkl database is a FlashEntropySearch object that contains the MS2 database. ms_entropy version 1.3.4 is highly recommended to generate this object (other versions may not work). Here is an example of how to generate a .pkl database from a msp file:\nfrom masscube.annotation import index_msp_to_pkl # it will output a database.pkl file in the same folder index_msp_to_pkl('database.msp') Please refer to the source code of index_msp_to_pkl for more details.\nJSON format A JSON database is a list of dictionaries. Each dictionary represents a compound with the following keys:\ndic = { \"name\": \"L-PHENYLALANINE\", # name \"precursor_mz\": 166.086013793945, # precursor m/z \"precursor_type\": \"[M+H]+\", # adduct \"ion_mode\": \"Positive\", # ion mode \"retention_time\": \"3.30520009994507\", # retention time in minutes \"ccs\": \"136.819671630859\", # collision cross section \"formula\": \"C9H11NO2\", # chemical formula \"smiles\": \"C1=CC=C(C=C1)C[C@@H](C(=O)O)N\", # SMILES string \"inchikey\": \"COLNVLDHVKWLRT-QMMMGPOBSA-N\", # InChIKey \"instrument_type\": \"LC-ESI-QFT\", # instrument type \"collision_energy\": \"35.0 eV\", # collision energy \"num peaks\": \"7\", # number of fragment signals \"peaks\": [ # fragment signals [\"103.054\", \"15\"], [\"107.049\", \"14\"], [\"120.081\", \"1000\"], [\"121.084\", \"16\"], [\"131.049\", \"41\"], [\"149.059\", \"16\"], [\"166.086\", \"56\"] ] } To index a JSON database, you can use the index_json_to_pkl function:\nfrom masscube.annotation import index_json_to_pkl index_json_to_pkl('database.json', 'database.pkl') Please refer to the source code of index_json_to_pkl for more details."},"title":"About MS/MS database"},"/docs/untargeted_metabolomics/generate_sample_table/":{"data":{"":"In the project folder, open a terminal and run the following command:\ngenerate-sample-table Your project folder should include a subfolder named data that contains the raw LC-MS data files in mzML or mzXML format.\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... |── ... Set yes in the ‘is_blank’ column for blank samples, and yes in the ‘is_qc’ column for quality control (QC) samples. You can add more columns to the sample table to claim biological groups or other information. For example, you can add a column named ’treatment’ to claim the treatment of each sample like drug A, drug B, or control. Example:\nname is_blank is_qc treatment sample1 no no drug A sample2 no no drug B sample3 no no control QC1 no yes NA QC2 no yes NA blank1 yes no NA blank2 yes no NA "},"title":"Make a sample table"},"/docs/untargeted_metabolomics/parameters/":{"data":{"":"","#":"Download the default parameters. Make sure to check and adjust the following three key parameters:\nion_mode Set to “positive” or “negative”.\nms1_abs_int_tol You may use 30000 for Orbitrap data, and 1000 for TOF data.\nms2_library_path The absolute path to the MS/MS database file (e.g. D:/databases/ms2_library.mzML).","key-parameters#Key parameters":"Here we summarized six most important parameters in masscube for untargeted metabolomics data processing:\nmz_tol_ms1: the mass tolerance for MS1 feature detection. 0.005-0.01 Da is recommended. ms1_abs_int_tol: the intensity tolerance for MS signals. 1000 is recommended for TOF data, and 30000 is recommended for Orbitrap data. mz_tol_alignment: the mass tolerance for feature alignment. 0.01-0.015 Da is recommended. rt_tol_alignment: the RT tolerance for feature alignment. 0.1-0.3 min is recommended. ms2_sim_tol: the threshold for MS/MS similarity score. 0.7-0.8 is recommended. ms2_library_path: the MS/MS library for MS/MS annotation. ","more-about-parameters#More about parameters":"Explanation of the commonly used parameters for the untargeted-metabolomics workflow can be found here.\nFor more tunable parameters, please refer to the API documentation or the source code in the params module."},"title":"Set parameters"},"/docs/untargeted_metabolomics/the_workflow/":{"data":{"":"","explainations-of-the-workflow#Explainations of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def untargeted_metabolomics_workflow(path=None, return_results=False, only_process_single_files=False, return_params_only=False): \"\"\" The untargeted metabolomics workflow. See the documentation for details. Parameters ---------- path : str The working directory. If None, the current working directory is used. return_results : bool Whether to return the results. Default is False. only_process_single_files : bool Whether to only process the single files. Default is False. return_params_only : bool Whether to return the parameters only. Default is False. Returns ------- features : list A list of features. params : Params object Parameters for the workflow. \"\"\" ... Step 1. Define or load parameters Parameters are critical for MS data processing. However, setting parameters are often challenging, especially for beginners or scientists who are not familiar with the MS data.\nmasscube automatically read the MS data and apply the corresponding default parameters. Users can also customize the parameters by providing a parameter file.\nStep 2. Load sample table and organize data A sample table is used to claim the name of samples and their groups. In most metabolomics studies, quality control samples and blank samples are included. masscube automatically apply normalization and statistical analysis if the sample table is provided.\nStep 3. Single file processing Individual files are processed for feature detection, which envolves the detection of peak apex, edges, area, and related MS/MS spectra. By default, features are not grouped in this step to reduce computational cost, and grouping will be performed in the alignment step.\nTo accelerate the processing, masscube supports parallel computing for multiple files. By default, the number of threads is set to be the 80% of the total CPU cores so that the computer can still be used for other tasks.\nTo control the memory usage, the files are processed in batches. The default batch size is 100.\nStep 4. Feature alignment Feature alignment aims to match the same feature across different samples. The alignment is based on the mass-to-charge ratio and retention time. The mass tolerance and retention time tolerance are critical for the alignment. It also includes the annotation of isotopes, charge states, adducts, and in-source fragments.\nStep 5. Gap filling Gap filling is critical for the downstream statistical analysis, and missing values are treated by forced peak detection.\nStep 6. MS/MS annotation Compound annotation was performed by matching the experimental MS/MS spectra with the MS/MS library. The MS/MS similarity score is generated to indicate the confidence of the annotation.\nFlash entropy search is used to accelerate the annotation. masscube also provides analog search (i.e. hybrid search) for unknown discovery.\nStep 7. Normalization Two types of normalization could be needed in metabolomics to address the systematic signal drifts and the sample-to-sample variation (i.e. total amount/concentration difference). masscube provides multiple post-acquisition normalization algorithms to address the normalization issue.\nStep 8. Statistical analysis Univariate and multivariate statistical analysis will be performed if sample table is provided. The results will be saved in the statistics folder.\nStep 9. Data visualization Users can choose to plot the base peak chromatogram (BPC) to verify possible bad injections or outliers. The MS/MS matching plots are generated for the annotated compounds. PCA plots are generated for the statistical analysis.","how-to-use#How to use":"Please refer to the quick start guide.","introduction#Introduction":"Data processing is critical for metabolomics studies. A series of steps are required to process the raw data to generate biological hypothesis that can be further validated.\nThe MassCube untargeted metabolomics workflow aims to address the burdens in mass spectrometry-based metabolomics data processing. It integrates metadata curation, feature detection, evaluation, alignment, annotation, and statistical analysis to provide users with a comprehensive view of the data."},"title":"The workflow"},"/docs/visualization/":{"data":{"":"Examples of data visualization in MassCube."},"title":"Visualization"},"/docs/visualization/chromatogram/":{"data":{"":"In case you need a demo data file.","base-peak-chromatogram#Base peak chromatogram":"Visualize the base peak chromatogram for a raw file:\nfrom masscube import read_raw_file_to_obj file_name = \"demo_data.mzML\" # load the raw file d = read_raw_file_to_obj(file_name) # read the raw file into a MassCube object # plot the base peak chromatogram d.plot_bpc() Example output 1 Set more parameters to customize the plot:\nfrom masscube import read_raw_file_to_obj file_name = \"demo_data.mzML\" # load the raw file d = read_raw_file_to_obj(file_name) # read the raw file into a MassCube object # plot the base peak chromatogram time_range = (1, 2) # set the time range for the x-axis label_name = False # do not show file name in the plot output_dir = None # set the absolute path to save the plot, or None to show it d.plot_bpc( time_range=time_range, label_name=label_name, output_dir=output_dir ) Example output 2 ","extracted-ion-chromatogram#Extracted ion chromatogram":"Plot the extracted ion chromatogram (EIC) for a specific m/z value:\nfrom masscube import read_raw_file_to_obj d = read_raw_file_to_obj(\"demo_data.mzML\") # parameters for extracting EICs target_mz_arr = 138.0521 # m/z value of the target ion. You can also make a list of m/z values, e.g. [138.0521, 150.1234] for # overlapping EICs target_rt = 1.774 # target retention time in minutes. Set it to None to plot the whole retention time range mz_tol = 0.005, # m/z tolerance in Da rt_tol = 0.3, # retention time tolerance in minutes rt_range = (1,2), # custom retention time range, e.g. (1, 2) to plot EICs in the range of 1 to 2 minutes output_file_name = None, # set the absolute path of the output file, or None to show the plot show_target_rt = True, # dashed blue line at the target retention time ylim = None, # custom y-axis limits, e.g. [0, 10000] return_eic_data = False # return the EIC data as a pandas DataFrame # If True, a list of EIC data: [[eic_time_arr, eic_signals, eic_scan_idx], ...] will be returned # example 1 d.plot_eics(target_mz_arr=target_mz_arr, target_rt=target_rt) # example 2 d.plot_eics(target_mz_arr=target_mz_arr, target_rt=target_rt, mz_tol=mz_tol, rt_tol=rt_tol, rt_range=rt_range, output_file_name=None, show_target_rt=True, ylim=None, return_eic_data=False) Example output 1 Example output 2 "},"title":"Chromatograms"},"/docs/visualization/ms2/":{"data":{"":"","mirror-plot#Mirror plot":"Compare a pair of MS/MS spectra using a mirror plot:\nfrom masscube.annotation import extract_signals_from_string from masscube.visualization import mirror_ms2 precursor_1 = 260.056 precursor_2 = 180.1019 ms2_1 = \"115.0538;0.1441|117.0689;0.3008|145.064;0.2618|163.0741;0.1822|180.1004;0.1111\" ms2_2 = \"79.0542;0.0034|91.0542;0.0308|105.0699;0.01|107.0491;0.0075|115.0542;0.0599|117.0699;0.3268|119.0491;0.0066|123.0441;0.0046|127.0542;0.0267|133.0648;0.0052|135.0661;0.0213|137.0597;0.0277|145.0648;0.3076|148.0519;0.0035|151.0754;0.021|163.0754;0.1376\" signals1 = extract_signals_from_string(ms2_1) # convert string to 2D numpy array signals2 = extract_signals_from_string(ms2_2) # convert string to 2D numpy array annotation = \"Salsolinol\" similarity = 0.84 mirror_ms2(precursor_1, precursor_1, signals1, signals2, annotation=annotation, score=similarity) ms2_1 and ms2_2 are MS/MS spectra in the format “m/z;intensity” pairs separated by “|”. You can copy them directly from the MS2 (experimental MS/MS) and matched_MS2 (database MS/MS) columns in the aligned_feature_table generated by the untargeted-metabolomics command.\nexample output "},"title":"MS/MS spectra"},"/docs/visualization/scan/":{"data":{"":"In case you need a demo data file.","visualize-a-single-ms1-or-msms-scan#Visualize a single MS1 or MS/MS scan":"Plot by scan index:\nfrom masscube import read_raw_file_to_obj d = read_raw_file_to_obj(\"demo_data.mzML\") # by index scan_index = 10 # index of the scan to visualize scan = d.scans[scan_index] # get the scan object # example 1 scan.plot_scan() Example output 1 Plot the scan by index:\nPlot MS/MS scans by searching for a specific m/z value and retention time:\nfrom masscube import read_raw_file_to_obj d = read_raw_file_to_obj(\"demo_data.mzML\") # by m/z and retention time target_mz_arr = 138.0521 # m/z value of the precursor ion. target_rt = 1.774 # target retention time in minutes. Set it to None to plot the whole retention time range mz_tol = 0.005, # m/z tolerance in Da rt_tol = 0.3, # retention time tolerance in minutes # search all available MS/MS scans scans = d.find_ms2_by_mzrt(target_mz_arr, target_rt, mz_tol=0.005, rt_tol=0.3) # example 2 for scan in scans: scan.plot_scan() Example output 2 The first MS/MS scan by m/z and retention time:\nThe second MS/MS scan by m/z and retention time:"},"title":"MS scans"}}