{"/about/":{"data":{"":"The MassCube project is developed by Dr. Huaxu Yu, a postdoctoral researcher in the Prof. Oliver Fiehn’s lab at the University of California, Davis.","contact#Contact":"Please contact us for any questions or suggestions. We welcome contributions to the documentation, code, and workflows.\nCorresponding author: Oliver Fiehn: ofiehn@ucdavis.edu\nDeveloper and maintainer: Huaxu Yu: hxuyu@ucdavis.edu; yhxchem@outlook.com","teams#Teams":"Our teams are organized as follows:\nCode and software development Documentation and website Researcher team for testing and validation Labs and researchers interested in collaborating with us are welcome to contact us. Now we have the following labs working together:\nFiehn Lab Huan Lab "},"title":"About Us"},"/contribute/":{"data":{"":"We welcome contributions to the code, workflows, and documentation.\nCorresponding author: Oliver Fiehn: ofiehn@ucdavis.edu\nDeveloper and maintainer: Huaxu Yu: hxuyu@ucdavis.edu; yhxchem@outlook.com"},"title":"Contribute"},"/docs/":{"data":{"":"Hello! Welcome to the MassCube documentation!\nDate: 2024-08-30 Version: 1.0.16","features#Features":" Open-source: Free for non-commercial use.\nModular design: Easily extendable functionalities.\nUser-friendly: Command-line interface (CLI) for easy data processing.\nScalable: Efficient and memory-friendly handling of large-scale metabolomics data.\nReproducible: Metadata tracking for recording parameters, dependencies, and module order.\nVisualization: Tools for intuitive data exploration and publication-quality figure creation.","getting-started#Getting Started":" Installation Quick Start ","what-is-masscube#What is MassCube?":"MassCube is an open-source computing library in Python that offers a flexible infrastructure for data processing and method development in mass spectrometry-based chemical analysis."},"title":"Documentation"},"/docs/algorithms/":{"data":{"":"masscube provides fundemental and novel algorithms for mass spectrometry data processing. Please check our paper for details."},"title":"Algorithms"},"/docs/api/":{"data":{"":"All the functions and objects in masscube are documented in the API reference. MassCube includes 16 modules developed to handle a wide range of data processing tasks, with fundamental objects specifically defined for MS data, particularly data acquired from LC-MS."},"title":"APIs"},"/docs/api/alignment/":{"data":{"":"This module provides functionality for aligning metabolic features from different samples in mass spectrometry data. Isotopes and in-source fragments are not considered in the alignment process.","classes#Classes":"Feature A class that models a feature in mass spectrometry data, typically defined by a unique pair of m/z and retention time.\nAttributes:\nid (int): Index of the feature. reference_file (str): The reference file for the feature. mz (float): m/z value. rt (float): Retention time. highest_intensity (float): The highest peak height from individual files. best_ms2 (str): The best MS2 spectrum. gaussian_similarity (float): Gaussian similarity score. noise_level (float): Noise level. asymmetry_factor (float): Asymmetry factor. fill_percentage (float): Fill percentage across samples. charge_state (int): Charge state (default 1). is_isotope (bool): Indicates if the feature is an isotope. isotopes (list): List of isotopes associated with the feature. is_in_source_fragment (bool): Indicates if the feature is an in-source fragment. adduct_type (str): Adduct type. annotation (str): Annotation of the feature. search_mode (str): Search mode ('identity search', 'hybrid search', 'mzrt_search'). formula (str): Molecular formula. similarity (float): Similarity score (0-1). matched_peak_number (int): Number of matched peaks. smiles (str): SMILES notation. inchikey (str): InChIKey notation. matched_ms2 (str): Matched MS2 spectrum. mz_seq (numpy array): m/z values from individual files. rt_seq (numpy array): Retention time values from individual files. peak_height_seq (numpy array): Peak heights from individual files. peak_area_seq (numpy array): Peak areas from individual files. ms2_seq (list): List of best MS2 spectra from individual files. detected_seq (numpy array): Boolean array indicating detection in individual files. roi_id_seq (numpy array): ROI IDs from individual files. fold_change (float): Fold change value. t_test_p (float): t-test p-value. adjusted_t_test_p (float): Adjusted t-test p-value. Methods:\n__init__(self, file_number=1): Initializes a Feature object. calculate_mzrt(self): Calculates the m/z and retention time of the feature by averaging detected values. This documentation should serve as a comprehensive guide for understanding and using the code. You can further enhance it by adding specific examples, diagrams, or more in-depth explanations if needed.","functions#Functions":"feature_alignment(path, parameters, drop_by_fill_pct_ratio=0.1)\nAligns features from individual files (.txt) based on m/z and retention time.\nParameters:\npath (str): The path to the feature tables. parameters (Params object): The parameters used for alignment, including tolerances and correction settings. drop_by_fill_pct_ratio (float): The threshold for dropping features based on fill percentage (default 0.1). Returns:\nfeature_table (DataFrame): The aligned feature table. gap_filling(features, parameters, mode='forced_peak_picking')\nFills the gaps in the aligned feature table using specified strategies.\nParameters:\nfeatures (list): The aligned features. parameters (Params object): The parameters used for gap filling. mode (str): The mode of gap filling ('forced_peak_picking' or '0.1_min_intensity'). Returns:\nfeatures (list): The aligned features with filled gaps. output_feature_table(feature_table, output_path)\nOutputs the aligned feature table to a specified file.\nParameters:\nfeature_table (DataFrame): The aligned feature table. output_path (str): The path where the aligned feature table will be saved. retention_time_correction(mz_ref, rt_ref, mz_arr, rt_arr, rt_max=50, mode='linear_interpolation', mz_tol=0.015, rt_tol=2.0, found_marker_ratio=0.4, return_model=False)\nCorrects retention times for feature alignment using selected anchors and a specified correction model.\nParameters:\nmz_ref (np.array): The m/z values of the reference features. rt_ref (np.array): The retention times of the reference features. mz_arr (np.array): The m/z values of the features to be corrected. rt_arr (np.array): The retention times of the features to be corrected. rt_max (float): Maximum retention time (default 50). mode (str): Mode of correction ('linear_interpolation' by default). mz_tol (float): m/z tolerance for selecting anchors. rt_tol (float): Retention time tolerance for selecting anchors. found_marker_ratio (float): Ratio of found markers required for correction (default 0.4). return_model (bool): Whether to return the correction model (default False). Returns:\nrt_corr (np.array): The corrected retention times. rt_anchor_selection(data_list, num=50, noise_tol=0.3, mz_tol=0.01, return_all_anchor=False)\nSelects anchors for retention time correction based on the provided data. Anchors are selected based on intensity, peak shape, and distribution.\nParameters:\ndata_list (list): A list of MSData objects or file names of the output .txt files. num (int): Number of anchors to be selected (default 50). noise_tol (float): Noise level tolerance for selecting anchors (default 0.3). mz_tol (float): m/z tolerance for anchor selection (default 0.01). return_all_anchor (bool): Whether to return all anchors (default False). Returns:\nanchors (list): A list of anchors (m/z and retention times) for retention time correction. _split_to_train_test(array, interval=0.3)\nSplits selected anchors into training and testing sets based on a specified time interval.\nParameters:\narray (numpy.ndarray): The retention times of the selected anchors. interval (float): The time interval for splitting the anchors (default 0.3). Returns:\ntrain_idx (list): Indices of the training set. test_idx (list): Indices of the testing set. ","overview#Overview":"The main components of this module include:\nFeature Alignment: Align features across different samples, considering parameters like m/z tolerance and retention time tolerance. Gap Filling: Fill in missing features across aligned samples using various strategies. Retention Time Correction: Correct retention times to align features more accurately. Output: Save the aligned features to a file. "},"title":"Alignment.py"},"/docs/api/annotation/":{"data":{"":"This module is designed for annotating metabolites based on their MS/MS spectra. It includes functions for loading MS/MS databases, performing feature annotation, and exporting results. The module supports various input formats and annotation methods, providing flexibility for different workflows.","functions#Functions":"load_msms_db load_msms_db(path)\nLoads the MS/MS database from a specified path, which can be in .msp, .pkl, or .json format.\nParameters:\npath (str): The path to the MS/MS database. Returns:\nAn instance of FlashEntropySearch with the loaded database indexed for fast searches. feature_annotation feature_annotation(features, parameters, num=5)\nAnnotates a list of features based on their MS/MS spectra using a loaded MS/MS database.\nParameters:\nfeatures (list): A list of features to be annotated. parameters (Params object): An object containing parameters for the annotation workflow. num (int): The number of top MS/MS spectra to search. Returns:\nfeatures (list): The annotated features. feature_annotation_mzrt feature_annotation_mzrt(features, path, default_adduct=\"[M+H]+\", mz_tol=0.01, rt_tol=0.3)\nAnnotates features based on a provided mzrt file, typically in CSV format.\nParameters:\nfeatures (list): A list of features to be annotated. path (str): The path to the mzrt file. default_adduct (str): The default adduct type for annotation. mz_tol (float): The m/z tolerance for matching. rt_tol (float): The RT tolerance for matching. Returns:\nfeatures (list): The annotated features. annotate_rois annotate_rois(d)\nAnnotates regions of interest (ROIs) within the MS data using their MS/MS spectra and a loaded MS/MS database.\nParameters:\nd (MSData object): The MS data object containing the detected ROIs. Returns:\nNone. The ROIs in the MSData object are annotated in place. annotate_ms2 annotate_ms2(ms2_seq, path)\nAnnotates a sequence of MS/MS spectra using a loaded MS/MS database.\nParameters:\nms2_seq (list): A list of MS/MS spectra (each can be a Scan object). path (str): The path to the MS/MS database. Returns:\nannotations (list): A list of annotations for each spectrum in the sequence. feature_to_feature_search feature_to_feature_search(feature_list, sim_tol=0.8)\nCalculates MS2 similarity between features using a hybrid search method, building a similarity matrix.\nParameters:\nfeature_list (list): A list of AlignedFeature objects. sim_tol (float): The similarity threshold for the feature-to-feature search. Returns:\nsimilarity_matrix (pandas.DataFrame): A DataFrame containing the similarity matrix between features. index_feature_list index_feature_list(feature_list, return_db=False)\nIndexes a list of features for spectrum entropy search.\nParameters:\nfeature_list (list): A list of AlignedFeature objects. return_db (bool): Whether to return the indexed database along with the search object. Returns:\nEither an instance of FlashEntropySearch or a tuple of (FlashEntropySearch, db) depending on the return_db parameter. output_ms2_to_msp output_ms2_to_msp(feature_table, output_path)\nExports MS2 spectra to MSP format.\nParameters:\nfeature_table (pandas.DataFrame): A DataFrame containing the MS2 spectra. output_path (str): The path to the output MSP file. Returns:\nNone. The spectra are written to the specified MSP file. extract_peaks_from_string extract_peaks_from_string(ms2)\nExtracts peaks from an MS2 spectrum provided as a string.\nParameters:\nms2 (str): The MS2 spectrum in string format. Returns:\npeaks (numpy.array): The peaks extracted as a numpy array. _convert_peaks_to_string _convert_peaks_to_string(peaks)\nConverts peaks from a numpy array to a string format suitable for storage or export.\nParameters:\npeaks (numpy.array): The peaks in numpy array format. Returns:\nms2 (str): The peaks converted to a string format. "},"title":"annotation.py"},"/docs/api/classifier_builder/":{"data":{"":"","#":"This module, classifier_builder.py, provides a set of tools for building and using a random forest classifier for metabolomics data analysis. It supports feature selection, model training, cross-validation, and prediction on new data. Below is a detailed breakdown of the functionality provided.\nModule Overview This module is designed to help users build and use a random forest classification model from metabolomics data. It integrates data processing, feature selection, model training, cross-validation, and prediction. The module supports various steps, including untargeted metabolomics workflows and utility functions for managing data.\nKey Functions Helper Functions feature_selection(X, y, k=None)\nPurpose: Selects the top k features based on statistical tests. Parameters: X: Feature matrix. y: Target variable. k: Number of features to select. Returns: Selected features and their indices. train_rdf_model(X_train, y_train)\nPurpose: Trains a random forest classifier. Parameters: X_train: Training feature matrix. y_train: Training target variable. Returns: Trained random forest model. cross_validate_model(X, y, model, k=5, random_state=0)\nPurpose: Performs k-fold cross-validation on the model. Parameters: X: Feature matrix. y: Target variable. model: Trained random forest model. k: Number of folds. random_state: Random state for reproducibility. Returns: List of accuracy scores for each fold. predict(model, X_test)\nPurpose: Predicts the class labels for test data. Parameters: model: Trained random forest model. X_test: Test feature matrix. Returns: Predicted class labels. evaluate_model(predictions, y_test)\nPurpose: Evaluates the model’s performance using accuracy. Parameters: predictions: Predicted class labels. y_test: True class labels. Returns: Accuracy score. Main Functions build_classifier(path=None, feature_num=None, gaussian_cutoff=0.6, fill_percentage_cutoff=0.9, fill_ratio=0.5, cross_validation_k=5, data_processed=False)\nPurpose: Builds a random forest classifier from raw or processed data. Parameters: path: Project path. feature_num: Number of features to select. gaussian_cutoff: Cutoff for Gaussian similarity. fill_percentage_cutoff: Minimum percentage of non-zero values to retain a feature. fill_ratio: Ratio to replace zero values in the data. cross_validation_k: Number of folds for cross-validation. data_processed: Flag to indicate if the data is already processed. Outputs: Saves the trained model, selected features, and evaluation metrics. Usage:\nbuild_classifier(path=\"/path/to/project\", feature_num=50) predict_samples(path, mz_tol=0.01, rt_tol=0.3)\nPurpose: Predicts sample classes using the trained model. Parameters: path: Project path. mz_tol: m/z tolerance for matching features. rt_tol: Retention time tolerance for matching features. Outputs: Saves predictions in the specified project path. Usage:\npredict_samples(path=\"/path/to/project\") Workflow Integration untargeted_metabolomics_workflow: This function, called within build_classifier and predict_samples, processes raw metabolomics data and prepares it for model building or prediction. Example Usage Building a Classifier:\nbuild_classifier(path=\"/path/to/project\", feature_num=100, gaussian_cutoff=0.7, cross_validation_k=10) Predicting New Samples:\npredict_samples(path=\"/path/to/project\") Dependencies Ensure that the following Python packages are installed:\nscikit-learn, pandas, numpy, os, pickle, shutil This module is designed to be used in metabolomics projects, providing a comprehensive approach to feature selection, model training, and prediction using random forest classifiers. It leverages the untargeted metabolomics workflow for data preparation and supports automated processing and analysis."},"title":"classifier_builder.py"},"/docs/api/feature_evaluation/":{"data":{"":"This module provides tools for predicting the quality of mass spectrometry features based on their peak shape. It includes functions for calculating Gaussian similarity, noise level, and asymmetry factor, which are key indicators of peak quality.","functions#Functions":"calculate_gaussian_similarity calculate_gaussian_similarity(x, y)\nCalculates the similarity between the observed peak shape and a Gaussian shape using a dot product.\nParameters:\nx (numpy array): Retention time values. y (numpy array): Intensity values corresponding to the retention times. Returns:\nsimilarity (float): Similarity score, where 1 indicates a perfect Gaussian shape and values closer to 0 indicate less similarity. calculate_noise_level calculate_noise_level(y, intensity_threshold=0.1)\nCalculates the noise level of a peak by analyzing intensity fluctuations.\nParameters:\ny (numpy array): Intensity values of the peak. intensity_threshold (float): Threshold relative to the maximum intensity for considering points in noise calculation (default 0.1). Returns:\nnoise_level (float): Noise level of the peak, with higher values indicating more noise. calculate_asymmetry_factor calculate_asymmetry_factor(y)\nCalculates the asymmetry factor of the peak at 10% of the peak height.\nParameters:\ny (numpy array): Intensity values of the peak. Returns:\nasymmetry_factor (float): Asymmetry factor, where values closer to 1 indicate more symmetrical peaks, and values deviating significantly from 1 indicate asymmetry. ","overview#Overview":" Gaussian Similarity Calculation: Estimates how closely the shape of a peak matches a Gaussian distribution. Noise Level Calculation: Measures the level of noise in the peak, which can indicate the reliability of the peak detection. Asymmetry Factor Calculation: Evaluates the symmetry of a peak, with ideal peaks being more symmetrical. ","usage#Usage":"Gaussian Similarity Calculation Gaussian similarity is a measure of how closely a detected peak’s shape matches a Gaussian distribution. This is useful for assessing the quality of the peak, as Gaussian-shaped peaks are often indicative of well-resolved features in chromatography.\nx = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) y = np.array([0, 2, 6, 10, 14, 15, 14, 10, 6, 2]) similarity = calculate_gaussian_similarity(x, y) print(f\"Gaussian Similarity: {similarity}\") Noise Level Calculation The noise level is calculated by observing the intensity fluctuations in the peak. Peaks with higher noise levels may be less reliable and indicative of poor detection or background noise.\ny = np.array([0, 2, 6, 10, 14, 15, 14, 10, 6, 2]) noise_level = calculate_noise_level(y) print(f\"Noise Level: {noise_level}\") Asymmetry Factor Calculation The asymmetry factor provides insight into the symmetry of the peak, which is another important characteristic of high-quality peaks. Ideal peaks should be symmetrical.\ny = np.array([0, 2, 6, 10, 14, 15, 14, 10, 6, 2]) asymmetry_factor = calculate_asymmetry_factor(y) print(f\"Asymmetry Factor: {asymmetry_factor}\") "},"title":"feature_evaluation.py"},"/docs/api/feature_grouping/":{"data":{"":"This module provides functionalities to group metabolic features in mass spectrometry data based on unique compounds. The module includes methods to annotate isotopes, adducts, and in-source fragments, which are essential for accurate interpretation of mass spectrometry data.","constants#Constants":"_ADDUCT_MASS_DIFFERENCE_POS_AGAINST_H A dictionary containing the mass differences for common adducts in positive ion mode, relative to the proton adduct [M+H]+.\n_ADDUCT_MASS_DIFFERENCE_NEG_AGAINST_H A dictionary containing the mass differences for common adducts in negative ion mode, relative to the deprotonated molecule [M-H]-.","functions#Functions":"annotate_isotope annotate_isotope(d, mz_tol=0.015, rt_tol=0.1, valid_intensity_ratio_range=[0.001, 1.2], charge_state_range=[1, 2])\nAnnotates isotopes in the MS data by comparing m/z and retention time values.\nParameters:\nd (MSData object): An MSData object containing the detected regions of interest (ROIs). mz_tol (float): m/z tolerance for identifying isotopes (default 0.015). rt_tol (float): Retention time tolerance for identifying isotopes (default 0.1). valid_intensity_ratio_range (list): Valid intensity ratio range between isotopes (default [0.001, 1.2]). charge_state_range (list): The range of charge states to consider for isotopes (default [1, 2]). Returns:\nNone. The function directly annotates the d.rois list with isotope information. annotate_in_source_fragment annotate_in_source_fragment(d, mz_tol=0.01, rt_tol=0.05)\nAnnotates in-source fragments by analyzing the MS data, focusing on peaks that may represent fragments of parent compounds.\nParameters:\nd (MSData object): An MSData object containing the detected ROIs. mz_tol (float): m/z tolerance for identifying in-source fragments (default 0.01). rt_tol (float): Retention time tolerance for identifying in-source fragments (default 0.05). Returns:\nNone. The function annotates the d.rois list with in-source fragment information. annotate_adduct(d, mz_tol=0.01, rt_tol=0.05) Annotates adducts within the MS data by comparing m/z values and retention times, assuming different adducts of the same compound.\nParameters:\nd (MSData object): An MSData object containing the detected ROIs. mz_tol (float): m/z tolerance for identifying adducts (default 0.01). rt_tol (float): Retention time tolerance for identifying adducts (default 0.05). Returns:\nNone. The function annotates the d.rois list with adduct information. peak_peak_correlation peak_peak_correlation(roi1, roi2)\nCalculates the peak-peak correlation between two ROIs based on their intensity profiles.\nParameters:\nroi1 (ROI object): The first ROI to compare. roi2 (ROI object): The second ROI to compare. Returns:\npp_cor (float): The peak-peak correlation value, where values close to 1 indicate strong correlation. get_charge_state get_charge_state(mz_seq)\nDetermines the charge state of a compound based on the difference between m/z values in its isotope series.\nParameters:\nmz_seq (list of floats): A list of m/z values representing the isotope series. Returns:\ncharge_state (int): The inferred charge state, either 1 or 2. ","overview#Overview":" Isotope Annotation: Identifies isotopic patterns within the data and annotates features that represent different isotopes of the same compound. Adduct Annotation: Detects and annotates different adducts of a compound, which can appear due to various ionization processes. In-Source Fragment Annotation: Identifies and annotates fragments that may form in the ion source, ensuring they are correctly associated with their parent compounds. ","usage#Usage":"Isotope Annotation To annotate isotopes in your mass spectrometry data:\nannotate_isotope(d, mz_tol=0.01, rt_tol=0.1) In-Source Fragment Annotation To annotate in-source fragments:\nannotate_in_source_fragment(d, mz_tol=0.01, rt_tol=0.05) Adduct Annotation To annotate adducts in the MS data:\nannotate_adduct(d, mz_tol=0.01, rt_tol=0.05) "},"title":"feature_grouping.py"},"/docs/api/feature_table_utils/":{"data":{"":"","#":"This utility module provides functions for manipulating and exporting feature tables in metabolomics data analysis. It focuses on converting feature lists to DataFrame format and exporting MS2 spectra to the MSP format. Below are detailed descriptions of the provided functions.\noutput_feature_to_msp output_feature_to_msp(feature_table, output_path)\nPurpose:\nThis function exports MS2 spectra from a DataFrame to the MSP format, which is commonly used in metabolomics for sharing spectral data.\nParameters:\nfeature_table (pandas.DataFrame): The DataFrame containing MS2 spectra data. output_path (str): The path where the MSP file will be saved. Functionality:\nChecks if the provided output path ends with .msp and raises a ValueError if not. Iterates through the rows of the feature_table DataFrame. For each feature, it writes the relevant information (e.g., precursor m/z, adduct type, retention time) and MS2 peaks to the MSP file. Handles cases where no MS2 spectrum is available by writing a default “Unknown” entry. Example Usage:\noutput_feature_to_msp(feature_table, \"output.msp\") convert_features_to_df convert_features_to_df(features, sample_names)\nPurpose:\nThis function converts a list of feature objects into a pandas DataFrame, which is useful for further data analysis or export.\nParameters:\nfeatures (list): A list of feature objects, each representing a detected metabolite or compound. sample_names (list or array): A list of sample names corresponding to the columns in the DataFrame. Returns:\nfeature_table (pandas.DataFrame): A DataFrame where each row corresponds to a feature, and the columns contain metadata and intensity values across samples. Functionality:\nCollects various attributes of each feature, such as m/z, retention time, adduct type, and any annotation information. Includes additional columns for sample-specific peak heights. Returns the constructed DataFrame, which is structured for easy export or further analysis. Example Usage:\nfeature_df = convert_features_to_df(features, sample_names) Example Workflow Convert Features to DataFrame:\nSuppose you have a list of feature objects detected during a metabolomics study. You can convert these features into a DataFrame for easier manipulation and analysis.\nfeature_df = convert_features_to_df(features, sample_names) Export MS2 Spectra to MSP:\nAfter converting the features to a DataFrame, you might want to export the MS2 spectra data to an MSP file for use in spectral databases or other analysis tools.\noutput_feature_to_msp(feature_df, \"output_data.msp\") These utility functions are designed to streamline the process of handling and exporting feature data in metabolomics workflows, particularly when dealing with large datasets and the need for standardized formats like MSP."},"title":"feature_table_utils.py"},"/docs/api/msjson/":{"data":{"":"Documentation is under construction. Please check back later."},"title":"msjson.py"},"/docs/api/network/":{"data":{"":"Documentation is under construction. Please check back later."},"title":"network.py"},"/docs/api/normalization/":{"data":{"":"","#":"This module provides functions for normalizing metabolomics data, focusing on two main types of normalization: Sample Normalization and Signal Normalization. These methods help address issues like varying sample concentrations and signal drift in mass spectrometry data.\nSample Normalization These functions focus on normalizing samples to account for differences in total amounts or concentrations between samples.\nfind_normalization_factors find_normalization_factors(array, method='pqn')\nFinds normalization factors for a dataset based on the specified method.\nParameters:\narray (numpy array): The data to be normalized. method (str): The method to find the normalization factors. Options: 'pqn': Probabilistic Quotient Normalization. Returns:\nnumpy array: Normalization factors. sample_normalization_by_factors sample_normalization_by_factors(array, v)\nNormalizes the data based on the provided normalization factors.\nParameters:\narray (numpy array): The data to be normalized. v (numpy array): The normalization factors. Returns:\nnumpy array: The normalized data. find_reference_sample find_reference_sample(array, method='median_intensity')\nFinds the reference sample for normalization.\nParameters:\narray (numpy array): The data to be normalized. method (str): The method to find the reference sample. Options: 'number': The sample with the most detected features. 'total_intensity': The sample with the highest total intensity. 'median_intensity': The sample with the highest median intensity. Returns:\nint: The index of the reference sample. sample_normalization sample_normalization(feature_table, individual_sample_groups, method='pqn')\nNormalizes samples using a feature list, typically excluding blank samples.\nParameters:\nfeature_table (pandas DataFrame): The feature table. individual_sample_groups (list): List of groups for individual samples. Blank samples will be skipped. method (str): The method to find the normalization factors. Options: 'pqn': Probabilistic Quotient Normalization. Returns:\npandas DataFrame: The normalized feature table. Signal Normalization These functions focus on correcting signal drift in the data, particularly important in mass spectrometry.\nqc_normalization qc_normalization(array, order, qc_idx, batch_idx=None, method='lowess')\nNormalizes samples using quality control (QC) samples to correct for signal drift.\nParameters:\narray (numpy array): The data to be normalized. Samples are in columns, and features are in rows. order (list): The order of the samples. It should have the same length as the number of samples. qc_idx (list): The index of the quality control samples. batch_idx (list): The index of the batches. Not used currently. method (str): The method to normalize the data. Options: 'lowess': Locally Weighted Scatterplot Smoothing. Returns:\nnumpy array: The normalized data. "},"title":"normalization.py"},"/docs/api/params/":{"data":{"":"This module defines and manages parameters for mass spectrometry data analysis, including feature detection, alignment, normalization, and statistical analysis. It provides functionalities to read, validate, and output parameters, as well as to prepare workflows for untargeted metabolomics.","classes#Classes":"Params A class to store and manage parameters for the project and individual files in mass spectrometry data processing.\nAttributes:\nProject-Related:\nproject_dir (str): Project directory. sample_names (list of str): List of raw file paths (without extension). sample_groups (list of str): List of sample group names. sample_group_num (int): Number of sample groups. sample_dir (str): Directory for sample information. single_file_dir (str): Directory for single file output. annotation_dir (str): Directory for annotation output. chromatogram_dir (str): Directory for chromatogram output. statistics_dir (str): Directory for statistical analysis output. MS Data Acquisition:\nrt_range (list of float): Retention time range in minutes, default [0.0, 1000.0]. ion_mode (str): Ionization mode, either “positive” or “negative”. Feature Detection:\nmz_tol_ms1 (float): m/z tolerance for MS1, default 0.01. mz_tol_ms2 (float): m/z tolerance for MS2, default 0.015. int_tol (int): Intensity tolerance, default 30000 for Orbitrap and 1000 for other instruments. roi_gap (int): Gap within a feature, default 30. ppr (float): Peak correlation threshold for feature grouping, default 0.7. Feature Alignment:\nalign_mz_tol (float): m/z tolerance for MS1, default 0.01. align_rt_tol (float): Retention time tolerance, default 0.2. run_rt_correction (bool): Whether to perform retention time correction, default True. min_scan_num_for_alignment (int): Minimum scan number for feature alignment, default 6. Feature Annotation:\nmsms_library (str): Path to the MS/MS library file. ms2_sim_tol (float): MS2 similarity tolerance, default 0.7. Normalization:\nrun_normalization (bool): Whether to normalize the data, default False. normalization_method (str): Normalization method, default “pqn” (probabilistic quotient normalization). Output:\noutput_single_file (bool): Whether to output processed individual files as CSV, default False. output_aligned_file (bool): Whether to output aligned features as CSV, default False. Statistical Analysis:\nrun_statistics (bool): Whether to perform statistical analysis, default False. Visualization:\nplot_bpc (bool): Whether to plot base peak chromatogram, default False. plot_ms2 (bool): Whether to plot MS2 mirror plots for matching, default False. Methods:\n__init__(self): Initializes a Params object with default values. read_parameters_from_csv(self, path): Reads parameters from a CSV file. _untargeted_metabolomics_workflow_preparation(self): Prepares parameters for an untargeted metabolomics workflow. set_default(self, ms_type, ion_mode): Sets default parameters based on the type of mass spectrometer and ionization mode. check_parameters(self): Validates the parameters using predefined ranges. output_parameters(self, path, format=\"json\"): Outputs the parameters to a file, currently only supports JSON format. ","constants#Constants":"PARAMETER_RAGES A dictionary containing the acceptable ranges for various parameters.\nKeys and Values: \"rt_start\": [0.0, 1000.0] \"rt_end\": [0.0, 1000.0] \"mz_tol_ms1\": [0.0, 0.02] \"mz_tol_ms2\": [0.0, 0.02] \"int_tol\": [0, 1e10] \"roi_gap\": [0, 50] \"min_scan_num_for_alignment\": [0, 50] \"align_mz_tol\": [0.0, 0.02] \"align_rt_tol\": [0.0, 2.0] \"ppr\": [0.5, 1.0] \"ms2_sim_tol\": [0.0, 1.0] PARAMETER_DEFAULT A dictionary containing default values for various parameters.\nKeys and Values: \"rt_start\": 0.0 \"rt_end\": 1000.0 \"mz_tol_ms1\": 0.01 \"mz_tol_ms2\": 0.015 \"int_tol\": 30000 \"roi_gap\": 10 \"min_scan_num_for_alignment\": 5 \"align_mz_tol\": 0.01 \"align_rt_tol\": 0.2 \"ppr\": 0.7 \"ms2_sim_tol\": 0.7 This documentation provides a clear and detailed overview of the Params class and associated functions, which are crucial for managing and validating parameters in mass spectrometry data processing. This should be useful for users who need to configure and customize their data analysis workflows.","functions#Functions":"find_ms_info(file_name)\nDetermines the type of mass spectrometer and ionization mode from a raw file.\nParameters:\nfile_name (str): The file name of the raw MS data file. Returns:\nms_type (str): The type of mass spectrometer (“orbitrap” or “tof”). ion_mode (str): The ionization mode (“positive” or “negative”). centroid (bool): Whether the data is centroided. ","overview#Overview":" Params Class: A class to store, manage, and validate parameters for various stages of mass spectrometry data processing. Helper Functions: Functions to determine mass spectrometry (MS) type, ion mode, and to validate parameter ranges. "},"title":"params.py"},"/docs/api/peak_detect/":{"data":{"":"This module provides tools for detecting features or peaks in mass spectrometry (MS) data. The main functionalities include finding regions of interest (ROIs), cutting ROIs based on intensity thresholds, and calculating various metrics related to the peaks.","classes#Classes":"Roi A class to represent a region of interest (ROI) in mass spectrometry data. An ROI typically corresponds to a peak or a group of peaks in a chromatogram.\nAttributes:\nid (int): Identifier for the ROI. scan_idx_seq (list of int): List of scan indices. rt_seq (list of float): List of retention times. mz_seq (list of float): List of m/z values. int_seq (list of int): List of intensity values. ms2_seq (list): List of associated MS2 spectra. gap_counter (int): Counter for the number of gaps in the ROI’s tail. mz (float): m/z value of the ROI peak. rt (float): Retention time of the ROI peak. scan_number (int): Number of scans in the ROI. peak_area (float): Area under the peak. peak_height (float): Height of the peak. best_ms2 (MS2 object): The best associated MS2 spectrum. length (int): Length of the ROI in terms of the number of scans. merged (bool): Indicates if the ROI has been merged with others. gaussian_similarity (float): Gaussian similarity score of the peak shape. noise_level (float): Estimated noise level in the ROI. asymmetry_factor (float): Asymmetry factor of the peak. cut (bool): Indicates if the ROI has been cut into smaller segments. charge_state (int): Charge state of the ROI (default 1). is_isotope (bool): Indicates if the ROI represents an isotope. isotope_mz_seq (list of float): List of m/z values for isotopes. isotope_int_seq (list of int): List of intensities for isotopes. isotope_id_seq (list of int): List of identifiers for isotopes. is_in_source_fragment (bool): Indicates if the ROI is an in-source fragment. isf_child_roi_id (list of int): List of child ROI IDs if the ROI is an in-source fragment. isf_parent_roi_id (int): Parent ROI ID if the ROI is an in-source fragment. adduct_type (str): Type of adduct, if applicable. adduct_parent_roi_id (int): Parent ROI ID for the adduct. adduct_child_roi_id (list of int): List of child ROI IDs for the adduct. annotation (str): Annotation of the ROI. formula (str): Molecular formula associated with the ROI. similarity (float): Similarity score for annotation. matched_peak_number (int): Number of matched peaks in the ROI. smiles (str): SMILES notation of the associated molecule. inchikey (str): InChIKey notation of the associated molecule. Methods:\n__init__(self, scan_idx, rt, mz, intensity): Initializes an ROI with scan index, retention time, m/z, and intensity. extend_roi(self, scan_idx, rt, mz, intensity): Extends an ROI with new data points. show_roi_info(self, show_annotation=False): Prints information about the ROI. get_mz_error(self): Calculates the m/z error (maximum - minimum) of the ROI. find_rt_ph_pa(self): Calculates the peak area and height using the trapezoidal rule. find_top_average(self, num=3): Finds the peak height by averaging the top three intensities. sum_roi(self, cal_g_score=True, cal_a_score=True): Summarizes the ROI, calculating key attributes. subset_roi(self, start, end): Subsets the ROI based on provided start and end positions. ","functions#Functions":"find_rois find_rois(d)\nIdentifies regions of interest (ROIs) in the MS data.\nParameters:\nd (MSData object): An object that contains the MS data. Returns:\nfinal_rois (list of Roi objects): A list of detected ROIs. cut_roi cut_roi(r, int_tol=1000, sigma=1.2, prominence_ratio=0.1, distance=5)\nCuts a region of interest (ROI) into smaller segments based on intensity and peak prominence.\nParameters:\nr (Roi object): The ROI object to be cut. int_tol (int): Intensity tolerance for cutting (default 1000). sigma (float): Sigma value for Gaussian filtering (default 1.2). prominence_ratio (float): Ratio of prominence used for finding peaks (default 0.1). distance (int): Minimum distance between peaks (default 5). Returns:\ncut_rois (list of Roi objects): A list of cut ROIs. find_closest_index_ordered(array, target, tol=0.01)\nFinds the index of the closest value in an ordered array.\nParameters:\narray (list or numpy array): The ordered array to search. target (float): The target value to find. tol (float): Tolerance for considering a match (default 0.01). Returns:\nidx (int or None): The index of the closest value, or None if no suitable match is found. ","overview#Overview":" ROI Detection: Identifies regions of interest in the MS data, capturing significant peaks and their characteristics. ROI Processing: Provides tools to refine and cut ROIs, calculate peak areas, and evaluate peak quality. Utilities: Helper functions to support the detection and processing of ROIs. "},"title":"peak_detect.py"},"/docs/api/raw_data_utils/":{"data":{"":"This module provides tools for reading and processing raw mass spectrometry (MS) data, specifically in mzML or mzXML format. It includes a class to handle the data, providing functionalities for extracting scans, finding regions of interest (ROIs), generating chromatograms, and more.","classes#Classes":"MSData A class that models a single MS file (mzML or mzXML) and processes the raw data.\nAttributes:\nfile_name (str): Name of the raw data file without extension. start_time (datetime): Start acquisition time of the raw data. params (Params object): Contains the parameters used for processing. scans (list): A list of Scan objects representing each scan in the data. ms1_rt_seq (numpy array): Retention times of all MS1 scans. bpc_int (numpy array): Intensity of the Base Peak Chromatogram (BPC). rois (list): A list of ROI objects. roi_mz_seq (numpy array): m/z values of all ROIs. roi_rt_seq (numpy array): Retention time of all ROIs. Methods:\n__init__(self): Initializes the MSData object. read_raw_data(self, file_name, params, read_ms2=True, clean_ms2=False, centroid=True): Reads raw MS data and extracts MS1 and MS2 scans. extract_scan_mzml(self, spectra, int_tol=0, read_ms2=True, clean_ms2=False, centroid=True): Extracts scans from an mzML file. extract_scan_mzxml(self, spectra, int_tol, read_ms2=True, clean_ms2=False, centroid=True): Extracts scans from an mzXML file. drop_ion_by_int(self): Drops ions by intensity. find_rois(self): Identifies ROIs in MS1 scans. cut_rois(self): Splits ROIs into smaller pieces. summarize_roi(self, cal_g_score=True, cal_a_score=True): Processes ROIs and assigns MS2 spectra. allocate_ms2_to_rois(self): Allocates MS2 spectra to ROIs. drop_rois_without_ms2(self): Removes ROIs without MS2 spectra. drop_rois_by_length(self, length=5): Removes ROIs shorter than a specified length. plot_bpc(self, rt_range=None, label_name=False, output_dir=None): Plots the Base Peak Chromatogram (BPC). output_single_file(self, user_defined_output_path=None): Generates a CSV report of ROIs. get_eic_data(self, target_mz, target_rt=None, mz_tol=0.005, rt_tol=0.3, rt_range=None): Extracts Extracted Ion Chromatogram (EIC) data for a target m/z. plot_eics(self, target_mz_seq, target_rt=None, mz_tol=0.005, rt_tol=0.3, output=None, show_rt_line=True, ylim=None, return_eic_data=False): Plots EICs for multiple target m/z values. plot_eic(self, target_mz, target_rt=None, mz_tol=0.005, rt_tol=0.3, output=None, show_rt_line=True, ylim=None, return_eic_data=False): Plots the EIC for a single target m/z. find_ms2_by_mzrt(self, mz_target, rt_target, mz_tol=0.01, rt_tol=0.3, return_best=False): Finds MS2 scans by precursor m/z and retention time. find_roi_by_mzrt(self, mz_target, rt_target=None, mz_tol=0.01, rt_tol=0.3): Finds ROIs by m/z and retention time. find_ms1_scan_by_rt(self, rt_target): Finds an MS1 scan by retention time. correct_retention_time(self, f): Corrects retention times based on a provided function. plot_roi(self, roi_idx, mz_tol=0.005, rt_range=[0, np.inf], rt_window=None, output=False): Plots the EIC for a specific ROI. plot_all_rois(self, output_path, mz_tol=0.01, rt_range=[0, np.inf], rt_window=None): Plots the EICs for all ROIs. Scan A class that represents an individual MS scan, either MS1 or MS2.\nAttributes:\nlevel (int): The MS level of the scan (1 or 2). scan (int): Scan number. rt (float): Retention time. mz_seq (numpy array): m/z sequence (for MS1). int_seq (numpy array): Intensity sequence (for MS1). precursor_mz (float): Precursor m/z (for MS2). peaks (numpy array): Product m/z and intensity pairs (for MS2). Methods:\n__init__(self, level=None, scan=None, rt=None): Initializes the Scan object. add_info_by_level(self, **kwargs): Adds scan information depending on the MS level. show_scan_info(self): Prints the scan’s information. plot_scan(self, mz_range=None, return_data=False): Plots the scan data. ","helper-functions#Helper Functions":"_clean_ms2(ms2, offset=2, int_drop_ratio=0.01) Cleans MS/MS spectra by removing ions with m/z greater than a specified offset and by removing ions with low intensity.\nParameters:\nms2 (Scan object): The MS2 scan to clean. offset (float): m/z offset for dropping ions. int_drop_ratio (float): Ratio of the base peak intensity below which ions will be dropped. _centroid(mz_seq, int_seq, mz_tol=0.005) Centroids m/z and intensity sequences.\nParameters:\nmz_seq (numpy array): m/z sequence. int_seq (numpy array): Intensity sequence. mz_tol (float): m/z tolerance for centroiding. read_raw_file_to_obj(file_name, params=None, int_tol=1000, centroid=True, read_ms2=True, clean_ms2=False, print_summary=False) Reads a raw MS file into an MSData object.\nParameters:\nfile_name (str): Name of the raw MS data file. params (Params object): Parameters for processing. int_tol (float): Intensity tolerance for ion filtering. centroid (bool): Whether to centroid the raw data. print_summary (bool): Whether to print a summary of the data. Returns:\nd (MSData object): The processed MSData object. find_best_ms2(ms2_seq) Finds the best MS2 spectrum from a list of MS2 spectra based on intensity.\nParameters:\nms2_seq (list): List of MS2 spectra. Returns:\nbest_ms2 (Scan object): The MS2 scan with the highest intensity. get_start_time(file_name) Extracts the start time of the raw data from the file.\nParameters:\nfile_name (str): Absolute path to the raw data file. Returns:\nstart_time (datetime): The start acquisition time of the raw data. ","overview#Overview":"The main components of this module include:\nMSData Class: A class that models a single MS data file, allowing for the extraction, processing, and visualization of MS data. Scan Class: A class that represents individual MS scans, including both MS1 and MS2 levels. Helper Functions: Various utility functions to assist in data processing, such as reading files, centroiding data, and finding the best MS2 spectrum. "},"title":"raw_data_utils.py"},"/docs/api/stats/":{"data":{"":"","#":"This module provides functions for performing statistical analysis on metabolomics data, including univariate analysis (t-tests and ANOVA) and multivariate analysis (Principal Component Analysis or PCA).\nUnivariate Analysis statistical_analysis statistical_analysis(feature_table, params, before_norm=False)\nPerforms statistical analysis on the feature table, including univariate analysis (t-test or ANOVA) and multivariate analysis (PCA).\nParameters:\nfeature_table (pandas DataFrame): The feature table containing metabolomics data. params (Params object): The parameters for the experiment. before_norm (bool): Whether the analysis is performed before normalization. Default is False. Returns:\npandas DataFrame: The updated feature table with p-values from statistical tests. t_test t_test(data_array, individual_sample_groups)\nPerforms a t-test on a feature list for two groups.\nParameters:\ndata_array (numpy array): The feature intensities. individual_sample_groups (list): A list of groups of individual samples. Returns:\nlist: p-values from the t-test. anova anova(data_array, individual_sample_groups)\nPerforms ANOVA on a feature list for more than two groups.\nParameters:\ndata_array (numpy array): The feature intensities. individual_sample_groups (list): A list of groups of individual samples. Returns:\nlist: p-values from the ANOVA test. Multivariate Analysis pca_analysis pca_analysis(data_array, individual_sample_groups, scaling=True, transformation=True, gapFillingRatio=0.2, output_dir=None, before_norm=False)\nPerforms Principal Component Analysis (PCA) on the data.\nParameters:\ndata_array (numpy array): The feature intensities. Features are in rows and samples are in columns. individual_sample_groups (list): A list of groups of individual samples. scaling (bool): Whether to scale the data. Default is True. transformation (bool): Whether to transform the data (log10). Default is True. gapFillingRatio (float): The ratio for gap-filling. Default is 0.2. output_dir (str): The directory to save the PCA plot. Default is None. before_norm (bool): Whether the analysis is performed before normalization. Default is False. Returns:\nvecPC1, vecPC2, var_PC1, var_PC2: PCA results including the principal component vectors and their explained variance ratios. "},"title":"stats.py"},"/docs/api/utils_functions/":{"data":{"":"","#":"This module provides utility functions for metabolomics data processing, including generating sample tables, obtaining timestamps from files, calculating ion masses, and estimating isotope distributions.\ngenerate_sample_table generate_sample_table(path=None, output=True)\nGenerates a sample table from the mzML or mzXML files in a specified directory.\nParameters:\npath (str): The path to the directory containing the ‘data’ subdirectory with mzML or mzXML files. If not specified, the current working directory is used. output (bool): If True, outputs the sample table to a CSV file. Returns:\npandas DataFrame (if output=False): The sample table containing two columns: ‘Sample’ and ‘Groups’. Outputs:\nsample_table.csv (if output=True): A CSV file with the sample table. Usage:\nsample_table = generate_sample_table(\"/path/to/project\", output=True) get_timestamps get_timestamps(path, output=True)\nObtains timestamps for individual mzML or mzXML files and sorts the files by acquisition time.\nParameters:\npath (str): The path to the directory containing the ‘data’ subdirectory with mzML or mzXML files. output (bool): If True, outputs the timestamps to a TXT file. Returns:\nlist or pandas DataFrame (if output=False): A list or DataFrame of tuples containing ‘file_name’ and ‘acquisition_time’. Outputs:\ntimestamps.txt (if output=True): A TXT file with the timestamps. Usage:\ntimestamps = get_timestamps(\"/path/to/project\", output=True) "},"title":"utils_functions.py"},"/docs/api/visualization/":{"data":{"":"","#":"This module provides a suite of data visualization functions tailored for metabolomics data analysis. It includes tools for plotting base peak chromatograms, extracted ion chromatograms (EIC), histograms, mirror images of MS² spectra, and Principal Component Analysis (PCA) plots. These visualizations aid in the interpretation and quality control of metabolomics experiments.\nFunctions plot_bpcs plot_bpcs(data_list=None, output=None, autocolor=False, show_legend=True)\nPlots overlapped Base Peak Chromatograms (BPC) from a list of MSData objects.\nParameters:\ndata_list (list of MSData objects, optional): A list of MSData objects to be plotted. Each object should contain ms1_rt_seq (retention time sequence), bpc_int (BPC intensities), and file_name attributes. output (str, optional): Path to save the plot as an image file. If None, the plot is displayed instead of being saved. autocolor (bool, default False): If True, assigns distinct colors to each BPC using a predefined color list. Otherwise, all BPCs are plotted in black. show_legend (bool, default True): If True, displays a legend with the file names. Usage:\nplot_bpcs(data_list=ms_data_list, output=\"bpc_plot.png\", autocolor=True, show_legend=True) plot_roi plot_roi(d, roi, mz_tol=0.01, rt_tol=1.0, output=False, break_scan=None)\nPlots the Extracted Ion Chromatogram (EIC) for a specified region of interest (ROI).\nParameters:\nd (MSData object): The MSData object containing EIC data. roi (ROI object): The region of interest containing attributes like mz, rt_seq, int_seq, scan_idx_seq, gaussian_similarity, noise_level, asymmetry_factor, and rt. mz_tol (float, default 0.01): Mass-to-charge ratio (m/z) tolerance for EIC extraction. rt_tol (float, default 1.0): Retention time (RT) tolerance around the ROI. output (str, optional): Path to save the plot as an image file. If False, the plot is displayed instead of being saved. break_scan (int, optional): Scan index at which to break and color the EIC differently. Usage:\nplot_roi(ms_data, roi, mz_tol=0.01, rt_tol=1.0, output=\"roi_plot.png\") mirror_ms2_from_scans mirror_ms2_from_scans(scan1, scan2, output=False)\nGenerates a mirror plot of two MS² spectra for comparison.\nParameters:\nscan1 (MS2Scan object): The first MS² scan (experimental). scan2 (MS2Scan object): The second MS² scan (database). output (str, optional): Path to save the plot as an image file. If False, the plot is displayed instead of being saved. Usage:\nmirror_ms2_from_scans(scan_exp, scan_db, output=\"ms2_mirror.png\") mirror_ms2 mirror_ms2(precursor_mz1, precursor_mz2, peaks1, peaks2, annotation=None, score=None, output=False)\nCreates a mirror image plot of two MS² spectra based on precursor m/z and fragment peaks.\nParameters:\nprecursor_mz1 (float): Precursor m/z of the first spectrum. precursor_mz2 (float): Precursor m/z of the second spectrum. peaks1 (numpy array): Fragment peaks of the first spectrum, shape (n, 2) where each row is [m/z, intensity]. peaks2 (numpy array): Fragment peaks of the second spectrum, shape (n, 2). annotation (str, optional): Annotation or name for the second spectrum. score (float, optional): Similarity score between the two spectra. output (str, optional): Path to save the plot as an image file. If False, the plot is displayed instead of being saved. Usage:\nmirror_ms2(precursor1, precursor2, peaks_exp, peaks_db, annotation=\"Compound A\", score=0.85, output=\"mirror_ms2.png\") plot_pca plot_pca(vecPC1, vecPC2, var_PC1, var_PC2, group_names, colors=None, plot_order=None, output_dir=None)\nPlots a PCA scatter plot with confidence ellipses for each group.\nParameters:\nvecPC1 (array-like): Principal Component 1 scores. vecPC2 (array-like): Principal Component 2 scores. var_PC1 (float): Explained variance ratio for PC1. var_PC2 (float): Explained variance ratio for PC2. group_names (list or array-like): Group labels for each sample. colors (list, optional): List of colors for each group. Defaults to a predefined color palette. plot_order (list, optional): Order in which groups are plotted. output_dir (str, optional): Path to save the PCA plot as an image file. If None, the plot is displayed instead of being saved. Usage:\nplot_pca(PC1_scores, PC2_scores, 0.45, 0.30, group_labels, colors=[\"#FF5050\", \"#0078F0\"], output_dir=\"pca_plot.png\") Helper Functions confidence_ellipse confidence_ellipse(x, y, ax, n_std=3.0, facecolor='none', **kwargs)\nAdds a covariance confidence ellipse to a plot.\nParameters:\nx (array-like): Data for the x-axis. y (array-like): Data for the y-axis. ax (matplotlib.axes.Axes): The axes object to draw the ellipse on. n_std (float, default 3.0): Number of standard deviations for the ellipse radius. facecolor (str, default 'none'): Face color of the ellipse. **kwargs: Additional keyword arguments for matplotlib.patches.Ellipse. Usage:\nfig, ax = plt.subplots() confidence_ellipse(x_data, y_data, ax, n_std=2.0, edgecolor='red') random_color_generator random_color_generator()\nGenerates a random CSS4 color name.\nReturns:\nstr: A randomly selected CSS4 color name. Usage:\ncolor = random_color_generator() Predefined Color Lists _color_list: A predefined list of colors used when autocolor=True in plot_bpcs.\n_color_list = [\"red\", \"blue\", \"green\", \"orange\", \"purple\", \"brown\", \"pink\", \"gray\", \"olive\", \"cyan\"] COLORS: A predefined list of hex color codes used in PCA plotting.\nCOLORS = [\"#FF5050\", \"#0078F0\", \"#00B050\", \"#FFC000\", \"#7030A0\", \"#FF00FF\", \"#00B0F0\", \"#FF0000\", \"#00FF00\", \"#0000FF\"] Dependencies Ensure the following Python packages are installed:\nmatplotlib numpy pandas tqdm pyteomics Other custom modules: .annotation (for extract_peaks_from_string) .raw_data_utils (for get_start_time) "},"title":"visualization.py"},"/docs/api/workflows/":{"data":{"":"","#":"This module summarizes several workflows and utilities for processing untargeted metabolomics data using various tools and packages. It provides comprehensive methods for feature detection, feature alignment, annotation, normalization, statistical analysis, and quality control. The workflows are designed to be flexible, allowing for parallel processing, and they include detailed steps for handling data from raw files to final feature tables.\nfeature_detection feature_detection(file_name, params=None, cal_g_score=True, cal_a_score=True, anno_isotope=True, anno_adduct=True, anno_in_source_fragment=True, annotation=False, ms2_library_path=None, output_dir=None)\nPerforms untargeted feature detection from a single file (e.g., .mzML or .mzXML).\nParameters:\nfile_name (str): Path to the raw data file. params (Params object, optional): Parameters for feature detection. If None, default parameters are used. cal_g_score (bool, default True): Whether to calculate the Gaussian similarity score for each ROI. anno_isotope (bool, default True): Whether to annotate isotopes. anno_adduct (bool, default True): Whether to annotate adducts. anno_in_source_fragment (bool, default True): Whether to annotate in-source fragments. annotation (bool, default False): Whether to annotate MS2 spectra using an MS2 library. ms2_library_path (str, optional): Path to the MS2 library file. output_dir (str, optional): Directory to save output files. If None, the output is saved in a default location. Returns:\nd (MSData object): An MSData object containing processed data. Usage:\nresult = feature_detection(\"sample.mzML\", params=custom_params, annotation=True, ms2_library_path=\"library.msp\") untargeted_metabolomics_workflow untargeted_metabolomics_workflow(path=None, batch_size=100, cpu_ratio=0.8)\nPerforms the full untargeted metabolomics workflow, including feature detection, alignment, annotation, normalization, and statistical analysis.\nParameters:\npath (str, optional): Path to the working directory. If None, the current working directory is used. batch_size (int, default 100): Number of files to process in each batch. cpu_ratio (float, default 0.8): Ratio of CPU cores to use for parallel processing. Usage:\nuntargeted_metabolomics_workflow(path=\"/path/to/project\", batch_size=50, cpu_ratio=0.9) batch_file_processing batch_file_processing(path=None, batch_size=100, cpu_ratio=0.8)\nProcesses multiple files in batch mode using the untargeted metabolomics workflow.\nParameters:\npath (str, optional): Path to the working directory. If None, the current working directory is used. batch_size (int, default 100): Number of files to process in each batch. cpu_ratio (float, default 0.8): Ratio of CPU cores to use for parallel processing. Usage:\nbatch_file_processing(path=\"/path/to/project\", batch_size=50, cpu_ratio=0.9) Dependencies Ensure that the following Python packages are installed:\nos, multiprocessing, pickle, deepcopy, pandas, numpy, tqdm, importlib.metadata, scipy, time, json The module also relies on several internal modules and functions:\nMSData, get_start_time from .raw_data_utils Params, find_ms_info from .params annotate_isotope, annotate_adduct, annotate_in_source_fragment from .feature_grouping feature_alignment, gap_filling, output_feature_table from .alignment feature_annotation, annotate_rois, feature_annotation_mzrt from .annotation sample_normalization from .normalization plot_ms2_matching_from_feature_table from .visualization statistical_analysis from .stats convert_features_to_df, output_feature_to_msp from .feature_table_utils "},"title":"workflows.py"},"/docs/installation/":{"data":{"":"","install-_masscube_#Install \u003cem\u003emasscube\u003c/em\u003e":"Install Python Visit the official Python website to download Python. Python 3.9-3.11 is recommended.\nDownload Python 3.11 Download Python 3.11. IMPORTANT: Make sure to check the box that says “Add Python to PATH” during installation.\nInstall masscube masscube is a Python package that can be installed using pip. Open terminal and run\npip install masscube To update the package to the latest version, open terminal and run\npip install masscube --upgrade Dependencies will be automatically installed. Consider creating a virtual environment if you’re working with Python on multiple projects.\nDependencies dependencies = [ \"numpy\u003e=1.24,\u003c=1.26\", \"pandas\u003e=2.2.1\", \"pyteomics==4.6.3\", \"scipy\u003e=1.10.1\", \"tqdm\u003e=4.66.1\", \"lxml\u003e=4.9.3\", \"matplotlib\u003e=3.8.2\", \"ms_entropy==1.1.1\", \"scikit-learn\u003e=1.3.2\", \"statsmodels\u003e=0.14.2\" ] ","install-python#Install Python":""},"title":"Installation"},"/docs/plans/":{"data":{"":"We are working on the following features and improvements and welcome contributions from the community.\nTargeted metabolomics workflows\nMore data normalization algorithms and evaluation metrics\nWorkflows and functions for data-independent acquisition (DIA) data.\nMS imaging data processing"},"title":"Plans for development"},"/docs/quickstart/":{"data":{"":"Let’s get started with the OneClick untargeted metabolomics workflow. This workflow is designed to streamline untargeted metabolomics analysis, providing comprehensive results with a single command.\nIf you haven’t installed MassCube, please follow the installation guide.","the-oneclick-untargeted-metabolomics-workflow#The OneClick untargeted metabolomics workflow":"Metabolomics data processing could be challenging for researchers. The OneClick untargeted metabolomics workflow was developed to address the burdens and support metabolomics research.\nThe OneClick workflow integrates metadata curation, feature detection, evaluation, alignment, annotation, and statistical analysis to provide users with a comprehensive view of the data (Fig. 1).\nFig. 1. The OneClick untargeted metabolomics workflow Input (3+1) You need three components for the project plus one MS/MS library for annotation.\nIn your project folder (e.g. my_project), you need to prepare the following components:\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... |── sample_table.csv └── parameters.csv data folder: a file folder containing all raw LC-MS data in .mzML or .mzXML format. It’s mandatory. Instructions for file conversion are provided here.\nsample_table.csv file: a csv file to claim the sample groups including biological groups, quality control samples, or blank samples. A template can be downloaded from here. It’s optional. If not provided, normalization and statistical analysis will not be applied. Note: In sample table, please name quality control samples as “qc” and blank samples as “blank” (not case-sensitive).\nparameters.csv file: a csv file to set parameters for the workflow. A template can be downloaded from here. It’s optional. If not provided, the default parameters will be applied, yet annotation will not be performed since the MS/MS library is not provided.\nMS2 database: To annotate MS/MS spectra, you need to download a MS/MS library from here. For faster database loading, please download and use the .pkl format.\nExtra component for annotation:\nmzrt_list.csv file: a csv file to provide the m/z and retention time for feature annotation. It was designed to annotate full-scan MS data or annotate the spiked internal standards. A template can be downloaded from here. It’s optional. If not provided, the annotation will not be performed. Data Preparation Processing In the project folder, open a terminal and run the following command:\nuntargeted-metabolomics How to open the terminal Make sure the terminal directory is set to the project folder. For Windows user and MacOS user Output After the processing, you will find the following files and folders in the project folder:\nproject/ ├── data ├── sample_table.csv ├── parameters.csv ├── project.mc ├── aligned_feature_table.txt ├── aligned_feature_table_before_normalization.txt ├── ms2.msp ├── single_file_output │ ├── sample1.txt │ ├── sample2.txt │ └── ... ├── chromatogram │ ├── sample1.png │ ├── sample2.png │ └── ... ├── ms2_matching │ ├── compound1.png │ ├── compound2.png │ └── ... ├── statistics ├── ... project.mc file: the project file of masscube. aligned_feature_table.txt file: feature table after alignment (if applied). aligned_feature_table_before_normalization.txt file: feature table before normalization. ms2.msp: MS/MS spectra for detected features that can be further analyzed on other platforms such as GNPS. single_file_output folder: a folder containing the feature table for each sample. chromatogram folder: a folder containing the chromatogram for each sample. ms2_matching folder: a folder containing the MS/MS matching for each annotated compound. statistics folder: a folder containing the statistical analysis results. "},"title":"Quick start"},"/docs/workflows/":{"data":{"":"Mass spectrometry data processing is application-oriented. MassCube supports flexible data processing workflows by combining individual functions and modules. The pre-defined workflows are designed to streamline data processing and analysis for specific applications.\nTo achieve this, we offer a series of pre-defined workflows that can be used as command line applications.\nWondering how to contribute to the workflows? Please refer to the contribution guide."},"title":"Workflows"},"/docs/workflows/batch_processing/":{"data":{"":"","explainations-of-the-workflow#Explainations of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def batch_file_processing(path=None, batch_size=100, cpu_ratio=0.8): \"\"\" The untargeted metabolomics workflow. See the documentation for details. Parameters ---------- path : str The working directory. If None, the current working directory is used. batch_size : int The number of files to be processed in each batch. cpu_ratio : float The ratio of CPU cores to be used. \"\"\" ... Step 1. Define or load parameters The parameters are critical for MS data processing. However, setting parameters are often challenging, especially for beginners or scientists who are not familiar with the MS data.\nmasscube automatically read the MS data and apply the corresponding default parameters. Users can also customize the parameters by providing a parameter file.\nStep 2. Single file processing Individual files are processed for feature detection, which envolves the detection of peak apex, edges, area, and related MS/MS spectra. It also includes the determination of isotopes, charge states, adducts, and in-source fragments.\nTo accelerate the processing, masscube supports parallel computing for multiple files. By default, the number of threads is set to be the 80% (cpu_ratio=0.8) of the total CPU cores so that the computer can still be used for other tasks.\nTo control the memory usage, the files are processed in batches. The default batch size is 100 (batch_size=100).\nMore details about the feature detection can be found here.\nStep 3. Data visualization Users can choose to plot the base peak chromatogram (BPC) to verify possible bad injections or outliers.","how-to-use#How to use":" Organize the data Similar to the untargeted metabolomics workflow, the data should be organized in the following structure:\nYou need two components for the project plus one MS/MS library for annotation.\nIn your project folder (e.g. my_project), you need to prepare the following components:\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... └── parameters.csv Processing In the project folder, open a terminal and run the following command:\nprocess-files Output After the processing, you will find the following files and folders in the project folder:\nproject/ ├── data ├── parameters.csv ├── project.mc ├── single_file_output │ ├── sample1.txt │ ├── sample2.txt │ └── ... ├── chromatogram │ ├── sample1.png │ ├── sample2.png │ └── ... ├── ... project.mc file: the project file of masscube. single_file_output folder: a folder containing the feature table for each sample. chromatogram folder: a folder containing the chromatogram for each sample. ","introduction#Introduction":"Processing each raw LC-MS data individually can be useful for further customized analysis. In this workflow, we introduce how to process single files in batch mode using masscube. Note, the processed files will not be aligned across samples. Users may employ the OneClick untargeted metabolomics workflow for comprehensive data processing."},"title":"Batch processing"},"/docs/workflows/data_preparation/":{"data":{"":"","file-conversion#File conversion":"Raw LC-MS data need to be converted to mzML or mxXML format for further processing in MassCube.\nCurrently, only centroid data are supported in MassCube. We recommend to use MSConvert for file conversion.\nDownload and install MSConvert Visit the official website to download ProteoWizard.\nFile conversion using MSConvert Fig. 1. MSConvert GUI Step 1. Set options Check the boxes as shown in Fig. 1.\n⚠️ Do NOT check Use Zlib compression. Step 2. Set the Peak Picking filter Step 3. Add the Peak Picking filter Step 4. Browse and load files Step 5. Start conversion By default, the converted files will be saved in the same directory as the raw files.\nConvert files in command line mode You can also convert files using MSConvert in command line mode. For more information, please refer to the documentation. ","parameter-file#Parameter file":"A parameter file (.csv) is used to set parameters for the workflow. A templete is provided here. If not provided, the default parameters will be applied.","sample-table#Sample table":"A sample table (.csv) is used to claim the name of samples and their groups including biological groups, quality control samples, or blank samples. A templete is provided here.\nFor large-scale metabolomics data, it’s not easy to prepare the sample table manually. In MassCube, we provide a function to automatically generate the sample table based on the file names in the data folder, and users can further define the groups.\nQuickly generate sample table In the project folder, open a terminal and run the following command:\ngenerate-sample-table Your project folder should include a subfolder named data that contains the raw LC-MS data files in mzML or mzXML format.\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... |── ... You need to further specify the groups in the generated sample table. "},"title":"Data preparation"},"/docs/workflows/find-outliers/":{"data":{"":"","explanation-of-the-workflow#Explanation of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 def run_evaluation(path=None): \"\"\" Evaluate the run and report the problematic files. Parameters ---------- path : str Path to the project directory. \"\"\" ... The run_evaluation function evaluates the run and reports the problematic files. It checks the quality of the raw data and identifies the problematic samples based on the number of detected features.\nThe function generates a problematic_samples.txt file that lists the names of the problematic samples. Users can further investigate the outliers and decide whether to remove them before downstream analysis.\nStep 1. Fast untargeted feature detection A fast untargeted feature detection algorithm is applied to the raw data. The algorithm automatically applies the default parameters for feature detection based on the metadata of the raw files. Parameters are not needed to be set by the users.\nStep 2. Find outliers The total number of features detected in each sample is calculated. Samples with total feature numnber deviating from the mean by more than 3 standard deviations are considered as outliers.\nStep 3. Report problematic samples The names of the problematic samples are saved in the problematic_samples.txt file. Users can further investigate the outliers and decide whether to remove them before downstream analysis.","how-to-use#How to use":" Step 1. Organize the data Put all the raw data files in a folder. The data should be organized in the following structure:\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... └── sample_table.csv Note: Please provide a sample table to specify the blank samples so that they can be excluded from the outlier detection.\nStep 2. Run the outlier detection In the data folder, open a terminal and run the following command:\nfind-outliers Output After the processing, you will find the following files and folders in the data folder:\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... ├── single_files │ ├── sample1.txt │ ├── sample2.txt | └── ... |── sample_table.csv └── problematic_files.txt problematic_samples.txt: a text file containing the names of the problematic samples. single_files: a folder containing the feature detection results for each sample. ","introduction#Introduction":"Outliers are data files that differ significantly from the rest of the dataset. In MS experiments, outliers can arise due to various factors such as instrument error, sample preparation issues, or biological variation. Identifying and removing outliers before downstream analysis is crucial to avoid misleading results.\nmasscube evaluates the analytical sequence and reports problematic samples in an unsupervised manner. It assesses the quality of the raw data by analyzing the total peak height of all detected features. Files with a Z-score lower than -2 (by default) are recognized as outliers, ensuring that only high-quality data are included in the downstream analysis."},"title":"Outlier detection"},"/docs/workflows/parameters/":{"data":{"":"Parameters are critical for MS data processing. However, setting parameters are often challenging, especially for beginners. masscube provides a default parameter setting for users to start with.\nThe default parameters are optimized for most untargeted metabolomics studies. Users can also customize the parameters by providing a parameter file.","customize-parameters#Customize parameters":"From the template, users can customize the parameters by providing a parameter file. The parameter file should be a .csv file with the following columns:\nParameter Value Explanation rt_start 0 start of the analytical gradient; minute rt_end 23 end of the analytical gradient; minute ion_mode negative “positive” or “negative” mz_tol_ms1 0.01 m/z tolerance for MS1 spectra; Da mz_tol_ms2 0.015 m/z tolerance for MS2 spectra; Da int_tol 1000 Intensity tolerance; 1000 for TOF and 30000 for orbitrap align_mz_tol 0.01 m/z tolerance for alignment; Da align_rt_tol 0.2 retention time tolerance for alignment; minute msms_library path to the MS2 library; msp or pickle ms2_sim_tol 0.7 MS2 similarity tolerance run_normalization TRUE TRUE or FALSE; whether to run post-acquisition sample normalization normalization_method pqn sample normalization algorithm plot_bpc FALSE TRUE or FALSE; whether to plot base peak chromatogram for individual files plot_ms2 TRUE TRUE or FALSE; whether to plot mirror plots for MS2 matching run_statistics TRUE TRUE or FALSE; whether to run statistical analysis ","default-parameters#Default parameters":"masscube automatically acquire the analytical metadata from the raw files including the mass spectrometer type and ionization mode. The corresponding default parameters will be applied based on the metadata.","key-parameters#Key parameters":"Here we summarized six most important parameters in masscube for untargeted metabolomics data processing:\nMS1 mass tolerance: the mass tolerance for MS1 feature detection. 0.005-0.01 Da is recommended. Intensity tolerance: the intensity tolerance for MS signals. 1000 is recommended for TOF data, and 30000 is recommended for Orbitrap data. Mass tolerance for alignement: the mass tolerance for feature alignment. 0.01-0.015 Da is recommended. RT tolerance for alignment: the RT tolerance for feature alignment. 0.1-0.3 min is recommended. MS/MS similarity score threshold: the threshold for MS/MS similarity score. 0.7-0.8 is recommended. MS/MS library: the MS/MS library for MS/MS annotation. ","more-about-parameters#More about parameters":"Almost all parameters in masscube are tunable to ensure flexibility and adaptability for different datasets. For programmers, please refer to each function and object in the API documentation for more details."},"title":"Parameters"},"/docs/workflows/targeted_metabolomics/":{"data":{"":"Workflow is under development. Please check back later."},"title":"Targeted metabolomics"},"/docs/workflows/untargeted_metabolomics/":{"data":{"":"","explainations-of-the-workflow#Explainations of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 12 def untargeted_metabolomics_workflow(path=None, batch_size=100, cpu_ratio=0.8): \"\"\" Parameters ---------- path : str The working directory. If None, the current working directory is used. batch_size : int The number of files to be processed in each batch. This is used to control the memory usage. cpu_ratio : float The ratio of CPU cores to be used. \"\"\" ... Step 1. Define or load parameters The parameters are critical for MS data processing. However, setting parameters are often challenging, especially for beginners or scientists who are not familiar with the MS data.\nmasscube automatically read the MS data and apply the corresponding default parameters. Users can also customize the parameters by providing a parameter file.\nStep 2. Load sample table and organize data A sample table is used to claim the name of samples and their groups. In most metabolomics studies, quality control samples and blank samples are included. masscube automatically apply normalization and statistical analysis if the sample table is provided.\nStep 3. Single file processing Individual files are processed for feature detection, which envolves the detection of peak apex, edges, area, and related MS/MS spectra. It also includes the determination of isotopes, charge states, adducts, and in-source fragments.\nTo accelerate the processing, masscube supports parallel computing for multiple files. By default, the number of threads is set to be the 80% (cpu_ratio=0.8) of the total CPU cores so that the computer can still be used for other tasks.\nTo control the memory usage, the files are processed in batches. The default batch size is 100 (batch_size=100).\nMore details about the feature detection can be found here.\nStep 4. Feature alignment Feature alignment aims to match the same feature across different samples. The alignment is based on the mass-to-charge ratio and retention time. The mass tolerance and retention time tolerance are critical for the alignment. See alignment for more details.\nStep 5. Gap filling Gap filling is critical for the downstream statistical analysis, and missing values are treated by forced peak detection. See gap filling for more details.\nStep 6. MS/MS annotation Compound annotation was performed by matching the experimental MS/MS spectra with the MS/MS library. The MS/MS similarity score is generated to indicate the confidence of the annotation.\nFlash entropy search is used to accelerate the annotation. masscube also provides analog search (i.e. hybrid search) for unknown discovery. See annotation for more details.\nStep 7. Normalization Two types of normalization could be needed in metabolomics to address the systematic signal drifts and the sample-to-sample variation (i.e. total amount/concentration difference). masscube provides multiple post-acquisition normalization algorithms to address the normalization issue. See normalization for more details.\nStep 8. Statistical analysis Univariate and multivariate statistical analysis will be performed if sample table is provided. The results will be saved in the statistics folder. See statistics for more details.\nStep 9. Data visualization Users can choose to plot the base peak chromatogram (BPC) to verify possible bad injections or outliers. The MS/MS matching plots are generated for the annotated compounds. PCA plots are generated for the statistical analysis. See visualization for more details.","how-to-use#How to use":"To use the OneClick untargeted metabolomics workflow, please refer to the quick start guide.","introduction#Introduction":"Data processing is critical for metabolomics studies. A series of steps are required to process the raw data to generate biological hypothesis that can be further validated.\nThe OneClick untargeted metabolomics workflow aims to address the burdens in mass spectrometry-based metabolomics data processing. It integrates metadata curation, feature detection, evaluation, alignment, annotation, and statistical analysis to provide users with a comprehensive view of the data."},"title":"Untargeted metabolomics"}}