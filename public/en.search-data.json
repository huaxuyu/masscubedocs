{"/about/":{"data":{"":"The MassCube project is developed by Dr. Huaxu Yu, a postdoctoral researcher in the Prof. Oliver Fiehn’s lab at the University of California, Davis.","contact#Contact":"Please contact us for any questions or suggestions. We welcome contributions to the documentation, code, and workflows.\nCorresponding author: Oliver Fiehn: ofiehn@ucdavis.edu\nDeveloper and maintainer: Huaxu Yu: hxuyu@ucdavis.edu; yhxchem@outlook.com","teams#Teams":"Our teams are organized as follows:\nCode and software development Documentation and website Researcher team for testing and validation Labs and researchers interested in collaborating with us are welcome to contact us. Now we have the following labs working together:\nFiehn Lab Huan Lab "},"title":"About Us"},"/contribute/":{"data":{"":"Please contact us for any questions or suggestions. We welcome contributions to the documentation, code, and workflows.\nCorresponding author: Oliver Fiehn: ofiehn@ucdavis.edu\nDeveloper and maintainer: Huaxu Yu: hxuyu@ucdavis.edu; yhxchem@outlook.com"},"title":"Contribute"},"/docs/":{"data":{"":"Hello! Welcome to the MassCube documentation!\nDate: 2024-05-29 Version: 1.0.0","features#Features":" Open-source: MassCube is an open-source project and free for non-commercial use.\nModular design: MassCube is designed with a modular structure, which allows users to easily extend the functionalities.\nUser-friendly: MassCube provides a user-friendly command-line interface (CLI) to facilitate data processing.\nScalable: MassCube handles large-scale metabolomics data efficiently and memory-friendly.\nReproducible: A project file contains all the parameters and package versions used in the analysis, which ensures reproducibility.\nVisualization: MassCube provides visualization tools to help users understand the data better.","getting-started#Getting Started":" Installation Quick Start ","what-is-masscube#What is MassCube?":"The advancement of metabolomics requires robust tools to support mass spectrometry data processing.\nMassCube, an open-source computing framework in Python that provides a flexible infrastructure to support data processing and method development in mass spectrometry-based metabolomics."},"title":"Documentation"},"/docs/algorithms/":{"data":{"":"","data-import-and-metadata-curation#Data import and metadata curation":"masscube provides fundemental and novel algorithms for mass spectrometry data processing. These algorithms are designed to improve the accuracy and efficiency of data processing and analysis. The proposed algorithms covers the following aspects:\nData import and metadata curation ","heading#":""},"title":"Algorithms"},"/docs/algorithms/alignment/":{"data":{"":"Application-oriented workflows as command line applications.","introduction#Introduction":"Mass spectrometry data processing is application-oriented, tailored to meet the specific needs of diverse scientific investigations.\nOne of the main purpose of MassCube is to provide a flexible and robust data processing framework that can be adapted to various applications. Here, we provided a series of pre-defined workflows that can be used as command line applications."},"title":"alignment"},"/docs/api/":{"data":{"":"All the functions and objects in masscube are documented in the API reference. The API reference is generated from the source code using the pdoc package. The API reference is available at https://masscube.github.io/masscube/api/."},"title":"APIs"},"/docs/api/raw_data_utils/":{"data":{"":" "},"title":"raw_data_utils"},"/docs/installation/":{"data":{"":"","install-_masscube_#Install \u003cem\u003emasscube\u003c/em\u003e":"Install Python Visit the official Python website to download Python.\nDownload Python 3.11 Python 3.9-3.11 is recommended. Download Python 3.11. IMPORTANT: Make sure to check the box that says “Add Python to PATH” during installation.\nInstall masscube masscube is a Python package that can be installed using pip. Open terminal and run\npip install masscube To update the package to the latest version, open terminal and run\npip install masscube --upgrade Dependencies will be automatically installed. Consider creating a virtual environment if you’re working with Python on multiple projects.\nDependencies dependencies = [ \"numpy==1.24\", \"pandas==2.2.1\", \"pyteomics==4.6.3\", \"scipy==1.10.1\", \"tqdm==4.66.1\", \"lxml==4.9.3\", \"matplotlib==3.8.2\", \"ms_entropy==1.1.1\", \"networkx==3.2.1\", \"scikit-learn==1.3.2\" ] ","install-python#Install Python":""},"title":"Installation"},"/docs/plans/":{"data":{"":"We are working on the following features and improvements and welcome contributions from the community.\nTargeted metabolomics workflows\nIsotope-based refinement of feature annotation\nMore data normalization algorithms and evaluation metrics\nWorkflows and functions for data-independent acquisition (DIA) data.\nMS imaging data processing","contact#Contact":"Please contact us if you are interested in contributing to any of these features.\nCorresponding author: Oliver Fiehn: ofiehn@ucdavis.edu\nDeveloper and maintainer: Huaxu Yu: hxuyu@ucdavis.edu; yhxchem@outlook.com"},"title":"Plans for development"},"/docs/quickstart/":{"data":{"":"Let’s get started with the OneClick untargeted metabolomics workflow. This workflow is designed to streamline untargeted metabolomics analysis, providing comprehensive results with a single command.\nIf you haven’t installed MassCube, please follow the installation guide.","the-oneclick-untargeted-metabolomics-workflow#The OneClick untargeted metabolomics workflow":"Metabolomics data processing could be challenging for researchers. The OneClick untargeted metabolomics workflow was developed to address the burdens and support metabolomics research.\nThe OneClick workflow integrates metadata curation, feature detection, evaluation, alignment, annotation, and statistical analysis to provide users with a comprehensive view of the data (Fig. 1).\nFig. 1. The OneClick untargeted metabolomics workflow Input (3+1) You need three components for the project plus one MS/MS library for annotation.\nIn your project folder (e.g. my_project), you need to prepare the following components:\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... |── sample_table.csv └── parameters.csv data folder: a file folder containing all raw LC-MS data in .mzML or .mzXML format. It’s mandatory. Instructions for file conversion are provided here.\nsample_table.csv file: a csv file to claim the sample groups including biological groups, quality control samples, or blank samples. A template can be downloaded from here. It’s optional. If not provided, normalization and statistical analysis will not be applied. Note: In sample table, please name quality control samples as “qc” and blank samples as “blank” (not case-sensitive).\nparameters.csv file: a csv file to set parameters for the workflow. A template can be downloaded from here. It’s optional. If not provided, the default parameters will be applied, yet annotation will not be performed since the MS/MS library is not provided.\nMS2 database: To annotate MS/MS spectra, you need to download a MS/MS library from here. For faster database loading, please download and use the .pkl format.\nExtra component for annotation:\nmzrt_list.csv file: a csv file to provide the m/z and retention time for feature annotation. It was designed to annotate full-scan MS data or annotate the spiked internal standards. A template can be downloaded from here. It’s optional. If not provided, the annotation will not be performed. Data Preparation Processing In the project folder, open a terminal and run the following command:\nuntargeted-metabolomics How to open the terminal Make sure the terminal directory is set to the project folder. For Windows user and MacOS user Output After the processing, you will find the following files and folders in the project folder:\nproject/ ├── data ├── sample_table.csv ├── parameters.csv ├── project.mc ├── aligned_feature_table.txt ├── aligned_feature_table_before_normalization.txt ├── ms2.msp ├── single_file_output │ ├── sample1.txt │ ├── sample2.txt │ └── ... ├── chromatogram │ ├── sample1.png │ ├── sample2.png │ └── ... ├── ms2_matching │ ├── compound1.png │ ├── compound2.png │ └── ... ├── statistics ├── ... project.mc file: the project file of masscube. aligned_feature_table.csv file: feature table after alignment (if applied). aligned_feature_table_before_normalization.csv file: feature table before normalization. ms2.msp file: MS/MS spectra for detected features that can be further analyzed on other platforms. single_file_output folder: a folder containing the feature table for each sample. chromatogram folder: a folder containing the chromatogram for each sample. ms2_matching folder: a folder containing the MS/MS matching for each annotated compound. statistics folder: a folder containing the statistical analysis results. "},"title":"Quick start"},"/docs/workflows/":{"data":{"":"Mass spectrometry data processing is application-oriented, tailored to meet the specific needs of diverse scientific investigations.\nOne of the main purposes of MassCube is to provide a flexible and robust data processing framework that can be adapted to various applications. To achieve this, we offer a series of pre-defined workflows that can be used as command line applications.\nThe pre-defined workflows are combinations of the core functions in MassCube. We encourage users to explore the workflows and customize them to meet their specific needs.\nWondering how to contribute to the workflows? Please refer to the contribution guide."},"title":"Workflows"},"/docs/workflows/batch_processing/":{"data":{"":"","explainations-of-the-workflow#Explainations of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def batch_file_processing(path=None, batch_size=100, cpu_ratio=0.8): \"\"\" The untargeted metabolomics workflow. See the documentation for details. Parameters ---------- path : str The working directory. If None, the current working directory is used. batch_size : int The number of files to be processed in each batch. cpu_ratio : float The ratio of CPU cores to be used. \"\"\" ... Step 1. Define or load parameters The parameters are critical for MS data processing. However, setting parameters are often challenging, especially for beginners or scientists who are not familiar with the MS data.\nmasscube automatically read the MS data and apply the corresponding default parameters. Users can also customize the parameters by providing a parameter file.\nStep 2. Single file processing Individual files are processed for feature detection, which envolves the detection of peak apex, edges, area, and related MS/MS spectra. It also includes the determination of isotopes, charge states, adducts, and in-source fragments.\nTo accelerate the processing, masscube supports parallel computing for multiple files. By default, the number of threads is set to be the 80% (cpu_ratio=0.8) of the total CPU cores so that the computer can still be used for other tasks.\nTo control the memory usage, the files are processed in batches. The default batch size is 100 (batch_size=100).\nMore details about the feature detection can be found here.\nStep 3. Data visualization Users can choose to plot the base peak chromatogram (BPC) to verify possible bad injections or outliers.","how-to-use#How to use":" Organize the data Similar to the untargeted metabolomics workflow, the data should be organized in the following structure:\nYou need two components for the project plus one MS/MS library for annotation.\nIn your project folder (e.g. my_project), you need to prepare the following components:\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... └── parameters.csv Processing In the project folder, open a terminal and run the following command:\nprocess-files Output After the processing, you will find the following files and folders in the project folder:\nproject/ ├── data ├── parameters.csv ├── project.mc ├── single_file_output │ ├── sample1.txt │ ├── sample2.txt │ └── ... ├── chromatogram │ ├── sample1.png │ ├── sample2.png │ └── ... ├── ... project.mc file: the project file of masscube. single_file_output folder: a folder containing the feature table for each sample. chromatogram folder: a folder containing the chromatogram for each sample. ","introduction#Introduction":"Processing each raw LC-MS data individually can be useful for further customized analysis. In this workflow, we introduce how to process single files in batch mode using masscube. Note, the processed files will not be aligned across samples. Users may employ the OneClick untargeted metabolomics workflow for comprehensive data processing."},"title":"Batch processing"},"/docs/workflows/data_preparation/":{"data":{"":"","file-conversion#File conversion":"Raw LC-MS data need to be converted to mzML or mxXML format.\nOnly centroid data are supported in masscube to maximize the speed and reduce the memory usage. We recommend to use ProteoWizard for file conversion.\nDownload and install ProteoWizard Visit the official website to download ProteoWizard.\nFile conversion using MSConvert Fig. 1. MSConvert GUI Step 1. Set options Check the boxes as shown in Fig. 1.\n⚠️ Do NOT check Use Zlib compression. Step 2. Set the Peak Picking filter Step 3. Add the Peak Picking filter Step 4. Browse and load files Step 5. Start conversion By default, the converted files will be saved in the same directory as the raw files.\nConvert files in command line mode You can also convert files using MSConvert in command line mode. For more information, please refer to the documentation. ","parameter-file#Parameter file":"A parameter file (.csv) is used to set parameters for the workflow. A templete is provided here. If not provided, the default parameters will be applied.","sample-table-for-the-oneclick-workflow#Sample table (for the OneClick workflow)":"A sample table (.csv) is used to claim the name of samples and their groups including biological groups, quality control samples, or blank samples. A templete is provided here.\nFor large-scale metabolomics data, it’s not easy to prepare the sample table manually. In masscube, we provide a function to automatically generate the sample table based on the file names in the data folder, and users can further define the groups.\nGenerate sample table In the project folder, open a terminal and run the following command:\ngenerate-sample-table "},"title":"Data preparation"},"/docs/workflows/find-outliers/":{"data":{"":"","explanation-of-the-workflow#Explanation of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 def run_evaluation(path): \"\"\" Evaluate the run and report the problematic files. Parameters ---------- path : str Path to the mzML or mzXML files. \"\"\" ... The run_evaluation function evaluates the run and reports the problematic files. It checks the quality of the raw data and identifies the problematic samples based on the number of detected features.\nThe function generates a problematic_samples.txt file that lists the names of the problematic samples. Users can further investigate the outliers and decide whether to remove them before downstream analysis.\nStep 1. Fast untargeted feature detection A fast untargeted feature detection algorithm is applied to the raw data. The algorithm automatically applies the default parameters for feature detection based on the metadata of the raw files. Parameters are not needed to be set by the users.\nStep 2. Find outliers The total number of features detected in each sample is calculated. Samples with total feature numnber deviating from the mean by more than 3 standard deviations are considered as outliers.\nStep 3. Report problematic samples The names of the problematic samples are saved in the problematic_samples.txt file. Users can further investigate the outliers and decide whether to remove them before downstream analysis.","how-to-use#How to use":" Step 1. Organize the data Put all the raw data files in a folder. The data should be organized in the following structure:\ndata ├── sample1.mzML ├── sample2.mzML └── ... Note: do NOT include blank samples in the data folder or provide a sample table to specify the blank samples.\nStep 2. Run the outlier detection In the data folder, open a terminal and run the following command:\nfind-outliers Output After the processing, you will find the following files and folders in the data folder:\ndata ├── sample1.mzML ├── sample2.mzML ├── ... ├── problematic_samples.txt problematic_samples.txt: a text file containing the names of the problematic samples. ","introduction#Introduction":"Outliers are data points that are significantly different from the rest of the data. In metabolomics, outliers can be caused by various reasons, such as instrument error, sample preparation, or biological variation. It is important to identify and remove outliers before downstream analysis to avoid misleading results.\nmasscube evaluate the analytical sequnce and report the problematic samples in an unsupervised manner. It checks the quality of the raw data and identifies the problematic samples based on the number of detected features."},"title":"Outlier detection"},"/docs/workflows/parameters/":{"data":{"":"Parameters are critical for MS data processing. However, setting parameters are often challenging, especially for beginners. masscube provides a default parameter setting for users to start with.\nThe default parameters are optimized for most untargeted metabolomics studies. Users can also customize the parameters by providing a parameter file.","customize-parameters#Customize parameters":"From the template, users can customize the parameters by providing a parameter file. The parameter file should be a .csv file with the following columns:\nParameter Value Explanation rt_start 0 start of the analytical gradient; minute rt_end 23 end of the analytical gradient; minute ion_mode negative “positive” or “negative” mz_tol_ms1 0.01 m/z tolerance for MS1 spectra; Da mz_tol_ms2 0.015 m/z tolerance for MS2 spectra; Da int_tol 1000 Intensity tolerance; 1000 for TOF and 30000 for orbitrap align_mz_tol 0.01 m/z tolerance for alignment; Da align_rt_tol 0.2 retention time tolerance for alignment; minute msms_library path to the MS2 library; msp or pickle ms2_sim_tol 0.7 MS2 similarity tolerance run_normalization TRUE TRUE or FALSE; whether to run post-acquisition sample normalization normalization_method pqn sample normalization algorithm plot_bpc FALSE TRUE or FALSE; whether to plot base peak chromatogram for individual files plot_ms2 TRUE TRUE or FALSE; whether to plot mirror plots for MS2 matching run_statistics TRUE TRUE or FALSE; whether to run statistical analysis ","default-parameters#Default parameters":"masscube automatically acquire the analytical metadata from the raw files including the mass spectrometer type and ionization mode. The corresponding default parameters will be applied based on the metadata.","key-parameters#Key parameters":"Here we summarized six most important parameters in masscube for untargeted metabolomics data processing:\nMS1 mass tolerance: the mass tolerance for MS1 feature detection. 0.005-0.01 Da is recommended. Intensity tolerance: the intensity tolerance for MS signals. 1000 is recommended for TOF data, and 30000 is recommended for Orbitrap data. Mass tolerance for alignement: the mass tolerance for feature alignment. 0.01-0.015 Da is recommended. RT tolerance for alignment: the RT tolerance for feature alignment. 0.1-0.3 min is recommended. MS/MS similarity score threshold: the threshold for MS/MS similarity score. 0.7-0.8 is recommended. MS/MS library: the MS/MS library for MS/MS annotation. ","more-about-parameters#More about parameters":"Almost all parameters in masscube are tunable to ensure flexibility and adaptability for different datasets. For programmers, please refer to each function and object in the API documentation for more details."},"title":"Parameters"},"/docs/workflows/targeted_metabolomics/":{"data":{"":"","introduction#Introduction":"Data processing for targeted metabolomics envolves the detection of the metabolites of interest. A list of molecules is needed to specify the targets. The targeted metabomics workflow is under development. Please stay tuned for the updates."},"title":"Targeted metabolomics"},"/docs/workflows/untargeted_metabolomics/":{"data":{"":"","explainations-of-the-workflow#Explainations of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 12 def untargeted_metabolomics_workflow(path=None, batch_size=100, cpu_ratio=0.8): \"\"\" Parameters ---------- path : str The working directory. If None, the current working directory is used. batch_size : int The number of files to be processed in each batch. This is used to control the memory usage. cpu_ratio : float The ratio of CPU cores to be used. \"\"\" ... Step 1. Define or load parameters The parameters are critical for MS data processing. However, setting parameters are often challenging, especially for beginners or scientists who are not familiar with the MS data.\nmasscube automatically read the MS data and apply the corresponding default parameters. Users can also customize the parameters by providing a parameter file.\nStep 2. Load sample table and organize data A sample table is used to claim the name of samples and their groups. In most metabolomics studies, quality control samples and blank samples are included. masscube automatically apply normalization and statistical analysis if the sample table is provided.\nStep 3. Single file processing Individual files are processed for feature detection, which envolves the detection of peak apex, edges, area, and related MS/MS spectra. It also includes the determination of isotopes, charge states, adducts, and in-source fragments.\nTo accelerate the processing, masscube supports parallel computing for multiple files. By default, the number of threads is set to be the 80% (cpu_ratio=0.8) of the total CPU cores so that the computer can still be used for other tasks.\nTo control the memory usage, the files are processed in batches. The default batch size is 100 (batch_size=100).\nMore details about the feature detection can be found here.\nStep 4. Feature alignment Feature alignment aims to match the same feature across different samples. The alignment is based on the mass-to-charge ratio and retention time. The mass tolerance and retention time tolerance are critical for the alignment. See alignment for more details.\nStep 5. Gap filling Gap filling is critical for the downstream statistical analysis, and missing values are treated by forced peak detection. See gap filling for more details.\nStep 6. MS/MS annotation Compound annotation was performed by matching the experimental MS/MS spectra with the MS/MS library. The MS/MS similarity score is generated to indicate the confidence of the annotation.\nFlash entropy search is used to accelerate the annotation. masscube also provides analog search (i.e. hybrid search) for unknown discovery. See annotation for more details.\nStep 7. Normalization Two types of normalization could be needed in metabolomics to address the systematic signal drifts and the sample-to-sample variation (i.e. total amount/concentration difference). masscube provides multiple post-acquisition normalization algorithms to address the normalization issue. See normalization for more details.\nStep 8. Statistical analysis Univariate and multivariate statistical analysis will be performed if sample table is provided. The results will be saved in the statistics folder. See statistics for more details.\nStep 9. Data visualization Users can choose to plot the base peak chromatogram (BPC) to verify possible bad injections or outliers. The MS/MS matching plots are generated for the annotated compounds. PCA plots are generated for the statistical analysis. See visualization for more details.","how-to-use#How to use":"To use the OneClick untargeted metabolomics workflow, please refer to the quick start guide.","introduction#Introduction":"Data processing is critical for metabolomics studies. A series of steps are required to process the raw data to generate biological hypothesis that can be further validated.\nThe OneClick untargeted metabolomics workflow aims to address the burdens in mass spectrometry-based metabolomics data processing. It integrates metadata curation, feature detection, evaluation, alignment, annotation, and statistical analysis to provide users with a comprehensive view of the data."},"title":"Untargeted metabolomics"}}