{"/about/":{"data":{"":"The MassCube project is developed by Dr. Huaxu Yu, a postdoctoral researcher in the Prof. Oliver Fiehn’s lab at the University of California, Davis.","contact#Contact":"Please contact us for any questions or suggestions. We welcome contributions to the documentation, code, and workflows.\nCorresponding author: Oliver Fiehn: ofiehn@ucdavis.edu\nDeveloper and maintainer: Huaxu Yu: hxuyu@ucdavis.edu; yhxchem@outlook.com","teams#Teams":"Our teams are organized as follows:\nCode and software development Documentation and website Researcher team for testing and validation Labs and researchers interested in collaborating with us are welcome to contact us. Now we have the following labs working together:\nFiehn Lab Huan Lab "},"title":"About Us"},"/contribute/":{"data":{"":"We welcome contributions to the code, workflows, and documentation.\nCorresponding author: Oliver Fiehn: ofiehn@ucdavis.edu\nDeveloper and maintainer: Huaxu Yu: hxuyu@ucdavis.edu; yhxchem@outlook.com"},"title":"Contribute"},"/docs/":{"data":{"":"Hello! Welcome to the MassCube documentation!\nDate: 2025-01-07 Version: 1.1.11","features#Features":" Open-source: Free for non-commercial use.\nModular design: Easily extendable functionalities.\nUser-friendly: Command-line interface for easy data processing.\nScalable: Efficient and memory-friendly handling of large-scale metabolomics data.\nReproducible: Metadata tracking for recording parameters, dependencies, and module order.\nVisualization: Tools for intuitive data exploration and publication-quality figure creation.","getting-started#Getting Started":" Installation Quick Start ","what-is-masscube#What is MassCube?":"MassCube is an open-source computing library and framework for MS data processing in Python. It supports comprehensive functionalities and workflows designed for versatile data processing tasks."},"title":"Documentation"},"/docs/algorithms/":{"data":{"":"We are preparing figures to explain the algorithms used in masscube.\nPlease check our publication for details."},"title":"Algorithms"},"/docs/api/":{"data":{"":"All functions and objects in MassCube are documented in the API reference. Version 1.1 of MassCube includes 16 modules designed to manage a variety of data processing tasks, featuring core objects specifically tailored for MS data, particularly data generated from LC-MS experiments.\nMassCube modules masscube ├───init ├───alignment ├───annotation ├───classifier_builder ├───feature_detection ├───feature_evaluation ├───feature_grouping ├───mzpkl ├───network ├───normalization ├───params ├───raw_data_utils ├───stats ├───utils_functions ├───visualization └───workflows "},"title":"APIs"},"/docs/api/alignment/":{"data":{"":"","classes#Classes":"AlignedFeature A class to model a feature in mass spectrometry data. Generally, a feature is defined as a unique pair of m/z and retention time.\nAttributes:\nfeature_id_arr (np.array): Feature ID from individual files (-1 if not detected or gap filled). mz_arr (np.array): m/z values. rt_arr (np.array): Retention times. scan_idx_arr (np.array): Scan index of the peak apex. peak_height_arr (np.array): Peak height. peak_area_arr (np.array): Peak area. top_average_arr (np.array): Average of the highest three intensities. ms2_seq (list): Representative MS2 spectrum from each file (default: highest total intensity). length_arr (np.array): Length (i.e. non-zero scans in the peak). gaussian_similarity_arr (np.array): Gaussian similarity. noise_score_arr (np.array): Noise score. asymmetry_factor_arr (np.array): Asymmetry factor. sse_arr (np.array): Squared error to the smoothed curve. is_segmented_arr (np.array): Whether the peak is segmented. id (int): Index of the feature. feature_group_id (int): Feature group ID. mz (float): m/z. rt (float): Retention time. reference_file (str): The reference file with the highest peak height. reference_scan_idx (int): The scan index of the peak apex from the reference file. highest_intensity (float): The highest peak height from individual files (which is the reference file). ms2 (str): Representative MS2 spectrum. ms2_reference_file (str): The reference file for the representative MS2 spectrum. gaussian_similarity (float): Gaussian similarity from the reference file. noise_score (float): Noise level from the reference file. asymmetry_factor (float): Asymmetry factor from the reference file. detection_rate (float): Number of detected files / total number of files (blank not included). detection_rate_gap_filled (float): Number of detected files after gap filling / total number of files (blank not included). charge_state (int): Charge state. is_isotope (bool): Whether it is an isotope. isotope_signals (list): Isotope signals [[m/z, intensity], …]. is_in_source_fragment (bool): Whether it is an in-source fragment. adduct_type (str): Adduct type. annotation_algorithm (str): Annotation algorithm. Not used now. search_mode (str): ‘identity search’, ‘fuzzy search’, or ‘mzrt_search’. similarity (float): Similarity score (0-1). annotation (str): Name of annotated compound. formula (str): Molecular formula. matched_peak_number (int): Number of matched peaks. smiles (str): SMILES. inchikey (str): InChIKey. matched_precursor_mz (float): Matched precursor m/z. matched_adduct_type (str): Matched adduct type. matched_ms2 (str): Matched ms2 spectra. ","functions#Functions":"feature_alignment feature_alignment(path: str, params: Params)\nAlign the features from multiple processed single files as .txt format.\nParameters:\npath (str): The path to the feature tables of individual files. params (Params object): The parameters for alignment including sample names and sample groups. Returns:\nfeatures (list of AlignedFeature objects) gap_filling gap_filling(features, params: Params)\nFill the gaps for aligned features.\nParameters:\nfeatures (list of AlignedFeature objects): The aligned features. parameters (Params object): The parameters used for gap filling. Returns:\nfeatures (list of AlignedFeature objects). merge_features merge_features(features: list, params: Params)\nClean features by merging features with almost the same m/z and retention time.\nParameters:\nfeatures (list of AlignedFeature objects): The aligned features. params (Params object): The parameters used for merging features. Returns:\nfeatures (list of AlignedFeature objects).\nconvert_features_to_df convert_features_to_df(features, sample_names, quant_method=\"peak_height\")\nConvert the aligned features to a DataFrame.\nParameters:\nfeatures (list of AlignedFeature objects): The aligned features. sample_names (list): The sample names. quant_method (str): The quantification method, “peak_height”, “peak_area” or “top_average”. Returns:\nfeature_table (pd.DataFrame): The feature DataFrame. output_feature_to_msp output_feature_to_msp(feature_table, output_path)\nOutput MS2 spectra to MSP format.\nParameters:\nfeature_table (pd.DataFrame): The feature table. output_path (str): The path to the output MSP file. output_feature_table output_feature_table(feature_table, output_path)\nOutput the aligned feature table.\nParameters:\nfeature_table (pd.DataFrame): The aligned feature table. output_path (str): The path to save the aligned feature table. retention_time_correction retention_time_correction(mz_ref, rt_ref, mz_arr, rt_arr, mz_tol=0.01, rt_tol=2.0, mode='linear_interpolation', rt_max=None)\nCorrect retention times for feature alignment. There are three steps including (1) finding the selected anchors in the given data, (2) creating a model to correct retention times, and (3) correcting retention times.\nParameters:\nmz_ref (np.array): The m/z values of the selected anchors from another reference file. rt_ref (np.array): The retention times of the selected anchors from another reference file. mz_arr (np.array): Feature m/z values in the current file. rt_arr (np.array): Feature retention times in the current file. mz_tol (float): The m/z tolerance for selecting anchors. rt_tol (float): The retention time tolerance for selecting anchors. mode (str): The mode for retention time correction. Only ’linear_interpolation’ is available now. rt_max (float): End of the retention time range. Returns:\nrt_arr (np.array): The corrected retention times. f (interp1d): The model for retention time correction. rt_anchor_selection rt_anchor_selection(data_path, num=50, noise_score_tol=0.1, mz_tol=0.01)\nSelect retention time anchors from the feature tables. Retention time anchors have unique m/z values and low noise scores. From all candidate features, the top num features with the highest peak heights are selected as anchors.\nParameters:\ndata_path (str): The absolute directory to the feature tables. num (int): The number of anchors to be selected. noise_score_tol (float): The noise level for the anchors. mz_tol (float): The m/z tolerance for selecting anchors. Returns:\nanchors (list): A list of anchors (dict) for retention time correction. ","overview#Overview":"This module provides functionality for aligning metabolic features from different samples in mass spectrometry data.\nFeature alignment: Align features across different samples, considering parameters like m/z tolerance and retention time tolerance. Gap filling: Fill in missing features across aligned samples using various strategies. Merge features: Clean feature table by merging features with almost the same m/z and retention time. Retention time correction: Correct retention times to align features more accurately. Output feature table: Save the aligned features to a file. "},"title":"alignment"},"/docs/api/annotation/":{"data":{"":"","functions#Functions":"load_ms2_db load_ms2_db(path)\nLoad MS2 database in pickle, msp, or json format.\nParameters:\npath (str): The path to the MS2 database. Returns:\nentropy_search (FlashEntropySearch object): The MS2 database. annotate_aligned_features annotate_aligned_features(features, params, num=5)\nAnnotate feature’s MS2 using database.\nParameters:\nfeatures (list): A list of AlignedFeature objects. params (Params object): The parameters for the workflow. num (int): The number of top MS2 spectra to search. Returns:\nfeatures (list): A list of AlignedFeature objects with MS2 annotation. annotate_features Annotate features from a single raw data file using MS2 database.\nannotate_features(d, sim_tol=None, fuzzy_search=True, ms2_library_path=None)\nParameters:\nd (MSData object): MS data file. sim_tol (float): The similarity threshold for MS2 annotation. If not specified, the corresponding parameter from the MS data file will be used. fuzzy_search (bool): Whether to further annotated the unmatched MS2 using fuzzy search. ms2_library_path (str): The absolute path to the MS2 database. If not specified, the corresponding parameter from the MS data file will be used. annotate_ms2 Annotate MS2 spectra using MS2 database.\nannotate_ms2(ms2, ms2_library_path, sim_tol=0.7, fuzzy_search=True)\nParameters:\nms2 (Scan object): MS2 spectrum. ms2_library_path (str): The absolute path to the MS2 database. If not specified, the corresponding parameter from the MS data file will be used. sim_tol (float): The similarity threshold for MS2 annotation. fuzzy_search (bool): Whether to further annotated the unmatched MS2 using fuzzy search. Returns:\nscore (float): The similarity score. matched (dict): The matched MS2 spectrum. matched_peak_num (int): The number of matched peaks. search_mode (str): The search mode, ‘identity_search’ or ‘fuzzy_search’. feature_annotation_mzrt feature_annotation_mzrt(features, path, mz_tol=0.01, rt_tol=0.3)\nAnnotate features based on a mzrt file (only .csv is supported now)\nParameters:\nfeatures (list): A list of features. path (str): The path to the mzrt file in csv format. mz_tol (float): The m/z tolerance for matching. rt_tol (float): The RT tolerance for matching. Returns:\nfeatures (list): A list of features with annotation. feature_to_feature_search feature_to_feature_search(feature_list)\nCalculate the MS2 similarity between features using fuzzy search.\nParameters:\nfeature_list (list): A list of AlignedFeature objects. Returns:\nsimilarity_matrix (pandas.DataFrame): A DataFrame containing the similarity matrix between features. index_feature_list index_feature_list(feature_list)\nA helper function to index a list of features for spectrum entropy search.\nParameters:\nfeature_list (list): A list of AlignedFeature objects. Returns:\nentropy_search (FlashEntropySearch object): The indexed feature list. output_ms2_to_msp output_ms2_to_msp(feature_table, output_path)\nOutput MS2 spectra to MSP format\nParameters:\nfeature_table (pandas.DataFrame): A DataFrame containing the MS2 spectra. output_path (str): The path to the output MSP file. ","overview#Overview":"This module is designed for annotating metabolites based on their m/z, retention time, and MS/MS spectra."},"title":"annotation"},"/docs/api/classifier_builder/":{"data":{"":"","functions#Functions":"feature_selection feature_selection(X, y, k=None)\nParameters:\nX (numpy.ndarray): The feature matrix. y (numpy.ndarray): The target variable. k (int): The number of features to select. By default, it is set to the number of samples divided by 10 (1/10 rule) and rounded up. Returns:\nX_new (numpy.ndarray): The selected features. selected_features (numpy.ndarray): The indices of the selected features. def feature_selection(X, y, k=None): \"\"\" Select features for the classification model.\nParameters ---------- X : two-dimensional numpy array The feature matrix. y : one-dimensional numpy array The target variable. k : int The number of features to select. By default, it is set to the number of samples divided by 10 (1/10 rule) and rounded up. Returns ------- X_new : two-dimensional numpy array The fit-transformed feature matrix. selected_features : one-dimensional numpy array The indices of the selected features. \"\"\" train_rdf_model train_rdf_model(X_train, y_train)\nParameters:\nX_train (numpy.ndarray): The feature matrix for training. y_train (numpy.ndarray): The target variable for training. Returns:\nmodel (RandomForestClassifier): The trained random forest model. cross_validate_model cross_validate_model(X, y, model, k=5, random_state=0)\nParameters:\nX (numpy.ndarray): The feature matrix. y (numpy.ndarray): The target variable. model (RandomForestClassifier): The trained random forest model. k (int): The number of folds for cross-validation. random_state (int): The random state for the shuffle in KFold. Returns:\nscores (list): The accuracy scores for each fold. predict predict(model, X_test)\nParameters:\nmodel (RandomForestClassifier): The trained random forest model. X_test (numpy.ndarray): The feature matrix for testing. Returns:\npredictions (numpy.ndarray): The predicted classes. evaluate_model evaluate_model(predictions, y_test)\nParameters:\npredictions (numpy.ndarray): The predicted classes. y_test (numpy.ndarray): The true classes. Returns:\naccuracy (float): The accuracy of the model. build_classifier build_classifier(path=None, by_group=None, feature_num=None, gaussian_cutoff=0.6, detection_rate_cutoff=0.9, fill_ratio=0.5, cross_validation_k=5)\nParameters:\npath (str): Path to the project file. feature_num (int): The number of features to select for building the model. gaussian_cutoff (float): The Gaussian similarity cutoff. Default is 0.6. fill_ratio (float): The zero values will be replaced by the minimum value in the feature matrix times fill_ratio. Default is 0.5. cross_validation_k (int): The number of folds for cross-validation. Default is 5. predict_samples predict_samples(path, mz_tol=0.01, rt_tol=0.3)\nParameters:\npath (str): Path to the project file. mz_tol (float): The m/z tolerance for matching the features. Default is 0.01. rt_tol (float): The retention time tolerance for matching the features. Default is 0.3. ","overview#Overview":"This module provides a set of tools for building and using a random forest classifier for metabolomics data analysis. It supports feature selection, model training, cross-validation, and prediction on new data."},"title":"classifier_builder"},"/docs/api/feature_detection/":{"data":{"":"","classes#Classes":"Feature A class to store a feature characterized by a unique pair of m/z and retention time.\nAttributes:\nrt_seq (list of float): Retention time sequence.\nsignals (list): Signal sequence organized as [[m/z, intensity], …].\nscan_idx_seq (list of int): Scan index sequence.\nms2_seq (list): MS2 spectra.\ngap_counter (int): Counter for the number of consecutive zeros in the peak tail.\nid (int): Feature ID.\nfeature_group_id (int): Peak group ID.\nmz (float): m/z value.\nrt (float): Retention time.\nscan_idx (int): Scan index of the peak apex.\npeak_height (float): Peak height.\npeak_area (float): Peak area.\ntop_average (float): Average of the highest three intensities.\nms2 (object): Representative MS2 spectrum.\nlength (int): Number of valid scans in the feature.\ngaussian_similarity (float): Gaussian similarity.\nnoise_score (float): Noise score.\nasymmetry_factor (float): Asymmetry factor.\nsse (float): Squared error to the smoothed curve.\nis_segmented (bool): Indicates if the feature is segmented.\nis_isotope (bool): Indicates if the feature is an isotope.\ncharge_state (int): Charge state of the feature.\nisotope_signals (list): Isotope signals [[m/z, intensity], …].\nis_in_source_fragment (bool): Indicates if the feature is an in-source fragment.\nadduct_type (str): Adduct type.\nannotation_algorithm (str): Annotation algorithm.\nsearch_mode (str): Search mode (‘identity search’, ‘fuzzy search’, or ‘mzrt_search’).\nsimilarity (float): Similarity score (0-1).\nannotation (str): Name of annotated compound.\nformula (str): Molecular formula.\nmatched_peak_number (int): Number of matched peaks.\nsmiles (str): SMILES notation.\ninchikey (str): InChIKey notation.\nmatched_precursor_mz (float): Matched precursor m/z.\nmatched_ms2 (object): Matched MS2 spectra.\nmatched_adduct_type (str): Matched adduct type.\nMethods:\nextend(self, rt, signal, scan_idx): Extends the chromatographic peak with new data points. get_mz_error(self): Calculates the 3*sigma error of the feature’s m/z. get_rt_error(self): Calculates the 3*sigma error of the feature’s retention time. summarize(self, ph=True, pa=True, ta=True, g_score=True, n_score=True, a_score=True): Summarizes the feature by calculating summary statistics. subset(self, start, end, summarize=True): Keeps a subset of the feature based on start and end positions. ","functions#Functions":"detect_features detect_features(d)\nDetects features in the MS data.\nParameters:\nd (MSData object): An object that contains the MS data. Returns:\nfinal_features (list of Feature objects): A list of detected features. segment_feature segment_feature(feature, sigma=1.2, prominence_ratio=0.05, distance=10, peak_height_tol=1000, length_tol=5, sse_tol=0.5)\nSegments a feature into multiple features based on edge detection.\nParameters:\nfeature (Feature object): The feature to segment. sigma (float): The sigma value for the Gaussian filter. DFault is 1.2. prominence_ratio (float): The prominence ratio for finding peaks. Default is 0.05. distance (int): The minimum distance between peaks. Default is 10. peak_height_tol (float): The peak height tolerance for segmentation. length_tol (int): The length tolerance for segmentation. Default is 5. sse_tol (float): The squared error tolerance for segmentation. Default is 0.5. Returns:\nsegmented_features (list of Feature objects): A list of segmented features. Please see the source code for more internal functions.","overview#Overview":"Untargeted feature detection."},"title":"feature_detection"},"/docs/api/feature_evaluation/":{"data":{"":"","functions#Functions":"calculate_gaussian_similarity calculate_gaussian_similarity(x, y)\nCalculates the Gaussian similarity of a peak by comparing its shape to a Gaussian distribution (Pearson product-moment correlation coefficients).\nParameters:\nx (numpy array): Retention time values of the peak. y (numpy array): Intensity values of the peak. Returns:\nsimilarity (float): Gaussian similarity score, where higher values indicate better similarity to a Gaussian distribution. calculate_noise_level calculate_noise_level(y, rel_int_tol=0.05)\nCalculates the noise level of a peak by observing the intensity fluctuations in the peak.\nParameters:\ny (numpy array): Intensity values of the peak. rel_int_tol (float): Relative intensity tolerance to the base peak. Returns:\nnoise_level (float): Noise level, reflecting the signal fluctuation. calculate_asymmetry_factor calculate_asymmetry_factor(y)\nCalculates the asymmetry factor of the peak at 10% of the peak height.\nParameters:\ny (numpy array): Intensity values of the peak. Returns:\nasymmetry_factor (float): Asymmetry factor, indicating the peak shape asymmetry. ","overview#Overview":"This module provides tools for evaluating the quality of detected features in untargeted metabolomics data. The quality metrics include Gaussian similarity, noise level, and asymmetry factor, which can help assess the reliability and robustness of detected peaks."},"title":"feature_evaluation"},"/docs/api/feature_grouping/":{"data":{"":"","constants#Constants":"ADDUCT_POS A dictionary of positive adducts with the adduct form as the key and the m/z shift, charge state, and multiplier as the values.\nADDUCT_NEG A dictionary of negative adducts with the adduct form as the key and the m/z shift, charge state, and multiplier as the values.","functions#Functions":"group_features_after_alignment group_features_after_alignment(features, params: Params)\nGroups features after alignment based on the reference file. This function requires reloading the raw data to examine the scan-to-scan correlation between features. The annotated feature groups are stored in the feature_group_id attribute of the AlignedFeature objects.\nParameters:\nfeatures (list): A list of AlignedFeature objects. params (Params object): A Params object that contains the parameters for feature grouping. group_features_single_file group_features_single_file(d)\nGroups features from a single file based on the m/z, retention time, MS2, and scan-to-scan correlation. The annotated feature groups are stored in the feature_group_id attribute of the Feature objects.\nParameters:\nd (MSData object): An MSData object containing the detected ROIs to be grouped. generate_search_dict generate_search_dict(feature, adduct_form, ion_mode)\nGenerates a search dictionary for feature grouping based on the adduct form and ionization mode.\nParameters:\nfeature (Feature object): The feature object to be grouped. adduct_form (str): The adduct form of the feature. ion_mode (str): The ionization mode, either “positive” or “negative”. Returns:\ndict: A dictionary containing the possible adducts and in-source fragments. find_isotope_signals find_isotope_signals(mz, signals, mz_tol=0.015, charge_state=1, num=5)\nFinds isotope patterns from the MS1 signals based on the m/z value and intensity.\nParameters:\nmz (float): The m/z value of the feature. signals (np.array): The MS1 signals as [[m/z, intensity], …]. mz_tol (float): The m/z tolerance to find isotopes (default 0.015 Da). charge_state (int): The charge state of the feature (default 1). num (int): The maximum number of isotopes to be found (default 5). Returns:\nnumpy.array: The m/z and intensity of the isotopes. scan_to_scan_cor_intensity scan_to_scan_cor_intensity(a, b)\nCalculates the scan-to-scan correlation between two features using Pearson correlation based on their intensity profiles.\nParameters:\na (np.array): Intensity array of the first m/z. b (np.array): Intensity array of the second m/z. Returns:\nfloat: The scan-to-scan correlation between the two features. scan_to_scan_correlation scan_to_scan_correlation(feature_a, feature_b)\nCalculates the scan-to-scan correlation between two features using Pearson correlation based on their intensity profiles.\nParameters:\nfeature_a (Feature object): The first feature object. feature_b (Feature object): The second feature object. Returns:\nfloat: The scan-to-scan correlation between the two features. get_charge_state get_charge_state(mz_seq, valid_charge_states=[1,2])\nDetermines the charge state of the isotopes based on the m/z sequence.\nParameters:\nmz_seq (list): A list of m/z values of isotopes. valid_charge_states (list): A list of valid charge states (default [1,2]). Returns:\nint: The charge state of the isotopes. ","overview#Overview":"The feature_grouping module provides functions to group features based on their m/z values, retention times, MS2 data, and scan-to-scan correlation. The module is designed for untargeted metabolomics workflows to group features that may represent the same compound, isotopes, in-source fragments, or adducts. The functions in this module are used to group features based on the reference file or within a single file."},"title":"feature_grouping"},"/docs/api/mzpkl/":{"data":{"":"","functions#Functions":"Convert MS Data object to mzpkl convert_MSData_to_mzpkl(d, output_dir: str = None)\nConverts an MSData object to an mzpkl file.\nParameters:\nd (MSData): The MSData object to be converted. output_dir (str): The directory where the mzpkl file will be saved. Output:\nthe converted mzpkl file will be saved in the specified directory. if the output directory is not specified, the mzpkl file will be returned as a dictionary. Read mzpkl to MS Data object read_mzpkl_to_MSData(d, file_path: str)\nReads an mzpkl file to an MSData object.\nParameters:\nd (MSData): The initiated MSData object without scans data. file_path (str): The path to the mzpkl file. ","overview#Overview":"This module defines the structure of the mzpkl file format, which is a temporary file format used to store the raw MS data for faster reloading. The mzpkl file format is a pickle file that is organized this way:\n{ \"name\": str, # the name of the file \"ion_mode\": str, # the ion mode of the file \"ms1_time_arr\": np.ndarray, # the time array of the MS1 scans \"ms1_idx\": np.ndarray, # the index array of the MS1 scans \"ms2_idx\": np.ndarray, # the index array of the MS2 scans \"scans\": list of 2D np.ndarray # MS1 and MS2 scans in the file. Each scan is a 2D np.ndarray with shape (n, 2), [[m/z, intensity], ...] } "},"title":"mzpkl"},"/docs/api/network/":{"data":{"":"Documentation is under construction. Please check our source code directly for the latest updates."},"title":"network"},"/docs/api/normalization/":{"data":{"":"","functions#Functions":"sample_normalization sample_normalization(feature_table, sample_metadata=None, method='pqn', feature_selection=True)\nNormalizes samples using a feature list, typically excluding blank samples.\nParameters:\nfeature_table (pandas DataFrame): The feature table. sample_metadata (pd.DataFrame): DataFrame containing sample metadata. See params module for details. method (str): The method to find the normalization factors. Options: 'pqn': Probabilistic Quotient Normalization. feature_selection (bool): Whether to select high-quality features for normalization. High-quality features have relative standard deviation (RSD) less than 25% in QC samples and average intensity in QC+biological samples greater than 2 fold of the average intensity in blank samples. Returns:\npandas DataFrame: The normalized feature table. find_normalization_factors find_normalization_factors(array, method='pqn')\nFinds the normalization factors for a data frame.\nParameters:\narray (numpy array): The data to be normalized. method (str): The method to find the normalization factors. Options: 'pqn': Probabilistic Quotient Normalization. Returns:\nnumpy array: The normalization factors. sample_normalization_by_factors sample_normalization_by_factors(array, v)\nNormalizes a data frame by a vector.\nParameters:\narray (numpy array): The data to be normalized. v (numpy array): The normalization factor. Returns:\nnumpy array: The normalized data. find_reference_sample find_reference_sample(array, method='median_intensity')\nFinds the reference sample for normalization.\nParameters:\narray (numpy array): The data to be normalized. method (str): The method to find the reference sample. Options: 'number': The reference sample has the most detected features. 'total_intensity': The reference sample has the highest total intensity. 'median_intensity': The reference sample has the highest median intensity. Returns:\nint: The index of the reference sample. high_quality_feature_selection high_quality_feature_selection(array, is_qc=None, is_blank=None, blank_ratio_tol=0.5, qc_rsd_tol=0.25)\nSelects high-quality features based on provided criteria for normalization.\nParameters:\narray (numpy array): The data to be normalized. Samples are in columns and features are in rows. is_qc (numpy array): Boolean array indicating whether a sample is a quality control sample. is_blank (numpy array): Boolean array indicating whether a sample is a blank sample. blank_ratio_tol (float): The tolerance of the ratio of the average intensity in blank samples to the average intensity in QC and biological samples. qc_rsd_tol (float): The tolerance of the relative standard deviation (RSD) in QC samples. Returns:\nnumpy array: High-quality features. Features are in rows and samples are in columns. numpy array: The index of the selected features. signal_normalization signal_normalization(feature_table, sample_metadata, method='lowess', output_plot_path=None)\nNormalizes MS signal drifts based on analytical order.\nParameters:\nfeature_table (pandas DataFrame): The feature table. sample_metadata (pd.DataFrame): DataFrame containing sample metadata. See params module for details. method (str): The method to find the normalization factors. Options: 'lowess': Locally Weighted Scatterplot Smoothing. output_plot_path (str): The path to save the normalization plot. If none, no visualization will be generated. Returns:\npandas DataFrame: The normalized feature table. lowess_normalization lowess_normalization(array, qc_idx, frac=0.07, it=3)\nNormalizes samples using quality control samples.\nParameters:\narray (numpy array): The data to be normalized. qc_idx (numpy array of bool): Boolean array indicating whether a sample is a quality control sample. It’s length should be the same as the length of array. frac (float): The fraction of the data used when estimating each y-value (used in lowess). it (int): The number of residual-based reweightings to perform (used in lowess). Returns:\n‘dict’: A dictionary containing the lowess model, the fit curve, and the normalized array: {‘model’: model, ‘fit_curve’: y, ’normed_arr’: int_arr_corr} ","overview#Overview":"This module provides functions for normalizing data, particularly in the context of mass spectrometry. There are two types of normalization including\nSample normalization - to normalize samples with different total amounts/concentrations. Signal normalization - to address the signal drifts in the mass spectrometry data. "},"title":"normalization"},"/docs/api/params/":{"data":{"":"","classes#Classes":"Params A class to store and manage parameters for mass spectrometry data processing.\nAttributes:\nsample_names (list): Sample names without extension. sample_abs_paths (list): Absolute paths of the raw MS data. sample_metadata (DataFrame): Sample metadata. project_dir (str): Project directory. sample_dir (str): Directory for the raw MS data. single_file_dir (str): Directory for the single file output. tmp_file_dir (str): Directory for the intermediate file output. ms2_matching_dir (str): Directory for the MS2 matching output. bpc_dir (str): Directory for the base peak chromatogram output. project_file_dir (str): Directory for the project files. normalization_dir (str): Directory for the normalization output. statistics_dir (str): Directory for the statistical analysis output. problematic_files (dict): Problematic files. file_name (str): File name of the raw data. file_path (str): Absolute path of the raw data. ion_mode (str): MS ion mode. ms_type (str): Type of MS. is_centroid (bool): Whether the raw data is centroid data. file_format (str): File type in lower case. time (datetime): When the data file was acquired. scan_time_unit (str): Time unit of the scan time. mz_lower_limit (float): Lower limit of m/z in Da. mz_upper_limit (float): Upper limit of m/z in Da. rt_lower_limit (float): Lower limit of RT in minutes. rt_upper_limit (float): Upper limit of RT in minutes. scan_levels (list): Scan levels to be read. centroid_mz_tol (float): m/z tolerance for centroiding. ms1_abs_int_tol (float): Absolute intensity threshold for MS1. ms2_abs_int_tol (float): Absolute intensity threshold for MS2. ms2_rel_int_tol (float): Relative intensity threshold to base peak for MS2. precursor_mz_offset (float): Offset for MS2 m/z range in Da. mz_tol_ms1 (float): m/z tolerance for MS1. mz_tol_ms2 (float): m/z tolerance for MS2. feature_gap_tol (int): Gap tolerance within a feature. batch_size (int): Batch size for parallel processing. percent_cpu_to_use (float): Percentage of CPU to use. group_features_single_file (bool): Whether to group features in a single file. scan_scan_cor_tol (float): Scan-to-scan correlation tolerance for feature grouping. mz_tol_feature_grouping (float): m/z tolerance for feature grouping. rt_tol_feature_grouping (float): RT tolerance for feature grouping. valid_charge_states (list): Valid charge states for feature grouping. mz_tol_alignment (float): m/z tolerance for alignment. rt_tol_alignment (float): RT tolerance for alignment. correct_rt (bool): Whether to perform RT correction. scan_number_cutoff (int): Feature with non-zero scan number greater than the cutoff will be aligned. detection_rate_cutoff (float): Features detected need to be \u003erate*(qc+sample). merge_features (bool): Whether to merge features with almost the same m/z and RT. mz_tol_merge_features (float): m/z tolerance for merging features. rt_tol_merge_features (float): RT tolerance for merging features. group_features_after_alignment (bool): Whether to group features after alignment. fill_gaps (bool): Whether to fill the gaps in the aligned features. gap_filling_method (str): Method for gap filling. gap_filling_rt_window (float): RT window for finding local maximum. ms2_library_path (str): Path to the MS2 library. ms2_sim_tol (float): MS2 similarity tolerance. fuzzy_search (bool): Whether to perform fuzzy search. sample_normalization (bool): Whether to normalize the data based on total sample amount/concentration. sample_norm_method (str): Sample normalization method. signal_normalization (bool): Whether to run feature-wised normalization to correct systematic signal drift. signal_norm_method (str): Normalization method for signal drift. run_statistics (bool): Whether to perform statistical analysis. plot_bpc (bool): Whether to plot base peak chromatograms. plot_ms2 (bool): Whether to plot mirror plots for MS2 matching. plot_normalization (bool): Whether to plot the normalization results. by_group_name (str): Group name for classifier building. output_single_file (bool): Whether to output the processed individual files to a csv file. output_ms1_scans (bool): Whether to output all MS1 scans to a pickle file for faster data reloading. output_aligned_file (bool): Whether to output aligned features to a csv file. quant_method (str): Value for quantification and output. Methods:\nread_parameters_from_csv(path): Read parameters from a CSV file. read_sample_metadata(path): Read sample metadata from a CSV file. _untargeted_metabolomics_workflow_preparation(): Prepare the parameters for the untargeted metabolomics workflow. set_default(ms_type, ion_mode): Set the parameters by the type of MS. check_parameters(): Check if the parameters are correct using PARAMETER_RAGES. output_parameters(path, format=\"json\"): Output the parameters to a file. ","constants#Constants":"valid parameter ranges PARAMETER_RAGES\nA dictionary of valid parameter ranges.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 PARAMETER_RAGES = { \"mz_lower_limit\": (0.0, 100000.0), \"mz_upper_limit\": (0.0, 100000.0), \"rt_lower_limit\": (0.0, 10000.0), \"rt_upper_limit\": (0.0, 10000.0), \"centroid_mz_tol\": (0.0, 0.1), \"ms1_abs_int_tol\": (0, 1e10), \"ms2_abs_int_tol\": (0, 1e10), \"ms2_rel_int_tol\": (0.0, 1.0), \"precursor_mz_offset\": (0.0, 100000.0), \"mz_tol_ms1\": (0.0, 0.02), \"mz_tol_ms2\": (0.0, 0.02), \"feature_gap_tol\": (0, 100), \"scan_scan_cor_tol\": (0.0, 1.0), \"mz_tol_alignment\": (0.0, 0.02), \"rt_tol_alignment\": (0.0, 2.0), \"scan_number_cutoff\": (0, 100), \"detection_rate_cutoff\": (0.0, 1.0), \"mz_tol_merge_features\": (0.0, 0.02), \"rt_tol_merge_features\": (0.0, 0.5), \"ms2_sim_tol\": (0.0, 1.0) } default parameters PARAMETER_DEFAULT\nA dictionary of default parameters.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 PARAMETER_DEFAULT = { \"mz_lower_limit\": 0.0, \"mz_upper_limit\": 100000.0, \"rt_lower_limit\": 0.0, \"rt_upper_limit\": 10000.0, \"centroid_mz_tol\": 0.005, \"ms1_abs_int_tol\": 1000.0, \"ms2_abs_int_tol\": 500, \"ms2_rel_int_tol\": 0.01, \"precursor_mz_offset\": 2.0, \"mz_tol_ms1\": 0.01, \"mz_tol_ms2\": 0.015, \"feature_gap_tol\": 30, \"scan_scan_cor_tol\": 0.7, \"mz_tol_alignment\": 0.01, \"rt_tol_alignment\": 0.2, \"scan_number_cutoff\": 5, \"detection_rate_cutoff\": 0.1, \"mz_tol_merge_features\": 0.01, \"rt_tol_merge_features\": 0.05, \"ms2_sim_tol\": 0.7 } ","functions#Functions":"find_ms_info find_ms_info(file_name)\nFind the type of mass spectrometer and ionization mode from the raw file.\nParameters:\nfile_name (str): The file name of the raw file. Returns:\nms_type (str): The type of MS, “orbitrap”, “qtof”, “tripletof” or “others”. ion_mode (str): The ion mode, “positive” or “negative”. centroid (bool): Whether the data is centroid data. ","overview#Overview":"The params module defines a class Params to store and manage parameters for mass spectrometry data processing. The class provides methods to read parameters from a CSV file, set default parameters based on the type of mass spectrometer and ionization mode, check the validity of parameters, and output parameters to a file. The module also includes a function find_ms_info to determine the type of mass spectrometer and ionization mode from a raw file."},"title":"params"},"/docs/api/raw_data_utils/":{"data":{"":"","classes#Classes":"MSData A class that models a single raw MS data file and processes the raw data.\nAttributes:\nscans (list): A list of Scan objects for mass spectra. ms1_idx (list): Scan indexes of MS1 spectra. ms1_time_arr (list): Time of MS1 scans. ms2_idx (list): Scan indexes of MS2 spectra. params (Params object): A Params object that contains all parameters. base_peak_arr (list): Base peak chromatogram, [[m/z, intensity], ...]. features (list): A list of features. feature_mz_arr (numpy array): m/z of all ROIs. Methods:\nread_raw_data(self, file_name, params=None, scan_levels=[1,2], centroid_mz_tol=0.005, ms1_abs_int_tol=None, ms2_abs_int_tol=None, ms2_rel_int_tol=0.01, precursor_mz_offset=2): Reads raw data from an MS file. extract_scan_mzml(self, scans): Extracts all scans from an mzML file. extract_scan_mzxml(self, scans): Extracts all scans from an mzXML file. drop_ms1_ions_by_intensity(self, int_tol): Drops ions in all MS1 scans by intensity threshold. detect_features(self): Runs feature detection. segment_features(self, iteration=2): Segments features by edge detection. summarize_features(self, cal_g_score=True, cal_a_score=True): Processes features to calculate summary statistics. allocate_ms2_to_features(self, mz_tol=0.015): Allocates MS2 scans to ROIs. drop_features_without_ms2(self): Drops features without MS2 scans. drop_features_by_length(self, length=5): Drops features by length. drop_isotope_features(self): Drops features annotated as isotopes. drop_in_source_fragment_features(self): Discards in-source fragments. plot_bpc(self, time_range=None, label_name=True, output_dir=None): Plots the base peak chromatogram. output_single_file(self, output_path=None): Generates a report for features in csv format. get_eic_data(self, target_mz, target_rt=None, mz_tol=0.005, rt_tol=0.3, rt_range=None): Gets the EIC data of a target m/z. plot_eics(self, target_mz_arr, target_rt=None, mz_tol=0.005, rt_tol=0.3, rt_range=None, output_file_name=None, show_target_rt=True, ylim: list=None, return_eic_data=False): Plots multiple EICs in a single plot. find_ms2_by_mzrt(self, mz_target, rt_target, mz_tol=0.01, rt_tol=0.3, return_best=False): Finds MS2 scan by precursor m/z and retention time. find_feature_by_mzrt(self, mz_target, rt_target=None, mz_tol=0.01, rt_tol=0.3): Finds feature by precursor m/z and retention time. find_ms1_scan_by_rt(self, rt_target): Finds the nearest n MS1 scan by retention time. correct_retention_time(self, f): Corrects retention time. plot_feature(self, feature_idx, mz_tol=0.005, rt_range=[0, np.inf], rt_window=None, output=False): Plots EIC of a ROI. Scan A class that models a single mass spectrum scan.\nAttributes:\nlevel (int): Level of mass spectrum. id (int): Scan ID. scan_time (float): Scan time. signals (numpy array): m/z and intensity signals. precursor_mz (float): Precursor m/z. ","functions#Functions":"clean_signals clean_signals(signals, mz_range=None, intensity_range=None)\nCleans signals by removing ions outside specified m/z and intensity ranges.\nParameters:\nsignals (numpy array): m/z and intensity signals. mz_range (list): m/z range [start, end]. intensity_range (list): Intensity range [min, max]. Returns:\ncleaned_signals (numpy array): Cleaned m/z and intensity signals. centroid_signals centroid_signals(signals, mz_tol)\nCentroids m/z and intensity signals.\nParameters:\nsignals (numpy array): m/z and intensity signals. mz_tol (float): m/z tolerance. Returns:\ncentroided_signals (numpy array): Centroided m/z and intensity signals. segment_feature segment_feature(feature, peak_height_tol, distance)\nSegments a feature by edge detection.\nParameters:\nfeature (Feature object): A feature. peak_height_tol (int): Peak height tolerance. distance (int): Distance. Returns:\nsegmented_features (list): Segmented features. detect_features detect_features(ms_data)\nDetects features in MS data.\nParameters:\nms_data (MSData object): An MSData object. Returns:\nfeatures (list): Detected features. find_best_ms2 find_best_ms2(ms2_seq)\nFinds the best MS2 scan with the highest total intensity.\nParameters:\nms2_seq (list): A list of MS2 scans. Returns:\nbest_ms2 (Scan object): The best MS2 scan. ","overview#Overview":"The raw_data_utils module provides classes and functions for reading and processing raw mass spectrometry (MS) data files. The module supports reading mzML, mzXML, mzjson, and compressed mzjson files. The main class in this module is MSData, which models a single MS file and processes the raw data. The module also includes helper functions for cleaning MS/MS spectra, centroiding m/z and intensity sequences, and extracting EIC data."},"title":"raw_data_utils"},"/docs/api/stats/":{"data":{"":"Documentation is under construction. Please check our source code directly for the latest updates."},"title":"stats"},"/docs/api/utils_functions/":{"data":{"":"","functions#Functions":"generate_sample_table generate_sample_table(path=None, output=True)\nGenerate a sample table from the mzML or mzXML files in the specified path. The stucture of the path should be:\npath ├── data │ ├── sample1.mzml │ ├── sample2.mzml │ └── ... └── ... Parameters:\npath : str Path to the main directory that contains a subdirectory ‘data’ with mzML or mzXML files. output : bool If True, output the sample table to a csv file. Return:\nsample_table : pandas DataFrame A DataFrame with two columns: ‘Sample’ and ‘Groups’. Output:\nsample_table.csv : csv file A csv file with two columns: ‘Sample’ and ‘Groups’ in the specified path. get_timestamps get_timestamps(path=None, output=True)\nGet timestamps for individual files and sort the files by time. The stucture of the path should be:\npath ├── data │ ├── sample1.mzml │ ├── sample2.mzml │ └── ... └── ... Parameters:\npath : str Path to the main directory that contains a subdirectory ‘data’ with mzML or mzXML files. output : bool If True, output the timestamps to a txt file with two columns: ‘file_name’ and ‘aquisition_time’. Return:\nfile_times : list A list of tuples with two elements: ‘file_name’ and ‘aquisition_time’. Output:\ntimestamps.txt : txt file A txt file with two columns: ‘file_name’ and ‘aquisition_time’ in the specified path. formula_to_mz formula_to_mz(formula, adduct, charge)\nCalculate the m/z value of a molecule given its chemical formula, adduct and charge.\nParameters:\nformula : str Chemical formula of the molecule. adduct : str Adduct of the molecule. The first character should be ‘+’ or ‘-’. In particular, for adduct like [M-H-H2O]-, use ‘-H3O’ or ‘-H2OH’. charge : int Charge of the molecule. Positive for cations and negative for anions. Returns:\nmz : float The m/z value of the molecule. Examples:\nformula_to_mz(\"C6H12O6\", \"+H\", 1) # 181.070665 formula_to_mz(\"C9H14N3O8P\", \"-H2OH\", -1) # 304.034010 get_start_time get_start_time(file_name)\nFunction to get the start time of the raw data.\nParameters:\nfile_name : str Absolute path of the raw data. extract_signals_from_string extract_signals_from_string(ms2)\nExtract signals from MS2 spectrum in string format.\nParameters:\nms2 : str MS2 spectrum in string format. Format: “mz1;intensity1|mz2;intensity2|…” Returns:\npeaks : numpy.array Peaks in numpy array format: [[mz1, intensity1], [mz2, intensity2], …] convert_signals_to_string convert_signals_to_string(signals)\nConvert peaks to string format.\nParameters:\nsignals : numpy.array MS2 signals organized as [[mz1, intensity1], [mz2, intensity2], …] Returns:\nstring : str Converted signals in string format. Format: “mz1;intensity1|mz2;intensity2|…” ","overview#Overview":"The utils_functions module contains utility functions that are commonly used in the data processing and analysis of mass spectrometry data. The module includes functions for generating a sample table, getting timestamps for individual files, converting chemical formulas to m/z values, extracting signals from MS2 spectrum in string format, and converting signals to string format."},"title":"utils_functions"},"/docs/api/visualization/":{"data":{"":"This documentation is under construction. Please check our source code directly for the latest updates."},"title":"visualization"},"/docs/api/workflows/":{"data":{"":"","functions#Functions":"process_single_file process_single_file(file_name, params=None, segment_feature=True, group_features=False, evaluate_peak_shape=True, annotate_ms2=False, ms2_library_path=None, output_dir=None)\nPerforms untargeted feature detection for a single file.\nParameters:\nfile_name (str): Path to the raw file. params (Params object, optional): Parameters for feature detection. If None, the default parameters are used based on the type of mass spectrometer. segment_feature (bool, default True): Whether to segment the feature to peaks for distinguishing possible isomers. group_features (bool, default False): Whether to group features by isotopes, adducts, and in-source fragments. evaluate_peak_shape (bool, default True): Whether to evaluate the peak shape by calculating noise score and asymmetry factor. annotate_ms2 (bool, default False): Whether to annotate MS2 spectra. ms2_library_path (str, optional): Path to the MS2 library. output_dir (str, optional): The output directory for the single file. If None, the output is saved to the same directory as the raw file. Returns:\nd (MSData object): An MSData object containing the processed data. Usage:\n# use default parameters for processing a single file result = feature_detection(\"sample.mzML\") untargeted_metabolomics_workflow untargeted_metabolomics_workflow(path=None, return_results=False, only_process_single_files=False, return_params_only=False)\nThe untargeted metabolomics workflow.\nParameters:\npath (str, optional): The working directory. If None, the current working directory is used. return_results (bool, default False): Whether to return the results. only_process_single_files (bool, default False): Whether to only process the single files. return_params_only (bool, default False): Whether to return the parameters only. Returns:\nfeatures (list): A list of features. params (Params object): Parameters for the workflow. Usage:\nuntargeted_metabolomics_workflow(path=\"/path/to/project\") batch_file_processing batch_file_processing(path=None, segment_feature=True, group_features=False, evaluate_peak_shape=True, annotate_ms2=True, ms2_library_path=None, cpu_ratio=0.8, batch_size=100)\nProcess single files using default parameters. This function is useful for batch processing of multiple files. Files from different ion modes are allowed, but parameters cannot be specified for individual files, and default parameters are used.\nParameters:\npath (str, optional): The working directory. If None, the current working directory is used. segment_feature (bool, default True): Whether to segment the feature to peaks for distinguishing possible isomers. group_features (bool, default False): Whether to group features by isotopes, adducts, and in-source fragments. evaluate_peak_shape (bool, default True): Whether to evaluate the peak shape by calculating noise score and asymmetry factor. annotate_ms2 (bool, default True): Whether to annotate MS2 spectra. ms2_library_path (str, optional): The path to the MS2 library. cpu_ratio (float, default 0.8): The percentage of CPU cores to use. batch_size (int, default 100): The number of files to process in each batch. run_evaluation run_evaluation(path=None, zscore_threshold=-2)\nEvaluate the run and report the problematic files. The path to the project directory should be organized as follows:\npath ├── single_files │ ├── sample1.txt │ ├── sample2.txt │ └── ... └── ... where single_files contains the processed files in txt format.\nParameters:\npath (str, optional): Path to the project directory. zscore_threshold (float, default -2): The threshold of z-score for detecting problematic files. ","overview#Overview":"This module provides premade data processing workflows for untargeted metabolomics analysis. The workflows include feature detection, alignment, annotation, normalization, and statistical analysis. The module also includes functions for batch file processing and evaluating the data quality of raw files."},"title":"workflows"},"/docs/installation/":{"data":{"":"","install-_masscube_#Install \u003cem\u003emasscube\u003c/em\u003e":"Install Python Visit the official Python website to download Python. Python 3.11 is recommended.\nDownload Python 3.11.7 Download Python 3.11.7. ❗ Add Python to PATH during installation: check the box ☑️ Add Python 3.X to PATH. Install masscube masscube is a Python package that can be installed using pip. Open terminal and run\npip install masscube To update the package to the latest version, open terminal and run\npip install masscube --upgrade To only install masscube for the current user, add the --user flag. This is to avoid permission issues when installing packages globally (e.g. you are not an administrator).\npip install --user masscube Dependencies will be automatically installed. Consider creating a virtual environment if you’re working with Python on multiple projects.\nDependencies dependencies = [ \"numpy\u003e=1.24\", \"pandas\u003e=2.2.1\", \"pyteomics==4.6.3\", \"scipy\u003e=1.10.1\", \"tqdm\u003e=4.66.1\", \"lxml\u003e=4.9.3\", \"matplotlib\u003e=3.8.2\", \"ms_entropy==1.2.2\", \"scikit-learn\u003e=1.3.2\", \"statsmodels\u003e=0.14.2\", \"umap-learn\u003e=0.5.7\", ] ","install-python#Install Python":""},"title":"Installation"},"/docs/plans/":{"data":{"":"We are working on the following features and improvements and welcome contributions from the community.\nTargeted metabolomics workflows\nMore data normalization algorithms and evaluation metrics\nAlgorithms and workflows for data-independent acquisition (DIA) data.\nTools for LC-MS experimental design and instrumental parameters optimization.\nMS imaging data processing"},"title":"Plans for development"},"/docs/quickstart/":{"data":{"":"Let’s dive into the untargeted metabolomics workflow, designed to simplify and streamline untargeted metabolomics analysis. This powerful workflow delivers comprehensive results with just a single command.\nIf you haven’t installed MassCube yet, be sure to follow the installation guide before proceeding.","the-masscube-untargeted-metabolomics-workflow#The MassCube untargeted metabolomics workflow":"The workflow integrates metadata curation, feature detection, evaluation, alignment, annotation, and statistical analysis to provide users with a comprehensive view of the data (Fig. 1).\nFig. 1. The MassCube untargeted metabolomics workflow Input (3+1) You need three components for the project plus one MS/MS library for annotation.\nIn your project folder (e.g. my_project), you need to prepare the following components:\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... |── sample_table.csv └── parameters.csv data folder: a file folder containing all raw LC-MS data in .mzML or .mzXML format. It’s mandatory. Instructions for file conversion are provided here.\nsample_table.csv file: a csv file to claim the sample groups including biological groups, quality control samples, or blank samples. A template can be downloaded from here. You could also use MassCube to generate a sample table and edit. If not provided, normalization and statistical analysis will not be applied. Note: In sample table, please specify if a sample is blank or qc from the “is_blank” and “is_qc” columns, respectively.\nparameters.csv file: a csv file to set parameters for the workflow. You can set parameters and download the file for the workflow from here or download a template here. If not provided, the default parameters will be applied, yet annotation will not be performed since the MS/MS library is not provided.\nMS2 database: To annotate MS/MS spectra, you need to download a MS/MS library from here. For faster database loading, please download and use the .pkl format.\nExtra component for annotation:\nmzrt_list.csv file: a csv file to provide the m/z and retention time for feature annotation. It was designed to annotate features using retention time (e.g. internal standards). A template can be downloaded from here. It’s optional. Data Preparation Demo data Processing In the project folder, open a terminal and run the following command:\nuntargeted-metabolomics How to open the terminal Make sure the terminal directory is set to the project folder. For Windows user and MacOS user Output After the processing, you will find the following files and folders in the project folder:\nproject/ ├── data ├── sample_table.csv ├── parameters.csv ├── mzrt_list.csv (optional) ├── project_files │ ├── data_processing_metadata_[DATE].pkl │ ├── features.msp │ └── ... ├── aligned_feature_table.txt |── normalized_feature_table.txt (if signal normalization applied) ├── single_files │ ├── sample1.txt │ ├── sample2.txt │ └── ... ├── chromatograms │ ├── sample1.png │ ├── sample2.png │ └── ... ├── ms2_matching │ ├── compound1.png │ ├── compound2.png │ └── ... ├── statistical_analysis ├── normalization results | ├──feature_0_normalization.png | ├──feature_1_normalization.png | └── ... ├── ... project_files folder: a folder containing the metadata file for data processing. aligned_feature_table.txt file: feature table after alignment (if applied). single_files folder: a folder containing the feature table for each sample. chromatograms folder: a folder containing the chromatogram for each sample. ms2_matching folder: a folder containing the MS/MS matching for each annotated compound. statistical_analysis folder: a folder containing the statistical analysis results. normalization results folder: a folder containing the normalization results (if applied). "},"title":"Quick start"},"/docs/workflows/":{"data":{"":"Mass spectrometry data processing is highly application-focused, and MassCube is designed to support this by integrating individual functions and modules into workflows. These pre-defined workflows simplify and accelerate data processing and analysis for specific applications.\nWondering how to contribute to the workflows? Please refer to the contribution guide."},"title":"Workflows"},"/docs/workflows/batch_processing/":{"data":{"":"","explainations-of-the-workflow#Explainations of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def batch_file_processing(path=None, segment_feature=True, group_features=False, evaluate_peak_shape=True, annotate_ms2=True, ms2_library_path=None, cpu_ratio=0.8, batch_size=100): \"\"\" Process single files using default parameters. Parameters ---------- path : str The working directory. If None, the current working directory is used. segment_feature : bool Whether to segment the feature to peaks for distinguishing possible isomers. Default is True. group_features : bool Whether to group features by isotopes, adducts and in-source fragments. Default is True. evaluate_peak_shape : bool Whether to evaluate the peak shape by calculating noise score and asymmetry factor. Default is True. annotate_ms2 : bool Whether to annotate MS2 spectra. Default is True. ms2_library_path : str The path to the MS2 library. cpu_ratio : float The percentage of CPU cores to use. Default is 0.8. batch_size : int The number of files to process in each batch. Default is 100. \"\"\" ... Step 1. Single file processing Individual files are processed for feature detection, which envolves the detection of peak apex, edges, area, and related MS/MS spectra. It also includes the determination of isotopes, charge states, adducts, and in-source fragments.\nTo accelerate the processing, masscube supports parallel computing for multiple files. By default, the number of threads is set to be the 80% (cpu_ratio=0.8) of the total CPU cores so that the computer can still be used for other tasks.\nTo control the memory usage, the files are processed in batches. The default batch size is 100 (batch_size=100).\nStep 2. Data visualization Users can choose to plot the base peak chromatogram (BPC) to verify possible bad injections or outliers.","how-to-use#How to use":" Organize the data Similar to the untargeted metabolomics workflow, the data should be organized in the following structure:\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... ├── ... You cannot set parameters here.\nProcessing In the project folder, open a terminal and run the following command:\nprocess-files Output After the processing, you will find the following files and folders in the project folder:\nproject/ ├── data ├── single_file_output │ ├── sample1.txt │ ├── sample2.txt │ └── ... ├── chromatogram │ ├── sample1.png │ ├── sample2.png │ └── ... ├── ... single_file_output folder: a folder containing the feature table for each sample. chromatogram folder: a folder containing the chromatogram for each sample. ","introduction#Introduction":"Processing each raw LC-MS data individually can be useful for further customized analysis. In this workflow, we introduce how to process single files in batch mode using masscube. Note, the processed files will not be aligned across samples. Also, files with different ion modes and instruments are allowed in the same batch, as masscube will apply different parameters depending on the data."},"title":"Batch processing"},"/docs/workflows/data_preparation/":{"data":{"":"","file-conversion#File conversion":"Raw LC-MS data need to be converted to mzML or mxXML format for further processing in MassCube.\nCurrently, only centroid data are supported in MassCube. We recommend to use MSConvert for file conversion.\nDownload and install MSConvert Visit the official website to download ProteoWizard.\nFile conversion using MSConvert Fig. 1. MSConvert GUI Step 1. Set options Check the boxes as shown in Fig. 1.\n⚠️ Do NOT check Use Zlib compression. Step 2. Set the Peak Picking filter Step 3. Add the Peak Picking filter Step 4. Browse and load files Step 5. Start conversion By default, the converted files will be saved in the same directory as the raw files.\nConvert files in command line mode You can also convert files using MSConvert in command line mode. For more information, please refer to the documentation. ","parameter-file#Parameter file":"A parameter file (.csv) is used to set parameters for the workflow. A templete is provided here. If not provided, the default parameters will be applied. For MassCube version 1.0 or earlier, please use this template.","sample-table#Sample table":"A sample table (.csv) is used to claim the name of samples and their groups including biological groups, quality control samples, or blank samples. A templete is provided here. For MassCube version 1.0 or earlier, please use this template\nFor large-scale metabolomics data, it’s not easy to prepare the sample table manually. In MassCube, we provide a function to automatically generate the sample table based on the file names in the data folder, and users can further define the groups.\nAutomatically generate sample table In the project folder, open a terminal and run the following command:\ngenerate-sample-table Your project folder should include a subfolder named data that contains the raw LC-MS data files in mzML or mzXML format.\nmy_project ├── data │ ├── sample1.mzML │ ├── sample2.mzML | └── ... |── ... You need to further edit the generated sample table to specify QCs, blanks and sample groups. "},"title":"Data preparation"},"/docs/workflows/database/":{"data":{"":"","download-a-database#Download a database":"For users without programming experience or just want to use a database directly, you can download a database from the here. For faster database loading, please download and use the .pkl format.","introduction#Introduction":"A database is a collection of m/z, MS2 spectra, retentiont time, collision cross section, and other information of known compounds. It is used to identify the compounds in the LC-MS data. In this workflow, we introduce how to prepare a database for masscube.","prepare-a-database-for-advanced-users#Prepare a database (for advanced users)":"Three formats are supported for the database: pickle, msp, and json. The pickle format is recommended for faster loading. The msp format is recommended for compatibility with other software. The json format is another human-readable format commonly used in Python.\nMSP format An MSP database is a text file that contains the MS2 database. Each block contains the information of a compound. IMPORTANT: make sure the keys are consistent with the example below.\nNAME: L-PHENYLALANINE PRECURSORMZ: 166.086013793945 PRECURSORTYPE: [M+H]+ IONMODE: Positive RETENTIONTIME: 3.30520009994507 CCS: 136.819671630859 FORMULA: C9H11NO2 ONTOLOGY: Phenylalanine and derivatives SMILES: C1=CC=C(C=C1)C[C@@H](C(=O)O)N INCHIKEY: COLNVLDHVKWLRT-QMMMGPOBSA-N INSTRUMENTTYPE: LC-ESI-QFT COLLISIONENERGY: 35.0 eV COMMENT: DB#=EMBL-MCF_spec98214; origin=EMBL - Metabolomics Core Facility Spectral Library Num Peaks: 7 103.054\t15 107.049\t14 120.081\t1000 121.084\t16 131.049\t41 149.059\t16 166.086\t56 Here, NAME, PRECURSORMZ and PRECURSORTYPE is mandatory. In particular,\nif RETENTIONTIME is not provided, level 1 annotation (i.e. retention time and MS2 matching) will not be performed. if any of FORMULA, SMILES or INCHIKEY is not provided, they will be missing in the output. if MS2 spectra (lines below Num Peaks) are not provided but retention time is provided, mzrt matching will be performed. In this case, no similarity score will be calculated. But you can compare the experimental and matched retention time to see if they are close. Pickle format A .pkl database is a FlashEntropySearch object that contains the MS2 database. ms_entropy version 1.2.2 is highly recommended to generate this object (other versions may not work). Here is an example of how to generate a .pkl database from a msp file:\nfrom masscube.annotation import index_msp_to_pkl # it will output a database.pkl file in the same folder index_msp_to_pkl('database.msp') Check the source code of index_.msp_to_pkl for more details.\nJSON format A JSON database is a list of dictionaries, each dictionary contains\n{ \"name\": \"L-PHENYLALANINE\", \"precursor_mz\": 166.086013793945, \"precursor_type\": \"[M+H]+\", \"ionmode\": \"Positive\", \"retentiontime\": \"3.30520009994507\", \"ccs\": \"136.819671630859\", \"formula\": \"C9H11NO2\", \"ontology\": \"Phenylalanine and derivatives\", \"smiles\": \"C1=CC=C(C=C1)C[C@@H](C(=O)O)N\", \"inchikey\": \"COLNVLDHVKWLRT-QMMMGPOBSA-N\", \"instrumenttype\": \"LC-ESI-QFT\", \"collisionenergy\": \"35.0 eV\", \"comment\": \"DB#=EMBL-MCF_spec98214; origin=EMBL - Metabolomics Core Facility Spectral Library\", \"num peaks\": \"7\", \"peaks\": [ [\"103.054\", \"15\"], [\"107.049\", \"14\"], [\"120.081\", \"1000\"], [\"121.084\", \"16\"], [\"131.049\", \"41\"], [\"149.059\", \"16\"], [\"166.086\", \"56\"] ] } Please see explanations of the keys in the MSP format."},"title":"Database"},"/docs/workflows/find-outliers/":{"data":{"":"","explanation-of-the-workflow#Explanation of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 12 def run_evaluation(path=None, zscore_threshold=-2): \"\"\" Evaluate the run and report the problematic files. Parameters ---------- path : str Path to the project directory. zscore_threshold : float The threshold of z-score for detecting problematic files. Default is -2. \"\"\" ... The run_evaluation function evaluates the run and reports the problematic files. It checks the quality of the raw data and identifies the problematic samples based on the number of detected features.\nThe function generates a problematic_samples.txt file that lists the names of the problematic samples. Users can further investigate the outliers and decide whether to remove them before downstream analysis.","how-to-use#How to use":" Step 1. Organize the data Put all processed raw data files in a folder. The data should be organized in the following structure:\nmy_project ├── single_files │ ├── sample1.txt │ ├── sample2.txt | └── ... └── sample_table.csv Note: Please provide a sample table to specify the blank samples so that they can be excluded from the outlier detection.\nStep 2. Run the outlier detection In the data folder, open a terminal and run the following command:\nfind-outliers Output After the processing, you will find the following files and folders in the data folder:\nmy_project ├── single_files │ ├── sample1.txt │ ├── sample2.txt | └── ... |── sample_table.csv └── problematic_files.txt problematic_samples.txt: a text file containing the names of the problematic samples. single_files: a folder containing the feature detection results for each sample. ","introduction#Introduction":"Outliers are data files that differ significantly from the rest of the dataset. In MS experiments, outliers can arise due to various factors such as instrument error, sample preparation issues, or biological variation. Identifying and removing outliers before downstream analysis is crucial to avoid misleading results.\nmasscube evaluates the analytical sequence and reports problematic samples in an unsupervised manner. It assesses the quality of the raw data by analyzing the total peak height of all detected features. Files with a Z-score lower than -2 (by default) are recognized as outliers, ensuring that only high-quality data are included in the downstream analysis."},"title":"Outlier detection"},"/docs/workflows/parameters/":{"data":{"":"Parameters are critical for MS data processing. However, setting parameters are often challenging, especially for beginners. masscube provides a default parameter setting for users to start with.\nThe default parameters are optimized for most untargeted metabolomics studies. Users can also customize the parameters by providing a parameter file.","customize-parameters#Customize parameters":"From the template, you can customize the parameters by providing a parameter file. The parameter file should be a .csv file with the following columns:\nParameter Value Explanation ion_mode positive MS ion mode, “positive” or “negative” ms_type qtof type of MS, “orbitrap”, “qtof”, “tripletof” or “others” is_centroid yes whether the raw data is centroid data, “yes” or “no” mz_lower_limit 0 lower limit of m/z in Da mz_upper_limit 100000 upper limit of m/z in Da rt_lower_limit 0 lower limit of retention time in minutes rt_upper_limit 10000 upper limit of retention time in minutes ms1_abs_int_tol 1000 absolute intensity threshold for MS1, recommend 30000 for Orbitrap and 1000 for QTOF ms2_abs_int_tol 500 absolute intensity threshold for MS2, recommend 10000 for Orbitrap and 500 for QTOF mz_tol_ms1 0.01 m/z tolerance for MS1, default is 0.01 mz_tol_ms2 0.015 m/z tolerance for MS2, default is 0.015 scan_scan_cor_tol 0.7 scan-to-scan correlation tolerance for feature grouping, default is 0.7 mz_tol_alignment 0.01 m/z tolerance for alignment, default is 0.01 rt_tol_alignment 0.2 RT tolerance for alignment, default is 0.2 correct_rt yes whether to perform RT correction merge_features yes whether to clean feature table by merging features with almost the same m/z and RT ms2_library_path path to the MS2 library (.msp or .pickle) ms2_sim_tol 0.7 MS2 similarity tolerance fuzzy_search yes whether to perform fuzzy search sample_normalization no whether to normalize the data based on total sample amount/concentration signal_normalization no whether to run feature-wised normalization to correct systematic signal drift run_statistics no whether to perform statistical analysis plot_bpc yes whether to plot base peak chromatograms plot_ms2 yes whether to plot mirror plots for MS2 matching plot_normalization yes whether to plot normalization results quant_method peak_height value for quantification and output, “peak_height”, “peak_area” or “top_average” ","default-parameters#Default parameters":"masscube automatically acquire the analytical metadata from the raw files including the mass spectrometer type and ionization mode. The corresponding default parameters will be applied based on the metadata.","key-parameters#Key parameters":"Here we summarized six most important parameters in masscube for untargeted metabolomics data processing:\nMS1 mass tolerance: the mass tolerance for MS1 feature detection. 0.005-0.01 Da is recommended. Intensity tolerance: the intensity tolerance for MS signals. 1000 is recommended for TOF data, and 30000 is recommended for Orbitrap data. Mass tolerance for alignement: the mass tolerance for feature alignment. 0.01-0.015 Da is recommended. RT tolerance for alignment: the RT tolerance for feature alignment. 0.1-0.3 min is recommended. MS/MS similarity score threshold: the threshold for MS/MS similarity score. 0.7-0.8 is recommended. MS/MS library: the MS/MS library for MS/MS annotation. ","more-about-parameters#More about parameters":"Much more parameters in masscube are tunable to ensure flexibility and adaptability for different datasets. For programmers, please refer to each function and object in the API documentation for more details."},"title":"Parameters"},"/docs/workflows/targeted_metabolomics/":{"data":{"":"Workflow is under development. Please check back later."},"title":"Targeted metabolomics"},"/docs/workflows/untargeted_metabolomics/":{"data":{"":"","explainations-of-the-workflow#Explainations of the workflow":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def untargeted_metabolomics_workflow(path=None, return_results=False, only_process_single_files=False, return_params_only=False): \"\"\" The untargeted metabolomics workflow. See the documentation for details. Parameters ---------- path : str The working directory. If None, the current working directory is used. return_results : bool Whether to return the results. Default is False. only_process_single_files : bool Whether to only process the single files. Default is False. return_params_only : bool Whether to return the parameters only. Default is False. Returns ------- features : list A list of features. params : Params object Parameters for the workflow. \"\"\" ... Step 1. Define or load parameters Parameters are critical for MS data processing. However, setting parameters are often challenging, especially for beginners or scientists who are not familiar with the MS data.\nmasscube automatically read the MS data and apply the corresponding default parameters. Users can also customize the parameters by providing a parameter file.\nStep 2. Load sample table and organize data A sample table is used to claim the name of samples and their groups. In most metabolomics studies, quality control samples and blank samples are included. masscube automatically apply normalization and statistical analysis if the sample table is provided.\nStep 3. Single file processing Individual files are processed for feature detection, which envolves the detection of peak apex, edges, area, and related MS/MS spectra. By default, features are not grouped in this step to reduce computational cost, and grouping will be performed in the alignment step.\nTo accelerate the processing, masscube supports parallel computing for multiple files. By default, the number of threads is set to be the 80% of the total CPU cores so that the computer can still be used for other tasks.\nTo control the memory usage, the files are processed in batches. The default batch size is 100.\nStep 4. Feature alignment Feature alignment aims to match the same feature across different samples. The alignment is based on the mass-to-charge ratio and retention time. The mass tolerance and retention time tolerance are critical for the alignment. It also includes the annotation of isotopes, charge states, adducts, and in-source fragments.\nStep 5. Gap filling Gap filling is critical for the downstream statistical analysis, and missing values are treated by forced peak detection.\nStep 6. MS/MS annotation Compound annotation was performed by matching the experimental MS/MS spectra with the MS/MS library. The MS/MS similarity score is generated to indicate the confidence of the annotation.\nFlash entropy search is used to accelerate the annotation. masscube also provides analog search (i.e. hybrid search) for unknown discovery.\nStep 7. Normalization Two types of normalization could be needed in metabolomics to address the systematic signal drifts and the sample-to-sample variation (i.e. total amount/concentration difference). masscube provides multiple post-acquisition normalization algorithms to address the normalization issue.\nStep 8. Statistical analysis Univariate and multivariate statistical analysis will be performed if sample table is provided. The results will be saved in the statistics folder.\nStep 9. Data visualization Users can choose to plot the base peak chromatogram (BPC) to verify possible bad injections or outliers. The MS/MS matching plots are generated for the annotated compounds. PCA plots are generated for the statistical analysis.","how-to-use#How to use":"Please refer to the quick start guide.","introduction#Introduction":"Data processing is critical for metabolomics studies. A series of steps are required to process the raw data to generate biological hypothesis that can be further validated.\nThe MassCube untargeted metabolomics workflow aims to address the burdens in mass spectrometry-based metabolomics data processing. It integrates metadata curation, feature detection, evaluation, alignment, annotation, and statistical analysis to provide users with a comprehensive view of the data."},"title":"Untargeted metabolomics"}}